<?xml version='1.0'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<book>
    <title>Think Complexity</title>
  
  
  

  
  

  
  <bookinfo>
  <title>Think Complexity</title>
  <authorgroup>
    <author>
      <surname>Allen B. Downey</surname>
    </author>
  </authorgroup>
  
  
</bookinfo>

  
  
<preface id="a0000000002">
  <title>Preface</title>
  
  
  <para>This book is about data structures and algorithms, intermediate programming in Python, computational modeling and the philosophy of science: </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Data structures and algorithms:</term>
      <listitem>
  
  <para>A data structure is a collection of data elements organized in a way that supports particular operations. For example, a Python dictionary organizes key-value pairs in a way that provides fast mapping from keys to values, but mapping from values to keys is slower. <indexterm>
  <primary>data structure</primary>

</indexterm> <indexterm>
  <primary>algorithm</primary>

</indexterm> </para>

  
  <para>An algorithm is a mechanical process for performing a computation. Designing efficient programs often involves the co-evolution of data structures and the algorithms that use them. For example, in the first few chapters I will present graphs, data structures that implement graphs, and graph algorithms based on those data structures. <indexterm>
  <primary>graph algorithm</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Python programming:</term>
      <listitem>
  
  <para>This book picks up where <emphasis>Think Python</emphasis> leaves off. I assume that you have read that book or have equivalent knowledge of Python. I try to emphasize fundamental ideas that apply to programming in many languages, but along the way you will learn some useful features that are specific to Python. <indexterm>
  <primary sortas="Think Python">Think Python</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Computational modeling:</term>
      <listitem>
  
  <para>A model of a system is a simplified description of a system used for simulation or analysis. Computational models are designed to take advantage of cheap, fast computation. <indexterm>
  <primary>modeling</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Philosophy of science:</term>
      <listitem>
  
  <para>The models and results in this book raise questions relevant to the philosophy of science, including the nature of scientific laws, theory choice, realism and instrumentalism, holism and reductionism, and epistemology. <indexterm>
  <primary>philosophy</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>There are two kinds of computational models: </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Continuous:</term>
      <listitem>
  
  <para>Many computational models compute approximate solutions to equations that are continuous in space and time. For example, to compute the trajectory of a planet, you could describe planetary motion using differential equations and then compute the position of the planet at discrete points in time. <indexterm>
  <primary>continuous model</primary>

</indexterm> </para>

  
  <para>The fields of numerical methods and scientific computing tend to focus on these kinds of models. <indexterm>
  <primary>numerical methods</primary>

</indexterm> <indexterm>
  <primary>scientific computing</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Discrete:</term>
      <listitem>
  
  <para>Discrete models include graphs, cellular automata, and agent-based models. They are often characterized by structure, rules and transitions rather than by equations. They tend to be more abstract than continuous models; in some cases there is no direct correspondence between the model and a physical system. <indexterm>
  <primary>discrete model</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>Complexity science is an interdisciplinary field—at the intersection of mathematics, computer science and natural science—that focuses on discrete models of physical systems. <indexterm>
  <primary>complexity science</primary>

</indexterm> </para>

  
  <para>And that’s what this book is about. </para>

  
  <para>Allen B. Downey Needham MA</para>

  
  <para>Allen Downey is a Professor of Computer Science at the Franklin W. Olin College of Engineering. </para>
<sect1 id="a0000000003" remap="section">
  <title>Contributor List</title>
    
  
  <para><indexterm>
  <primary>contributors</primary>

</indexterm> </para>

  
  <para>If you have a suggestion or correction, please send email to <literal>downey@greenteapress.com</literal>. If I make a change based on your feedback, I will add you to the contributor list (unless you ask to be omitted). <indexterm>
  <primary>contributors</primary>

</indexterm> </para>

  
  <para>If you include at least part of the sentence the error appears in, that makes it easy for me to search. Page and section numbers are fine, too, but not quite as easy to work with. Thanks! </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Richard Hollands pointed out several typos. </para>
</listitem>
  
    <listitem>
  
  <para>John Harley, Jeff Stanton, Colden Rouleau and Keerthik Omanakuttan are Computational Modeling students who pointed out typos. </para>
</listitem>
  
    <listitem>
  
  <para>Muhammad Najmi bin Ahmad Zabidi caught some typos. </para>
</listitem>
  
    <listitem>
  
  <para>Phillip Loh, Corey Dolphin, Noam Rubin and Julian Ceipek found typos and made helpful suggestions. </para>
</listitem>
  
    <listitem>
  
  <para>Jose Oscar Mur-Miranda found several typos. </para>
</listitem>
  
</itemizedlist></para>

  
  

  
  

  
  

  
  

</sect1>
</preface><chapter id="a0000000004">
  <title>Graphs</title>
  <sect1 id="a0000000005" remap="section">
  <title>What’s a graph?</title>
    
  
  <para>To most people a graph is a visual representation of a data set, like a bar chart or an EKG. That’s not what this chapter is about. <indexterm>
  <primary>graph</primary>

</indexterm> </para>

  
  <para>In this chapter, a <emphasis role="bold">graph</emphasis> is an abstraction used to model a system that contains discrete, interconnected elements. The elements are represented by <emphasis role="bold">nodes</emphasis> (also called <emphasis role="bold">vertices</emphasis>) and the interconnections are represented by <emphasis role="bold">edges</emphasis>. <indexterm>
  <primary>node</primary>

</indexterm> <indexterm>
  <primary>edge</primary>

</indexterm> <indexterm>
  <primary>vertex</primary>

</indexterm> </para>

  
  <para>For example, you could represent a road map with one node for each city and one edge for each road between cities. Or you could represent a social network using one node for each person, with an edge between two people if they are “friends” and no edge otherwise. <indexterm>
  <primary>road network</primary>

</indexterm> <indexterm>
  <primary>social network</primary>

</indexterm> </para>

  
  <para>In some graphs, edges have different lengths (sometimes called “weights” or “costs”). For example, in a road map, the length of an edge might represent the distance between two cities, or the travel time, or bus fare. In a social network there might be different kinds of edges to represent different kinds of relationships: friends, business associates, etc. <indexterm>
  <primary>edge weight</primary>

</indexterm> <indexterm>
  <primary>weight</primary>

</indexterm> </para>

  
  <para>Edges may be <emphasis role="bold">undirected</emphasis>, if they represent a relationship that is symmetric, or <emphasis role="bold">directed</emphasis>. In a social network, friendship is usually symmetric: if <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0001.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$A$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is friends with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0002.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$B$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> then <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0002.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$B$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is friends with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0001.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$A$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. So you would probably represent friendship with an undirected edge. In a road map, you would probably represent a one-way street with a directed edge. <indexterm>
  <primary>directed graph</primary>

</indexterm> <indexterm>
  <primary>undirected graph</primary>

</indexterm> </para>

  
  <para>Graphs have interesting mathematical properties, and there is a branch of mathematics called <emphasis role="bold">graph theory</emphasis> that studies them. <indexterm>
  <primary>graph theory</primary>

</indexterm> </para>

  
  <para>Graphs are also useful, because there are many real world problems that can be solved using <emphasis role="bold">graph algorithms</emphasis>. For example, Dijkstra’s shortest path algorithm is an efficient way to find the shortest path from a node to all other nodes in a graph. A <emphasis role="bold">path</emphasis> is a sequence of nodes with an edge between each consecutive pair. <indexterm>
  <primary>graph algorithm</primary>

</indexterm> <indexterm>
  <primary>path</primary>

</indexterm> </para>

  
  <para>Sometimes the connection between a real world problem and a graph algorithm is obvious. In the road map example, it is not hard to imagine using a shortest path algorithm to find the route between two cities that minimizes distance (or time, or cost). <indexterm>
  <primary>shortest distance</primary>

</indexterm> </para>

  
  <para>In other cases it takes more effort to represent a problem in a form that can be solved with a graph algorithm, and then interpret the solution. <indexterm>
  <primary>problem formulation</primary>

</indexterm> </para>

  
  <para>For example, a complex system of radioactive decay can be represented by a graph with one node for each nuclide (type of atom) and an edge between two nuclides if one can decay into the other. A path in this graph represents a decay chain. See <ulink url="wikipedia.org/wiki/Radioactive_decay">wikipedia.org/wiki/Radioactive_decay</ulink>. <indexterm>
  <primary>radioactive decay</primary>

</indexterm> <indexterm>
  <primary>decay chain</primary>

</indexterm> </para>

  
  <para>The rate of decay between two nuclides is characterized by a decay constant, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0003.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, measured in becquerels (Bq) or decay events per second. You might be more familiar with half-life, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0004.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t_{1/2}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the expected time until half of a sample decays. You can convert from one characterization to the other using the relation <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0005.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t_{1/2} = \ln 2 / \lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>half life</primary>

</indexterm> <indexterm>
  <primary>becquerel</primary>

</indexterm> </para>

  
  <para>In our best current model of physics, nuclear decay is a fundamentally random process, so it is impossible to predict when an atom will decay. However, given <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0003.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the probability that an atom will decay during a short time interval <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0006.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$dt$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0007.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\lambda dt$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>random process</primary>

</indexterm> </para>

  
  <para>In a graph with multiple decay chains, the probability of a given path is the product of the probabilities of each decay process in the path. </para>

  
  <para>Now suppose you want to find the decay chain with the highest probability. You could do it by assigning each edge a “length” of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0008.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-\log \lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and using a shortest path algorithm. Why? Because the shortest path algorithm adds up the lengths of the edges, and adding up log-probabilities is the same as multiplying probabilities. Also, because the logarithms are negated, the smallest sum corresponds to the largest probability. So the shortest path corresponds to the most likely decay chain. </para>

  
  <para>This is an example of a common and useful process in applying graph algorithms: <indexterm>
  <primary>applying graph algorithm</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Reduce</term>
      <listitem>
  
  <para>a real-world problem to an instance of a graph problem. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Apply</term>
      <listitem>
  
  <para>a graph algorithm to compute the result efficiently. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Interpret</term>
      <listitem>
  
  <para>the result of the computation in terms of a solution to the original problem. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>We will see other examples of this process soon. </para>

  
  

  
  <para>Read the Wikipedia page about graphs at <ulink url="http://en.wikipedia.org/wiki/Graph_(mathematics)">http://en.wikipedia.org/wiki/Graph_(mathematics)</ulink> and answer the following questions: </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What is a simple graph? In the rest of this section, we will be assuming that all graphs are simple graphs. This is a common assumption for many graph algorithms—so common it is often unstated. <indexterm>
  <primary>simple graph</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is a regular graph? What is a complete graph? Prove that a complete graph is regular. <indexterm>
  <primary>regular graph</primary>

</indexterm> <indexterm>
  <primary>complete graph</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is a path? What is a cycle? <indexterm>
  <primary>path</primary>

</indexterm> <indexterm>
  <primary>cycle</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is a forest? What is a tree? Note: a graph is <emphasis role="bold">connected</emphasis> if there is a path from every node to every other node. <indexterm>
  <primary>forest</primary>

</indexterm> <indexterm>
  <primary>connected graph</primary>

</indexterm> </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000006" remap="section">
  <title>Representing graphs</title>
    
  
  <para>Graphs are usually drawn with squares or circles for nodes and lines for edges. In the example below, the graph on the left represents a social network with three people. <indexterm>
  <primary>representing graphs</primary>

</indexterm> </para>

  
  <figure id="a0000000007">
  
  <title>Examples of graphs.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/graph_examples.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>In the graph on the right, the weights of the edges are the approximate travel times, in hours, between cities in the northeast United States. In this case the placement of the nodes corresponds roughly to the geography of the cities, but in general the layout of a graph is arbitrary. <indexterm>
  <primary>graph layout</primary>

</indexterm> </para>

  
  <para>To implement graph algorithms, you have to figure out how to represent a graph in the form of a data structure. But to choose the best data structure, you have to know which operations the graph should support. <indexterm>
  <primary>data structure</primary>

</indexterm> </para>

  
  <para>To get out of this chicken-and-egg problem, I am going to present a data structure that is a good choice for many graph algorithms. Later we will come back and evaluate its pros and cons. </para>

  
  <para>Here is an implementation of a graph as a dictionary of dictionaries: <indexterm>
  <primary>dictionary</primary>

</indexterm> <indexterm>
  <primary>nested dictionary</primary>

</indexterm> <indexterm>
  <primary sortas="Graph">Graph</primary>

</indexterm> </para>

  
  <programlisting>class Graph(dict):
    def __init__(self, vs=[], es=[]):
        """create a new graph.  (vs) is a list of vertices;
        (es) is a list of edges."""
        for v in vs:
            self.add_vertex(v)

        for e in es:
            self.add_edge(e)

    def add_vertex(self, v):
        """add (v) to the graph"""
        self[v] = {}

    def add_edge(self, e):
        """add (e) to the graph by adding an entry in both directions.

        If there is already an edge connecting these Vertices, the
        new edge replaces it.
        """
        v, w = e
        self[v][w] = e
        self[w][v] = e</programlisting>

  
  <para> The first line declares that <literal>Graph</literal> inherits from the built-in type <literal>dict</literal>, so a Graph object has all the methods and operators of a dictionary. <indexterm>
  <primary>inheritance</primary>

</indexterm> </para>

  
  <para>More specifically, a Graph is a dictionary that maps from a Vertex <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0009.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$v$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to an inner dictionary that maps from a Vertex <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0010.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$w$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to an Edge that connects <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0009.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$v$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0010.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$w$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. So if <literal>g</literal> is a graph, <literal>g[v][w]</literal> maps to an Edge if there is one and raises a <literal>KeyError</literal> otherwise. <indexterm>
  <primary>vertex</primary>

</indexterm> <indexterm>
  <primary>edge</primary>

</indexterm> </para>

  
  <para><literal remap="verb">__init__</literal> takes a list of vertices and a list of edges as optional parameters. If they are provided, it calls <literal remap="verb">add_vertex</literal> and <literal remap="verb">add_edge</literal> to add the vertices and edges to the graph. <indexterm>
  <primary>optional parameter</primary>

</indexterm> </para>

  
  <para>Adding a vertex to a graph means making an entry for it in the outer dictionary. Adding an edge makes two entries, both pointing to the same Edge. So this implementation represents an undirected graph. <indexterm>
  <primary>directed edge</primary>

</indexterm> <indexterm>
  <primary>undirected edge</primary>

</indexterm> </para>

  
  <para>Here is the definition for <literal>Vertex</literal>: <indexterm>
  <primary sortas="Vertex">Vertex</primary>

</indexterm> </para>

  
  <programlisting>class Vertex(object):
    def __init__(self, label=''):
        self.label = label

    def __repr__(self):
        return 'Vertex(%s)' % repr(self.label)

    __str__ = __repr__</programlisting>

  
  <para> A Vertex is just an object that has a label attribute. We can add attributes later, as needed. <indexterm>
  <primary>label</primary>

</indexterm> </para>

  
  <para><literal remap="verb">__repr__</literal> is a special function that returns a string representation of an object. It is similar to <literal remap="verb">__str__</literal> except that the return value from <literal remap="verb">__str__</literal> is intended to be readable for people, and the return value from <literal remap="verb">__repr__</literal> is supposed to be a legal Python expression. <indexterm>
  <primary sortas="repr">__repr__</primary>

</indexterm> <indexterm>
  <primary sortas="str">__str__</primary>

</indexterm> <indexterm>
  <primary sortas="str">str</primary>

</indexterm> <indexterm>
  <primary sortas="repr">repr</primary>

</indexterm> </para>

  
  <para>The built-in function <literal>str</literal> invokes <literal remap="verb">__str__</literal> on an object; similarly the built-in function <literal>repr</literal> invokes <literal remap="verb">__repr__</literal>. </para>

  
  <para>In this case <literal remap="verb">Vertex.__str__</literal> and <literal remap="verb">Vertex.__repr__</literal> refer to the same function, so we get the same string either way. </para>

  
  <para>Here is the definition for <literal>Edge</literal>: <indexterm>
  <primary sortas="Edge">Edge</primary>

</indexterm> </para>

  
  <programlisting>class Edge(tuple):
    def __new__(cls, *vs):
        return tuple.__new__(cls, vs)

    def __repr__(self):
        return 'Edge(%s, %s)' % (repr(self[0]), repr(self[1]))

    __str__ = __repr__</programlisting>

  
  <para> <literal>Edge</literal> inherits from the built-in type <literal>tuple</literal> and overrides the <literal remap="verb">__new__</literal> method. When you invoke an object constructor, Python invokes <literal remap="verb">__new__</literal> to create the object and then <literal remap="verb">__init__</literal> to initialize the attributes. <indexterm>
  <primary>tuple</primary>

</indexterm> <indexterm>
  <primary sortas="new">__new__</primary>

</indexterm> <indexterm>
  <primary sortas="init">__init__</primary>

</indexterm> </para>

  
  <para>For mutable objects it is most common to override <literal remap="verb">__init__</literal> and use the default implementation of <literal remap="verb">__new__</literal>, but because Edges inherit from <literal>tuple</literal>, they are immutable, which means that you can’t modify the elements of the tuple in <literal remap="verb">__init__</literal>. <indexterm>
  <primary>mutable objects</primary>

</indexterm> <indexterm>
  <primary>immutable objects</primary>

</indexterm> </para>

  
  <para>By overriding <literal remap="verb">__new__</literal>, we can use the <literal>*</literal> operator to gather the parameters and use them to initialize the elements of the tuple. A precondition of this method is that there should be exactly two arguments. A more careful implementation would check. <indexterm>
  <primary>override</primary>

</indexterm> <indexterm>
  <primary>gather operator</primary>

</indexterm> <indexterm>
  <primary>precondition</primary>

</indexterm> </para>

  
  <para>Here is an example that creates two vertices and an edge: </para>

  
  <programlisting>v = Vertex('v')
    w = Vertex('w')
    e = Edge(v, w)
    print e</programlisting>

  
  <para> Inside <literal remap="verb">Edge.__str__</literal> the term <literal>self[0]</literal> refers to <literal>v</literal> and <literal>self[1]</literal> refers to <literal>w</literal>. So the output when you print <literal>e</literal> is: </para>

  
  <programlisting>Edge(Vertex('v'), Vertex('w'))</programlisting>

  
  <para> Now we can assemble the edge and vertices into a graph: </para>

  
  <programlisting>g = Graph([v, w], [e])
    print g</programlisting>

  
  <para> The output looks like this (with a little formatting): </para>

  
  <programlisting>{Vertex('w'): {Vertex('v'): Edge(Vertex('v'), Vertex('w'))},
 Vertex('v'): {Vertex('w'): Edge(Vertex('v'), Vertex('w'))}}</programlisting>

  
  <para> We didn’t have to write <literal remap="verb">Graph.__str__</literal>; it is inherited from <literal>dict</literal>. <indexterm>
  <primary>inheritance</primary>

</indexterm> </para>

  
  

  
  <para>In this exercise you write methods that will be useful for many of the Graph algorithms that are coming up. <indexterm>
  <primary>graph methods</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Download <ulink url="thinkcomplex.com/GraphCode.py">thinkcomplex.com/GraphCode.py</ulink>, which contains the code in this chapter. Run it as a script and make sure the test code in <literal>main</literal> does what you expect. </para>
</listitem>
  
  <listitem>
  
  <para>Make a copy of <literal>GraphCode.py</literal> called <literal>Graph.py</literal>. Add the following methods to <literal>Graph</literal>, adding test code as you go. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal remap="verb">get_edge</literal> that takes two vertices and returns the edge between them if it exists and <literal>None</literal> otherwise. Hint: use a <literal>try</literal> statement. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal remap="verb">remove_edge</literal> that takes an edge and removes all references to it from the graph. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal>vertices</literal> that returns a list of the vertices in a graph. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal>edges</literal> that returns a list of edges in a graph. Note that in our representation of an undirected graph there are two references to each edge. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal remap="verb">out_vertices</literal> that takes a Vertex and returns a list of the adjacent vertices (the ones connected to the given node by an edge). </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal remap="verb">out_edges</literal> that takes a Vertex and returns a list of edges connected to the given Vertex. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method named <literal remap="verb">add_all_edges</literal> that starts with an edgeless Graph and makes a complete graph by adding edges between all pairs of vertices. </para>
</listitem>
  
</orderedlist></para>

  
  <para>Test your methods by writing test code and checking the output. Then download <ulink url="thinkcomplex.com/GraphWorld.py">thinkcomplex.com/GraphWorld.py</ulink>. GraphWorld is a simple tool for generating visual representations of graphs. It is based on the World class in Swampy, so you might have to install Swampy first: see <ulink url="thinkpython.com/swampy">thinkpython.com/swampy</ulink>. <indexterm>
  <primary sortas="GraphWorld">GraphWorld</primary>

</indexterm> <indexterm>
  <primary>Swampy</primary>

</indexterm> </para>

  
  <para>Read through <literal>GraphWorld.py</literal> to get a sense of how it works. Then run it. It should import your <literal>Graph.py</literal> and then display a complete graph with 10 vertices. </para>

  
  

  
  

  
  <para>Write a method named <literal remap="verb">add_regular_edges</literal> that starts with an edgeless graph and adds edges so that every vertex has the same degree. The <emphasis role="bold">degree</emphasis> of a node is the number of edges it is connected to. <indexterm>
  <primary>regular graph</primary>

</indexterm> <indexterm>
  <primary>degree</primary>

</indexterm> </para>

  
  <para>To create a regular graph with degree 2 you would do something like this: </para>

  
  <programlisting>vertices = [ ... list of Vertices ... ]
g = Graph(vertices, [])
g.add_regular_edges(2)</programlisting>

  
  <para> It is not always possible to create a regular graph with a given degree, so you should figure out and document the preconditions for this method. </para>

  
  <para>To test your code, you might want to create a file named <literal>GraphTest.py</literal> that imports <literal>Graph.py</literal> and <literal>GraphWorld.py</literal>, then generates and displays the graphs you want to test. </para>

  
  

  
  

</sect1><sect1 id="ex.randomgraph" remap="section">
  <title>Random graphs</title>
    
  
  <para>A random graph is just what it sounds like: a graph with edges generated at random. Of course, there are many random processes that can generate graphs, so there are many kinds of random graphs. One interesting kind is the Erdȍs-Rényi model, denoted <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0011.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$G(n,p)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which generates graphs with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> nodes, where the probability is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> that there is an edge between any two nodes. See <ulink url="http://en.wikipedia.org/wiki/Erdos-Renyi_model">http://en.wikipedia.org/wiki/Erdos-Renyi_model</ulink>. <indexterm>
  <primary sortas="Erdos-Renyi model">-Rényimodel</primary>

</indexterm> <indexterm>
  <primary>random graph</primary>

</indexterm> </para>

  
  

  
  <para>Create a file named <literal>RandomGraph.py</literal> and define a class named <literal>RandomGraph</literal> that inherits from <literal>Graph</literal> and provides a method named <literal remap="verb">add_random_edges</literal> that takes a probability <literal>p</literal> as a parameter and, starting with an edgeless graph, adds edges at random so that the probability is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> that there is an edge between any two nodes. <indexterm>
  <primary sortas="RandomGraph">RandomGraph</primary>

</indexterm> </para>

  
  

</sect1><sect1 id="bfs" remap="section">
  <title>Connected graphs</title>
    
  
  

  
  <para>A graph is <emphasis role="bold">connected</emphasis> if there is a path from every node to every other node. See <ulink url="wikipedia.org/wiki/Connectivity_(graph_theory)">wikipedia.org/wiki/Connectivity_(graph_theory)</ulink>. <indexterm>
  <primary>connected graph</primary>

</indexterm> <indexterm>
  <primary>path</primary>

</indexterm> </para>

  
  <para>There is a simple algorithm to check whether a graph is connected. Start at any vertex and conduct a search (usually a breadth-first-search or BFS), marking all the vertices you can reach. Then check to see whether all vertices are marked. <indexterm>
  <primary>breadth-first search</primary>

</indexterm> <indexterm>
  <primary>BFS</primary>

</indexterm> </para>

  
  <para>You can read about breadth-first-search at <ulink url="wikipedia.org/wiki/Breadth-first_search">wikipedia.org/wiki/Breadth-first_search</ulink>. </para>

  
  <para>In general, when you process a node, we say that you are <emphasis role="bold">visiting</emphasis> it. <indexterm>
  <primary>visting a node</primary>

</indexterm> </para>

  
  <para>In a search, you visit a node by marking it (so you can tell later that it has been visited) then visiting any unmarked vertices it is connected to. <indexterm>
  <primary>marking a node</primary>

</indexterm> </para>

  
  <para>In a breadth-first-search, you visit nodes in the order they are discovered. You can use a queue or a “worklist” to keep them in order. Here’s how it works: <indexterm>
  <primary>queue</primary>

</indexterm> <indexterm>
  <primary>worklist</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Start with any vertex and add it to the queue. </para>
</listitem>
  
  <listitem>
  
  <para>Remove a vertex from the queue and mark it. If it is connected to any unmarked vertices, add them to the queue. </para>
</listitem>
  
  <listitem>
  
  <para>If the queue is not empty, go back to Step 2. </para>
</listitem>
  
</orderedlist></para>

  
  

  
  <para>Write a Graph method named <literal remap="verb">is_connected</literal> that returns <literal>True</literal> if the Graph is connected and <literal>False</literal> otherwise. </para>

  
  

</sect1><sect1 id="a0000000010" remap="section">
  <title>Paul Erdȍs: peripatetic mathematician, speed freak</title>
    
  
  <para> <indexterm>
  <primary sortas="Erdos, Paul">, Paul</primary>

</indexterm> </para>

  
  <para>Paul Erdȍs was a Hungarian mathematician who spent most of his career (from 1934 until his death in 1992) living out of a suitcase, visiting colleagues at universities all over the world, and authoring papers with more than 500 collaborators. </para>

  
  <para>He was a notorious caffeine addict and, for the last 20 years of his life, an enthusiastic user of amphetamines. He attributed at least some of his productivity to the use of these drugs; after giving them up for a month to win a bet, he complained that the only result was that mathematics had been set back by a month<footnote><para>Much of this biography follows <ulink url="wikipedia.org/wiki/Paul_Erdos">wikipedia.org/wiki/Paul_Erdos</ulink></para></footnote>. <indexterm>
  <primary>caffeine</primary>

</indexterm> <indexterm>
  <primary>amphetamine</primary>

</indexterm> </para>

  
  <para>In the 1960s he and Afréd Rényi  wrote a series of papers introducing the Erdȍs-Rényi  model of random graphs and studying their properties. <indexterm>
  <primary sortas="Renyi, Afred">Rényi, Afréd</primary>

</indexterm> </para>

  
  <para>One of their most surprising results is the existence of abrupt changes in the characteristics of random graphs as random edges are added. They showed that for a number of graph properties there is a threshold value of the probability <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> below which is the property is rare and above which it is almost certain. This transition is sometimes called a “phase change” by analogy with physical systems that change state at some critical value of temperature. See <ulink url="wikipedia.org/wiki/Phase_transition">wikipedia.org/wiki/Phase_transition</ulink>. <indexterm>
  <primary>phase chance</primary>

</indexterm> <indexterm>
  <primary>threshold value</primary>

</indexterm> </para>

  
  

  
  <para>One of the properties that displays this kind of transition is connectedness. For a given size <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, there is a critical value, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0014.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p^*$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, such that a random graph <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0015.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$G(n, p)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is unlikely to be connected if <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0016.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p &lt; p^*$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and very likely to be connected if <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0017.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p &gt; p^*$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>critical value</primary>

</indexterm> </para>

  
  <para>Write a program that tests this result by generating random graphs for values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and computes the fraction of them that are connected. </para>

  
  <para>How does the abruptness of the transition depend on <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>

  
  <para>You can download my solution from <ulink url="thinkcomplex.com/RandomGraph.py">thinkcomplex.com/RandomGraph.py</ulink>. </para>

  
  

</sect1><sect1 id="a0000000011" remap="section">
  <title>Iterators</title>
    
  
  <para>If you have read the documentation of Python dictionaries, you might have noticed the methods <literal>iterkeys</literal>, <literal>itervalues</literal> and <literal>iteritems</literal>. These methods are similar to <literal>keys</literal>, <literal>values</literal> and <literal>items</literal>, except that instead of building a new list, they return iterators. <indexterm>
  <primary>iterator</primary>

</indexterm> </para>

  
  <para>An <emphasis role="bold">iterator</emphasis> is an object that provides a method named <literal>next</literal> that returns the next element in a sequence. Here is an example that creates a dictionary and uses <literal>iterkeys</literal> to traverse the keys. </para>

  
  <programlisting>&gt;&gt;&gt; d = dict(a=1, b=2)
&gt;&gt;&gt; iter = d.iterkeys()
&gt;&gt;&gt; print iter.next()
a
&gt;&gt;&gt; print iter.next()
b
&gt;&gt;&gt; print iter.next()
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
StopIteration</programlisting>

  
  <para> The first time <literal>next</literal> is invoked, it returns the first key from the dictionary (the order of the keys is arbitrary). The second time it is invoked, it returns the second element. The third time, and every time thereafter, it raises a <literal>StopIteration</literal> exception. <indexterm>
  <primary sortas="StopIteration">StopIteration</primary>

</indexterm> </para>

  
  <para>An iterator can be used in a <literal>for</literal> loop; for example, the following is a common idiom for traversing the key-value pairs in a dictionary: <indexterm>
  <primary sortas="for">for loop</primary>

</indexterm> </para>

  
  <programlisting>for k, v in d.iteritems():
        print k, v</programlisting>

  
  <para> In this context, <literal>iteritems</literal> is likely to be faster than <literal>items</literal> because it doesn’t have to build the entire list of tuples; it reads them from the dictionary as it goes along. <indexterm>
  <primary>dictionary</primary>

</indexterm> </para>

  
  <para>But it is only safe to use the iterator methods if you do not add or remove dictionary keys inside the loop. Otherwise you get an exception: </para>

  
  <programlisting>&gt;&gt;&gt; d = dict(a=1)
&gt;&gt;&gt; for k in d.iterkeys():
...     d['b'] = 2
...
RuntimeError: dictionary changed size during iteration</programlisting>

  
  <para> Another limitation of iterators is that they do not support index operations. </para>

  
  <programlisting>&gt;&gt;&gt; iter = d.iterkeys()
&gt;&gt;&gt; print iter[1]
TypeError: 'dictionary-keyiterator' object is unsubscriptable</programlisting>

  
  <para> If you need indexed access, you should use <literal>keys</literal>. Alternatively, the Python module <literal>itertools</literal> provides many useful iterator functions. <indexterm>
  <primary sortas="itertools">itertools</primary>

</indexterm> </para>

  
  <para>A user-defined object can be used as an iterator if it provides methods named <literal>next</literal> and <literal remap="verb">__iter__</literal>. The following example is an iterator that always returns <literal>True</literal>: <indexterm>
  <primary sortas="iter">__iter__</primary>

</indexterm> </para>

  
  <programlisting>class AllTrue(object):
    def next(self):
        return True

    def __iter__(self):
        return self</programlisting>

  
  <para> The <literal remap="verb">__iter__</literal> method for iterators returns the iterator itself. This protocol makes it possible to use iterators and sequences interchangeably in many contexts. </para>

  
  <para>Iterators like <literal>AllTrue</literal> can represent an infinite sequence. They are useful as an argument to <literal>zip</literal>: <indexterm>
  <primary>infinite sequence</primary>

</indexterm> </para>

  
  <programlisting>&gt;&gt;&gt; print zip('abc', AllTrue())
[('a', True), ('b', True), ('c', True)]</programlisting>

</sect1><sect1 id="a0000000012" remap="section">
  <title>Generators</title>
    
  
  <para>For many purposes the easiest way to make an iterator is to write a <emphasis role="bold">generator</emphasis>, which is a function that contains a <literal>yield</literal> statement. <literal>yield</literal> is similar to <literal>return</literal>, except that the state of the running function is stored and can be resumed. <indexterm>
  <primary>generator</primary>

</indexterm> <indexterm>
  <primary sortas="yield">yield</primary>

</indexterm> </para>

  
  <para>For example, here is a generator that yields successive letters of the alphabet: </para>

  
  <programlisting>def generate_letters():
    for letter in 'abc':
        yield letter</programlisting>

  
  <para>When you call this function, the return value is an iterator: </para>

  
  <programlisting>&gt;&gt;&gt; iter = generate_letters()
&gt;&gt;&gt; print iter
&lt;generator object at 0xb7d4ce4c&gt;
&gt;&gt;&gt; print iter.next()
a
&gt;&gt;&gt; print iter.next()
b</programlisting>

  
  <para>And you can use an iterator in a <literal>for</literal> loop: </para>

  
  <programlisting>&gt;&gt;&gt; for letter in generate_letters():
...     print letter
...
a
b
c</programlisting>

  
  <para>A generator with an infinite loop returns an iterator that never terminates. For example, here’s a generator that cycles through the letters of the alphabet: <indexterm>
  <primary>infinite loop</primary>

</indexterm> </para>

  
  <programlisting>def alphabet_cycle():
    while True:
        for c in string.lowercase:
            yield c</programlisting>

  
  

  
  <para>Write a generator that yields an infinite sequence of alpha-numeric identifiers, starting with <literal>a1</literal> through <literal>z1</literal>, then <literal>a2</literal> through <literal>z2</literal>, and so on. </para>

  
  

</sect1>
</chapter><chapter id="a0000000013">
  <title>Analysis of algorithms</title>
  
  
  <para>Analysis of algorithms is the branch of computer science that studies the performance of algorithms, especially their run time and space requirements. See <ulink url="wikipedia.org/wiki/Analysis_of_algorithms">wikipedia.org/wiki/Analysis_of_algorithms</ulink>. <indexterm>
  <primary>algorithm</primary>

</indexterm> <indexterm>
  <primary>analysis of algorithms</primary>

</indexterm> </para>

  
  <para>The practical goal of algorithm analysis is to predict the performance of different algorithms in order to guide design decisions. </para>

  
  <para>During the 2008 United States Presidential Campaign, candidate Barack Obama was asked to perform an impromptu analysis when he visited Google. Chief executive Eric Schmidt jokingly asked him for “the most efficient way to sort a million 32-bit integers.” Obama had apparently been tipped off, because he quickly replied, “I think the bubble sort would be the wrong way to go.” See <ulink url="http://www.youtube.com/watch?v=k4RRi_ntQc8">http://www.youtube.com/watch?v=k4RRi_ntQc8</ulink>. <indexterm>
  <primary>Obama, Barack</primary>

</indexterm> <indexterm>
  <primary>Schmidt, Eric</primary>

</indexterm> <indexterm>
  <primary>bubble sort</primary>

</indexterm> </para>

  
  <para>This is true: bubble sort is conceptually simple but slow for large datasets. The answer Schmidt was probably looking for is “radix sort” (see <ulink url="wikipedia.org/wiki/Radix_sort">wikipedia.org/wiki/Radix_sort</ulink>)<footnote><para> But if you get a question like this in an interview, I think a better answer is, “The fastest way to sort a million integers is to use whatever sort function is provided by the language I’m using. Its performance is good enough for the vast majority of applications, but if it turned out that my application was too slow, I would use a profiler to see where the time was being spent. If it looked like a faster sort algorithm would have a significant effect on performance, then I would look around for a good implementation of radix sort.”</para></footnote>. <indexterm>
  <primary>radix sort</primary>

</indexterm> </para>

  
  <para>So the goal of algorithm analysis is to make meaningful comparisons between algorithms, but there are some problems: <indexterm>
  <primary>comparing algorithms</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>The relative performance of the algorithms might depend on characteristics of the hardware, so one algorithm might be faster on Machine A, another on Machine B. The general solution to this problem is to specify a <emphasis role="bold">machine model</emphasis> and analyze the number of steps, or operations, an algorithm requires under a given model. <indexterm>
  <primary>machine model</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Relative performance might depend on the details of the dataset. For example, some sorting algorithms run faster if the data are already partially sorted; other algorithms run slower in this case. A common way to avoid this problem is to analyze the <emphasis role="bold">worst case</emphasis> scenario. It is also sometimes useful to analyze average case performance, but it is usually harder, and sometimes it is not clear what set of cases to average over. <indexterm>
  <primary>worst case</primary>

</indexterm> <indexterm>
  <primary>average case</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Relative performance also depends on the size of the problem. A sorting algorithm that is fast for small lists might be slow for long lists. The usual solution to this problem is to express run time (or number of operations) as a function of problem size, and to compare the functions <emphasis role="bold">asymptotically</emphasis> as the problem size increases. <indexterm>
  <primary>asymptotic analysis</primary>

</indexterm> </para>
</listitem>
  
</itemizedlist></para>

  
  <para>The good thing about this kind of comparison that it lends itself to simple classification of algorithms. For example, if I know that the run time of Algorithm A tends to be proportional to the size of the input, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and Algorithm B tends to be proportional to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0018.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, then I expect A to be faster than B for large values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>This kind of analysis comes with some caveats, but we’ll get to that later. </para>
<sect1 id="a0000000014" remap="section">
  <title>Order of growth</title>
    
  
  <para>Suppose you have analyzed two algorithms and expressed their run times in terms of the size of the input: Algorithm A takes <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0019.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$100 n + 1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> steps to solve a problem with size <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; Algorithm B takes <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0020.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^2 + n + 1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> steps. <indexterm>
  <primary>order of growth</primary>

</indexterm> </para>

  
  <para>The following table shows the run time of these algorithms for different problem sizes: </para>

  
  <para>
   
   
     <informaltable remap="tabular">
     <tr>
     
       
       <td>
  
  <para> Input </para>
</td>
     
       
       <td>
  
  <para> Run time of </para>
</td>
     
       
       <td>
  
  <para> Run time of </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>size </para>
</td>
     
       
       <td>
  
  <para> Algorithm A </para>
</td>
     
       
       <td>
  
  <para> Algorithm B </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>10 </para>
</td>
     
       
       <td>
  
  <para> 1 001 </para>
</td>
     
       
       <td>
  
  <para> 111 </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>100 </para>
</td>
     
       
       <td>
  
  <para> 10 001 </para>
</td>
     
       
       <td>
  
  <para> 10 101 </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>1 000 </para>
</td>
     
       
       <td>
  
  <para> 100 001 </para>
</td>
     
       
       <td>
  
  <para> 1 001 001 </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>10 000 </para>
</td>
     
       
       <td>
  
  <para> 1 000 001 </para>
</td>
     
       
       <td>
  
  <para> <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0021.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$&gt; 10^{10}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
     </tr>
     </informaltable>
   
</para>

  
  <para>At <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0022.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n=10$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, Algorithm A looks pretty bad; it takes almost 10 times longer than Algorithm B. But for <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0023.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n=100$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> they are about the same, and for larger values A is much better. </para>

  
  <para>The fundamental reason is that for large values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, any function that contains an <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0018.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> term will grow faster than a function whose leading term is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. The <emphasis role="bold">leading term</emphasis> is the term with the highest exponent. <indexterm>
  <primary>leading term</primary>

</indexterm> <indexterm>
  <primary>exponent</primary>

</indexterm> </para>

  
  <para>For Algorithm A, the leading term has a large coefficient, 100, which is why B does better than A for small <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. But regardless of the coefficients, there will always be some value of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0024.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$a n^2 &gt; b n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>leading coefficient</primary>

</indexterm> </para>

  
  <para>The same argument applies to the non-leading terms. Even if the run time of Algorithm A were <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0025.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n + 1000000$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, it would still be better than Algorithm B for sufficiently large <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>In general, we expect an algorithm with a smaller leading term to be a better algorithm for large problems, but for smaller problems, there may be a <emphasis role="bold">crossover point</emphasis> where another algorithm is better. The location of the crossover point depends on the details of the algorithms, the inputs, and the hardware, so it is usually ignored for purposes of algorithmic analysis. But that doesn’t mean you can forget about it. <indexterm>
  <primary>crossover point</primary>

</indexterm> </para>

  
  <para>If two algorithms have the same leading order term, it is hard to say which is better; again, the answer depends on the details. So for algorithmic analysis, functions with the same leading term are considered equivalent, even if they have different coefficients. </para>

  
  <para>An <emphasis role="bold">order of growth</emphasis> is a set of functions whose asymptotic growth behavior is considered equivalent. For example, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0026.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$2n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0027.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$100n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0028.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n + 1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> belong to the same order of growth, which is written <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0029.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in <emphasis role="bold">Big-Oh notation</emphasis> and often called <emphasis role="bold">linear</emphasis> because every function in the set grows linearly with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>big-oh notation</primary>

</indexterm> <indexterm>
  <primary>linear growth</primary>

</indexterm> </para>

  
  <para>All functions with the leading term <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0018.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> belong to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0030.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^2)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; they are <emphasis role="bold">quadratic</emphasis>, which is a fancy word for functions with the leading term <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0018.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>quadratic growth</primary>

</indexterm> </para>

  
  <para>The following table shows some of the orders of growth that appear most commonly in algorithmic analysis, in increasing order of badness. <indexterm>
  <primary>badness</primary>

</indexterm> </para>

  
  <para>
   
   
     <informaltable remap="tabular">
     <tr>
     
       
       <td>
  
  <para> Order of </para>
</td>
     
       
       <td>
  
  <para> Name </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>growth </para>
</td>
     
       
       <td></td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0031.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(1)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> constant </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0032.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(\log _ b n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> logarithmic (for any <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0033.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$b$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>) </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0029.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> linear </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0034.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n \log _ b n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> “en log en” </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0030.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^2)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> quadratic </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0035.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^3)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> cubic </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0036.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(c^ n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>
</td>
     
       
       <td>
  
  <para> exponential (for any <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0037.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>) </para>
</td>
     
     </tr>
     </informaltable>
   
</para>

  
  <para>For the logarithmic terms, the base of the logarithm doesn’t matter; changing bases is the equivalent of multiplying by a constant, which doesn’t change the order of growth. Similarly, all exponential functions belong to the same order of growth regardless of the base of the exponent. Exponential functions grow very quickly, so exponential algorithms are only useful for small problems. <indexterm>
  <primary>logarithmic growth</primary>

</indexterm> <indexterm>
  <primary>exponential growth</primary>

</indexterm> </para>

  
  

  
  <para>Read the Wikipedia page on Big-Oh notation at <ulink url="wikipedia.org/wiki/Big_O_notation">wikipedia.org/wiki/Big_O_notation</ulink> and answer the following questions: </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What is the order of growth of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0038.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^3 + n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? What about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0039.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1000000 n^3 + n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? What about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0040.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n^3 + 1000000 n^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
  <listitem>
  
  <para>What is the order of growth of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0041.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$(n^2 + n) \cdot (n + 1)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? Before you start multiplying, remember that you only need the leading term. </para>
</listitem>
  
  <listitem>
  
  <para>If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0043.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(g)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, for some unspecified function <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0044.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$g$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, what can we say about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0045.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$a f + b$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
  <listitem>
  
  <para>If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0046.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0047.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> are in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0043.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(g)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, what can we say about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0048.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1 + f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
  <listitem>
  
  <para>If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0046.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0043.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(g)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0047.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0049.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(h)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, what can we say about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0048.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1 + f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
  <listitem>
  
  <para>If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0046.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0043.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(g)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0047.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0049.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(h)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, what can we say about <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0050.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f_1 * f_2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
</orderedlist></para>

  
  

  
  <para>Programmers who care about performance often find this kind of analysis hard to swallow. They have a point: sometimes the coefficients and the non-leading terms make a real difference. And sometimes the details of the hardware, the programming language, and the characteristics of the input make a big difference. And for small problems asymptotic behavior is irrelevant. <indexterm>
  <primary>practical analysis of algorithms</primary>

</indexterm> </para>

  
  <para>But if you keep those caveats in mind, algorithmic analysis is a useful tool. At least for large problems, the “better” algorithms is usually better, and sometimes it is <emphasis>much</emphasis> better. The difference between two algorithms with the same order of growth is usually a constant factor, but the difference between a good algorithm and a bad algorithm is unbounded! <indexterm>
  <primary>unbounded</primary>

</indexterm> </para>

</sect1><sect1 id="a0000000015" remap="section">
  <title>Analysis of basic operations</title>
    
  
  <para>Most arithmetic operations are constant time; multiplication usually takes longer than addition and subtraction, and division takes even longer, but these run times don’t depend on the magnitude of the operands. Very large integers are an exception; in that case the run time increases linearly with the number of digits. <indexterm>
  <primary>analysis of primitives</primary>

</indexterm> </para>

  
  <para>Indexing operations—reading or writing elements in a sequence or dictionary—are also constant time, regardless of the size of the data structure. <indexterm>
  <primary>indexing</primary>

</indexterm> </para>

  
  <para>A <literal>for</literal> loop that traverses a sequence or dictionary is usually linear, as long as all of the operations in the body of the loop are constant time. For example, adding up the elements of a list is linear: </para>

  
  <programlisting>total = 0
    for x in t:
        total += x</programlisting>

  
  <para>The built-in function <literal>sum</literal> is also linear because it does the same thing, but it tends to be faster because it is a more efficient implementation; in the language of algorithmic analysis, it has a smaller leading coefficient. </para>

  
  <para>If you use the same loop to “add” a list of strings, the run time is quadratic because string concatenation is linear. <indexterm>
  <primary>string concatenation</primary>

</indexterm> </para>

  
  <para>The string method <literal>join</literal> is usually faster because it is linear in the total length of the strings. <indexterm>
  <primary sortas="join">join</primary>

</indexterm> </para>

  
  <para>As a rule of thumb, if the body of a loop is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0051.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^ a)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> then the whole loop is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0052.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^{a+1})$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. The exception is if you can show that the loop exits after a constant number of iterations. If a loop runs <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> times regardless of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, then the loop is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0051.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^ a)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, even for large <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Multiplying by <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> doesn’t change the order of growth, but neither does dividing. So if the body of a loop is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0051.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^ a)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and it runs <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0054.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n / k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> times, the loop is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0052.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n^{a+1})$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, even for large <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Most string and tuple operations are linear, except indexing and <literal>len</literal>, which are constant time. The built-in functions <literal>min</literal> and <literal>max</literal> are linear. The run-time of a slice operation is proportional to the length of the output, but independent of the size of the input. <indexterm>
  <primary>string methods</primary>

</indexterm> <indexterm>
  <primary>tuple methods</primary>

</indexterm> </para>

  
  <para>All string methods are linear, but if the lengths of the strings are bounded by a constant—for example, operations on single characters—they are considered constant time. </para>

  
  <para>Most list methods are linear, but there are some exceptions: <indexterm>
  <primary>list methods</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Adding an element to the end of a list is constant time on average; when it runs out of room it occasionally gets copied to a bigger location, but the total time for <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> operations is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0029.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, so we say that the “amortized” time for one operation is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0031.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(1)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
    <listitem>
  
  <para>Removing an element from the end of a list is constant time. </para>
</listitem>
  
    <listitem>
  
  <para>Sorting is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0055.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n \log n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>sorting</primary>

</indexterm> </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Most dictionary operations and methods are constant time, but there are some exceptions: <indexterm>
  <primary>dictionary methods</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>The run time of <literal>copy</literal> is proportional to the number of elements, but not the size of the elements (it copies references, not the elements themselves). </para>
</listitem>
  
    <listitem>
  
  <para>The run time of <literal>update</literal> is proportional to the size of the dictionary passed as a parameter, not the dictionary being updated. </para>
</listitem>
  
    <listitem>
  
  <para><literal>keys</literal>, <literal>values</literal> and <literal>items</literal> are linear because they return new lists; <literal>iterkeys</literal>, <literal>itervalues</literal> and <literal>iteritems</literal> are constant time because they return iterators. But if you loop through the iterators, the loop will be linear. Using the “iter” functions saves some overhead, but it doesn’t change the order of growth unless the number of items you access is bounded. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>The performance of dictionaries is one of the minor miracles of computer science. We will see how they work in <xref linkend="hashtable" />. </para>

  
  

  
  <para>Read the Wikipedia page on sorting algorithms at <ulink url="wikipedia.org/wiki/Sorting_algorithm">wikipedia.org/wiki/Sorting_algorithm</ulink> and answer the following questions: <indexterm>
  <primary>sorting</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What is a “comparison sort?” What is the best worst-case order of growth for a comparison sort? What is the best worst-case order of growth for any sort algorithm? <indexterm>
  <primary>comparison sort</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is the order of growth of bubble sort, and why does Barack Obama think it is “the wrong way to go?” </para>
</listitem>
  
  <listitem>
  
  <para>What is the order of growth of radix sort? What preconditions do we need to use it? </para>
</listitem>
  
  <listitem>
  
  <para>What is a stable sort and why might it matter in practice? <indexterm>
  <primary>stable sort</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is the worst sorting algorithm (that has a name)? </para>
</listitem>
  
  <listitem>
  
  <para>What sort algorithm does the C library use? What sort algorithm does Python use? Are these algorithms stable? You might have to Google around to find these answers. </para>
</listitem>
  
  <listitem>
  
  <para>Many of the non-comparison sorts are linear, so why does does Python use an <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0055.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(n \log n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> comparison sort? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000016" remap="section">
  <title>Analysis of search algorithms</title>
    
  
  <para>A <emphasis role="bold">search</emphasis> is an algorithm that takes a collection and a target item and determines whether the target is in the collection, often returning the index of the target. <indexterm>
  <primary>search</primary>

</indexterm> </para>

  
  <para>The simplest search algorithm is a “linear search,” which traverses the items of the collection in order, stopping if it finds the target. In the worst case it has to traverse the entire collection, so the run time is linear. <indexterm>
  <primary>linear search</primary>

</indexterm> </para>

  
  <para>The <literal>in</literal> operator for sequences uses a linear search; so do string methods like <literal>find</literal> and <literal>count</literal>. <indexterm>
  <primary sortas="in">in operator</primary>

</indexterm> </para>

  
  <para>If the elements of the sequence are in order, you can use a <emphasis role="bold">bisection search</emphasis>, which is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0056.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(\log n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Bisection search is similar to the algorithm you probably use to look a word up in a dictionary (the book, not the data structure). Instead of starting at the beginning and checking each item in order, you start with the item in the middle and check whether the word you are looking for comes before or after. If it comes before, then you search the first half of the sequence. Otherwise you search the second half. Either way, you cut the number of remaining items in half. <indexterm>
  <primary>bisection search</primary>

</indexterm> </para>

  
  <para>If the sequence has 1,000,000 items, it will take about 20 steps to find the word or conclude that it’s not there. So that’s about 50,000 times faster than a linear search. </para>

  
  

  
  <para>Write a function called <literal>bisection</literal> that takes a sorted list and a target value and returns the index of the value in the list, if it’s there, or <literal>None</literal> if it’s not. <indexterm>
  <primary sortas="bisect">bisect module</primary>

</indexterm> </para>

  
  <para><indexterm>
  <primary>bisect module</primary>

</indexterm> <indexterm>
  <primary>module</primary>
<secondary>bisect</secondary>
</indexterm> </para>

  
  <para>Or you could read the documentation of the <literal>bisect</literal> module and use that! </para>

  
  

  
  <para>Bisection search can be much faster than linear search, but it requires the sequence to be in order, which might require extra work. </para>

  
  <para>There is another data structure, called a <emphasis role="bold">hashtable</emphasis> that is even faster—it can do a search in constant time—and it doesn’t require the items to be sorted. Python dictionaries are implemented using hashtables, which is why most dictionary operations, including the <literal>in</literal> operator, are constant time. </para>

</sect1><sect1 id="hashtable" remap="section">
  <title>Hashtables</title>
    
  
  

  
  <para>To explain how hashtables work and why their performance is so good, I start with a simple implementation of a map and gradually improve it until it’s a hashtable. <indexterm>
  <primary>hashtable</primary>

</indexterm> </para>

  
  <para>I use Python to demonstrate these implementations, but in real life you wouldn’t write code like this in Python; you would just use a dictionary! So for the rest of this chapter, you have to imagine that dictionaries don’t exist and you want to implement a data structure that maps from keys to values. The operations you have to implement are: </para>

  
  <para><variablelist>
  <varlistentry>
    <term><literal>add(k, v)</literal>:</term>
      <listitem>
  
  <para>Add a new item that maps from key <literal>k</literal> to value <literal>v</literal>. With a Python dictionary, <literal>d</literal>, this operation is written <literal>d[k] = v</literal>. </para>
</listitem>
  </varlistentry><varlistentry>
    <term><literal>get(target)</literal>:</term>
      <listitem>
  
  <para>Look up and return the value that corresponds to key <literal>target</literal>. With a Python dictionary, <literal>d</literal>, this operation is written <literal>d[target]</literal> or <literal>d.get(target)</literal>. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>For now, I assume that each key only appears once. The simplest implementation of this interface uses a list of tuples, where each tuple is a key-value pair. <indexterm>
  <primary sortas="LinearMap">LinearMap</primary>

</indexterm> </para>

  
  <programlisting>class LinearMap(object):

    def __init__(self):
        self.items = []

    def add(self, k, v):
        self.items.append((k, v))

    def get(self, k):
        for key, val in self.items:
            if key == k:
                return val
        raise KeyError</programlisting>

  
  <para><literal>add</literal> appends a key-value tuple to the list of items, which takes constant time. </para>

  
  <para><literal>get</literal> uses a <literal>for</literal> loop to search the list: if it finds the target key it returns the corresponding value; otherwise it raises a <literal>KeyError</literal>. So <literal>get</literal> is linear. <indexterm>
  <primary sortas="KeyError">KeyError</primary>

</indexterm> </para>

  
  <para>An alternative is to keep the list sorted by key. Then <literal>get</literal> could use a bisection search, which is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0056.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(\log n)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. But inserting a new item in the middle of a list is linear, so this might not be the best option. There are other data structures<footnote><para>See <ulink url="wikipedia.org/wiki/Red-black_tree">wikipedia.org/wiki/Red-black_tree</ulink>.</para></footnote> that can implement <literal>add</literal> and <literal>get</literal> in log time, but that’s still not as good as a hashtable, so let’s move on. <indexterm>
  <primary>red-black tree</primary>

</indexterm> </para>

  
  <para>One way to improve <literal>LinearMap</literal> is to break the list of key-value pairs into smaller lists. Here’s an implementation called <literal>BetterMap</literal>, which is a list of 100 LinearMaps. As we’ll see in a second, the order of growth for <literal>get</literal> is still linear, but <literal>BetterMap</literal> is a step on the path toward hashtables: <indexterm>
  <primary sortas="BetterMap">BetterMap</primary>

</indexterm> </para>

  
  <programlisting>class BetterMap(object):

    def __init__(self, n=100):
        self.maps = []
        for i in range(n):
            self.maps.append(LinearMap())

    def find_map(self, k):
        index = hash(k) % len(self.maps)
        return self.maps[index]

    def add(self, k, v):
        m = self.find_map(k)
        m.add(k, v)

    def get(self, k):
        m = self.find_map(k)
        return m.get(k)</programlisting>

  
  <para><literal remap="verb">__init__</literal> makes a list of <literal>n</literal> <literal>LinearMap</literal>s. </para>

  
  <para><literal remap="verb">find_map</literal> is used by <literal>add</literal> and <literal>get</literal> to figure out which map to put the new item in, or which map to search. </para>

  
  <para><literal remap="verb">find_map</literal> uses the built-in function <literal>hash</literal>, which takes almost any Python object and returns an integer. A limitation of this implementation is that it only works with hashable keys. Mutable types like lists and dictionaries are unhashable. <indexterm>
  <primary>hash function</primary>

</indexterm> </para>

  
  <para>Hashable objects that are considered equal return the same hash value, but the converse is not necessarily true: two different objects can return the same hash value. </para>

  
  <para><literal remap="verb">find_map</literal> uses the modulus operator to wrap the hash values into the range from 0 to <literal>len(self.maps)</literal>, so the result is a legal index into the list. Of course, this means that many different hash values will wrap onto the same index. But if the hash function spreads things out pretty evenly (which is what hash functions are designed to do), then we expect <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0057.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n/100$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> items per LinearMap. </para>

  
  <para>Since the run time of <literal>LinearMap.get</literal> is proportional to the number of items, we expect BetterMap to be about 100 times faster than LinearMap. The order of growth is still linear, but the leading coefficient is smaller. That’s nice, but still not as good as a hashtable. </para>

  
  <para>Here (finally) is the crucial idea that makes hashtables fast: if you can keep the maximum length of the LinearMaps bounded, <literal>LinearMap.get</literal> is constant time. All you have to do is keep track of the number of items and when the number of items per LinearMap exceeds a threshold, resize the hashtable by adding more LinearMaps. <indexterm>
  <primary>bounded</primary>

</indexterm> </para>

  
  <para>Here is an implementation of a hashtable: <indexterm>
  <primary>HashMap</primary>

</indexterm> </para>

  
  <programlisting>class HashMap(object):

    def __init__(self):
        self.maps = BetterMap(2)
        self.num = 0

    def get(self, k):
        return self.maps.get(k)

    def add(self, k, v):
        if self.num == len(self.maps.maps):
            self.resize()

        self.maps.add(k, v)
        self.num += 1

    def resize(self):
        new_maps = BetterMap(self.num * 2)

        for m in self.maps.maps:
            for k, v in m.items:
                new_maps.add(k, v)</programlisting>

  
  <para>Each <literal>HashMap</literal> contains a <literal>BetterMap</literal>; <literal remap="verb">__init__</literal> starts with just 2 LinearMaps and initializes <literal>num</literal>, which keeps track of the number of items. </para>

  
  <para><literal>get</literal> just dispatches to <literal>BetterMap</literal>. The real work happens in <literal>add</literal>, which checks the number of items and the size of the <literal>BetterMap</literal>: if they are equal, the average number of items per LinearMap is 1, so it calls <literal>resize</literal>. </para>

  
  <para><literal>resize</literal> make a new <literal>BetterMap</literal>, twice as big as the previous one, and then “rehashes” the items from the old map to the new. </para>

  
  <para>Rehashing is necessary because changing the number of LinearMaps changes the denominator of the modulus operator in <literal remap="verb">find_map</literal>. That means that some objects that used to wrap into the same LinearMap will get split up (which is what we wanted, right?). <indexterm>
  <primary>rehashing</primary>

</indexterm> </para>

  
  <para>Rehashing is linear, so <literal>resize</literal> is linear, which might seem bad, since I promised that <literal>add</literal> would be constant time. But remember that we don’t have to resize every time, so <literal>add</literal> is usually constant time and only occasionally linear. The total amount of work to run <literal>add</literal> <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> times is proportional to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, so the average time of each <literal>add</literal> is constant time! <indexterm>
  <primary>constant time</primary>

</indexterm> </para>

  
  <para>To see how this works, think about starting with an empty HashTable and adding a sequence of items. We start with 2 LinearMaps, so the first 2 adds are fast (no resizing required). Let’s say that they take one unit of work each. The next add requires a resize, so we have to rehash the first two items (let’s call that 2 more units of work) and then add the third item (one more unit). Adding the next item costs 1 unit, so the total so far is 6 units of work for 4 items. </para>

  
  <para>The next <literal>add</literal> costs 5 units, but the next three are only one unit each, so the total is 14 units for the first 8 adds. </para>

  
  <para>The next <literal>add</literal> costs 9 units, but then we can add 7 more before the next resize, so the total is 30 units for the first 16 adds. </para>

  
  <para>After 32 adds, the total cost is 62 units, and I hope you are starting to see a pattern. After <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> adds, where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a power of two, the total cost is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0058.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$2n - 2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> units, so the average work per add is a little less than 2 units. When <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a power of two, that’s the best case; for other values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> the average work is a little higher, but that’s not important. The important thing is that it is constant time! <indexterm>
  <primary>average cost</primary>

</indexterm> </para>

  
  <para>The following figure shows how this works graphically. Each block represents a unit of work. The columns show the total work for each add in order from left to right: the first two <literal>adds</literal> cost 1 units, the third costs 3 units, etc. </para>

  
  <figure id="a0000000018">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/towers.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>The extra work of rehashing appears as a sequence of increasingly tall towers with increasing space between them. Now if you knock over the towers, amortizing the cost of resizing over all adds, you can see graphically that the total cost after <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> adds is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0058.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$2n - 2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>An important feature of this algorithm is that when we resize the HashTable it grows geometrically; that is, we multiply the size by a constant. If you increase the size arithmetically—adding a fixed number each time—the average time per <literal>add</literal> is linear. <indexterm>
  <primary>geometric resizing</primary>

</indexterm> </para>

  
  <para>You can download my implementation of HashMap from <ulink url="thinkcomplex.com/Map.py">thinkcomplex.com/Map.py</ulink>, but remember that there is no reason to use it; if you want a map, just use a Python dictionary. </para>

  
  

  
  <para>My implementation of <literal>HashMap</literal> accesses the attributes of <literal>BetterMap</literal> directly, which shows poor object-oriented design. <indexterm>
  <primary>object-oriented design</primary>

</indexterm> </para>

  
  <para>Improve it by: </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>The special method <literal remap="verb">__len__</literal> is invoked by the built-in function <literal>len</literal>. Write a <literal remap="verb">__len__</literal> method for <literal>BetterMap</literal> and use it in <literal>add</literal>. <indexterm>
  <primary sortas="len">__len__</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>Use a generator to write <literal>BetterMap.iteritems</literal>, and use it in <literal>resize</literal>. <indexterm>
  <primary>generator</primary>

</indexterm> </para>
</listitem>
  
</orderedlist></para>

  
  

  
  

  
  <para>Write an implementation of the map interface called <literal>TreeMap</literal> that uses a red-black tree to perform <literal>add</literal> and <literal>get</literal> in log time. <indexterm>
  <primary>red-black tree</primary>

</indexterm> <indexterm>
  <primary sortas="TreeMap">TreeMap</primary>

</indexterm> </para>

  
  

</sect1><sect1 id="a0000000019" remap="section">
  <title>Summing lists</title>
    
  
  <para>Suppose you have a bunch of lists and you want to join them up into a single list. There are three ways you might do that in Python: <indexterm>
  <primary>summing lists</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>You could use the <literal>+=</literal> operator: </para>

  
  <programlisting>total = []
    for x in t:
        total += x</programlisting>
</listitem>
  
    <listitem>
  
  <para>Or the <literal>extend</literal> method: </para>

  
  <programlisting>total = []
    for x in t:
        total.extend(x)</programlisting>
</listitem>
  
    <listitem>
  
  <para>Or the built-in function <literal>sum</literal>: </para>

  
  <programlisting>total = sum(t, [])</programlisting>

  
  <para>The second argument to <literal>sum</literal> is the initial value for the total. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Without knowing how <literal>+=</literal> and <literal>extend</literal> and <literal>sum</literal> are implemented, it is hard to analyze their performance. For example, if <literal>total += x</literal> creates a new list every time, the loop is quadratic; but if it modifies <literal>total</literal>, it’s linear. <indexterm>
  <primary sortas="+=">+= operator</primary>

</indexterm> <indexterm>
  <primary sortas="extend">extend</primary>

</indexterm> <indexterm>
  <primary sortas="sum">sum</primary>

</indexterm> </para>

  
  <para>To find out, we could read the source code, but as an exercise, let’s see if we can figure it out by measuring run times. </para>

  
  <para>A simple way to measure the run time of a program is to use the function <literal>times</literal> in the <literal>os</literal> module, which returns a tuple of floats indicating the time your process has used (see the documentation for details). I use a function <literal>etime</literal>, which returns the sum of “user time” and “system time” which is usually what we care about for performance measurement: <indexterm>
  <primary sortas="os module">os module</primary>

</indexterm> <indexterm>
  <primary>user time</primary>

</indexterm> <indexterm>
  <primary>system time</primary>

</indexterm> </para>

  
  <programlisting>import os

def etime():
    """See how much user and system time this process has used
    so far and return the sum."""

    user, sys, chuser, chsys, real = os.times()
    return user+sys</programlisting>

  
  <para>To measure the elapsed time of a function you can call <literal>etime</literal> twice and compute the difference: </para>

  
  <programlisting>start = etime()

    # put the code you want to measure here

    end = etime()
    elapsed = end - start</programlisting>

  
  <para>Alternatively, if you use IPython, you can use the <literal>timeit</literal> command. See <ulink url="ipython.scipy.org">ipython.scipy.org</ulink>. <indexterm>
  <primary>IPython</primary>

</indexterm> <indexterm>
  <primary sortas="timeit">timeit</primary>

</indexterm> </para>

  
  <para>If an algorithm is quadratic, we expect the run time, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> as a function of input size, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, to look like this: <indexterm>
  <primary>quadratic</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000020" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0060.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  t = a n^2 + b n + c  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0061.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$a$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0033.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$b$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0037.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> are unknown coefficients. If you take the log of both sides you get: </para>

  
  <para><informalequation id="a0000000021" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0062.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \log t \sim \log a + 2 \log n  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>For large values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the non-leading terms are insignificant and this approximation is pretty good. So if we plot <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> on a log-log scale, we expect a straight line with slope 2. <indexterm>
  <primary>log-log scale</primary>

</indexterm> </para>

  
  <para>Similarly if the algorithm is linear, we expect a line with slope 1. <indexterm>
  <primary>linear</primary>

</indexterm> </para>

  
  <para>I wrote three functions that concatenate lists: <literal remap="verb">sum_plus</literal> uses <literal>+=</literal>; <literal remap="verb">sum_extend</literal> uses <literal>list.extend</literal>; and <literal remap="verb">sum_sum</literal> uses <literal>sum</literal>. I timed them for a range of <literal>n</literal> and plotted the results on a log-log scale. Figures <xref linkend="listsum1" /> and <xref linkend="listsum2" /> show the results. </para>

  
  <figure id="listsum1">
  
  <title>Runtime versus <literal>n</literal>. The gray lines have slope 1.<anchor id="a0000000022" /></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/listsum1.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <figure id="listsum2">
  
  <title>Runtime versus <literal>n</literal>. The gray line has slope 2.<anchor id="a0000000023" /></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/listsum2.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>In <xref linkend="listsum1" /> I fit a line with slope 1 to the curves. The data fit this line well, so we conclude that these implementations are linear. The implementation for <literal>+=</literal> is faster by a constant factor because it takes some time to look up the <literal>extend</literal> method each time through the loop. </para>

  
  <para>In <xref linkend="listsum2" /> the data fit a line with slope 2, so the implementation of <literal>sum</literal> is quadratic. <indexterm>
  <primary>quadratic</primary>

</indexterm> </para>

</sect1><sect1 id="pyplot" remap="section">
  <title><literal>pyplot</literal></title>
    
  
  <para> <indexterm>
  <primary sortas="pyplot">pyplot</primary>

</indexterm> <anchor id="a0000000024" /> </para>

  
  <para>To make the figures in this section I used <literal>pyplot</literal>, which is part of <literal>matplotlib</literal>. If <literal>matplotlib</literal> is not part of your Python installation, you might have to install it, or you can use another library to make plots. <indexterm>
  <primary>pyplot</primary>

</indexterm> <indexterm>
  <primary>matplotlib</primary>

</indexterm> </para>

  
  <para>Here’s an example that makes a simple plot: </para>

  
  <programlisting>import matplotlib.pyplot as pyplot

    pyplot.plot(xs, ys)
    scale = 'log'
    pyplot.xscale(scale)
    pyplot.yscale(scale)
    pyplot.title('')
    pyplot.xlabel('n')
    pyplot.ylabel('run time (s)')
    pyplot.show()</programlisting>

  
  <para>The import statement makes <literal>matplotlib.pyplot</literal> accessible with the shorter name <literal>pyplot</literal>. </para>

  
  <para><literal>plot</literal> takes a list of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0063.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>-values and a list of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>-values and plots them. The lists have to have the same length. <literal>xscale</literal> and <literal>yscale</literal> make the axes either linear or logarithmic. </para>

  
  <para><literal>title</literal>, <literal>xlabel</literal> and <literal>ylabel</literal> are self-explanatory. Finally, <literal>show</literal> displays the plot on the screen. You could also use <literal>savefig</literal> to save the plot in a file. </para>

  
  <para>Documentation of <literal>pyplot</literal> is at <ulink url="http://matplotlib.sourceforge.net/">http://matplotlib.sourceforge.net/</ulink>. </para>

  
  

  
  <para>Test the performance of <literal>LinearMap</literal>, <literal>BetterMap</literal> and <literal>HashMap</literal>; see if you can characterize their order of growth. </para>

  
  <para>You can download my map implementations from <ulink url="thinkcomplex.com/Map.py">thinkcomplex.com/Map.py</ulink>, and the code I used in this section from <ulink url="thinkcomplex.com/listsum.py">thinkcomplex.com/listsum.py</ulink>. </para>

  
  <para>You will have to find a range of <literal>n</literal> that is big enough to show asymptotic behavior, but small enough to run quickly. </para>

  
  

</sect1><sect1 id="a0000000025" remap="section">
  <title>List comprehensions</title>
    
  
  <para>One of the most common programming patterns is to traverse a list while building a new list. <indexterm>
  <primary>list comprehension</primary>

</indexterm> <indexterm>
  <primary>traverse list</primary>

</indexterm> </para>

  
  <para>Here is an example that computes the square of each element in a list accumulates the results: </para>

  
  <programlisting>res = []
    for x in t:
        res.append(x**2)</programlisting>

  
  <para>This pattern is so common that Python provides a more concise syntax for it, called a <emphasis role="bold">list comprehension</emphasis>. In this context, the sense of “comprehend” is something like “contain” rather than “understand.” See <ulink url="wikipedia.org/wiki/List_comprehension">wikipedia.org/wiki/List_comprehension</ulink>. </para>

  
  <para>Here’s what it looks like: </para>

  
  <programlisting>res = [x**2 for x in t]</programlisting>

  
  <para>This expression yields the same result as the previous loop. List comprehensions tend to be fast because the loop is executed in C rather than Python. The drawback is that they are harder to debug. </para>

  
  <para>List comprehensions can include an <literal>if</literal> clause that selects a subset of the items. The following example makes a list of the positive elements in <literal>t</literal>: </para>

  
  <programlisting>res = [x for x in t if x &gt; 0]</programlisting>

  
  <para>The following is a common idiom for making a list of tuples, where each tuple is a value and a key from a dictionary: <indexterm>
  <primary>list of tuples</primary>

</indexterm> </para>

  
  <programlisting>res = [(v, k) for k, v in d.iteritems()]</programlisting>

  
  <para>In this case it is safe to use <literal>iteritems</literal>, rather than <literal>items</literal>, because the loop does not modify the dictionary; and it is likely to be faster because it doesn’t have to make a list, just an iterator. <indexterm>
  <primary sortas="iteritems">iteritems</primary>

</indexterm> </para>

  
  <para>It is also possible to nest <literal>for</literal> loops inside a list comprehension. The following example builds a list of Edges between each pair of vertices in <literal>vs</literal>: </para>

  
  <programlisting>edges = [Edge(v, w) for v in vs for w in vs if v is not w]</programlisting>

  
  <para>That’s pretty concise, but complicated comprehensions can be hard to read, so use them sparingly. </para>

  
  

  
  <para>Review the methods your wrote in <literal>Graph.py</literal> and see if any can be rewritten using list comprehensions. <indexterm>
  <primary>graph methods</primary>

</indexterm> </para>

  
  

</sect1>
</chapter><chapter id="a0000000026">
  <title>Small world graphs</title>
  <sect1 id="a0000000027" remap="section">
  <title>Analysis of graph algorithms</title>
    
  
  

  
  <para>The order of growth for a graph algorithm is usually expressed as a function of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0065.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|V|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the number of vertices, and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0066.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|E|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the number of edges. <indexterm>
  <primary>analysis of graph algorithms</primary>

</indexterm> <indexterm>
  <primary>graph algorithm</primary>

</indexterm> </para>

  
  <para>The order of growth for BFS is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0067.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|+ |E|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is a convenient way to say that the run time grows in proportion to either <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0065.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|V|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> or <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0066.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|E|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, whichever is “bigger.” <indexterm>
  <primary>breadth first search</primary>

</indexterm> <indexterm>
  <primary>BFS</primary>

</indexterm> </para>

  
  <para>To see why, think about these four operations: </para>

  
  <para><variablelist>
  <varlistentry>
    <term></term>
      <listitem>
  
  <para>Adding a vertex to the queue: this happens once for each vertex, so the total cost is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0068.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  </varlistentry><varlistentry>
    <term></term>
      <listitem>
  
  <para>Removing a vertex from the queue: this happens once for each vertex, so the total cost is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0068.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  </varlistentry><varlistentry>
    <term></term>
      <listitem>
  
  <para>Marking a vertex “visited”: this happens once for each vertex, so the total cost is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0068.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  </varlistentry><varlistentry>
    <term></term>
      <listitem>
  
  <para>Checking whether a vertex is marked: this happens once each edge, so the total cost is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0069.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|E|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>Adding them up, we get <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0067.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|+ |E|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. If we know the relationship between <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0065.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|V|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0066.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|E|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, we can simplify this expression. For example, in a regular graph, the number of edges is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0068.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> so BFS is linear in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0065.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|V|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. In a complete graph, the number of edges is in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0070.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(|V|^2)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> so BFS is quadratic in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0065.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|V|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>quadratic</primary>

</indexterm> </para>

  
  <para>Of course, this analysis is based on the assumption that all four operations—adding and removing vertices, marking and checking marks—are constant time. <indexterm>
  <primary>constant time</primary>

</indexterm> </para>

  
  <para>Marking vertices is easy. You can add an attribute to the <literal>Vertex</literal> objects or put the marked ones in a set and use the <literal>in</literal> operator. </para>

  
  <para>But making a first-in-first-out (FIFO) queue that can add and remove vertices in constant time turns out to be non-trivial. <indexterm>
  <primary>queue</primary>

</indexterm> </para>

</sect1><sect1 id="a0000000028" remap="section">
  <title>FIFO implementation</title>
    
  
  <para>A FIFO is a data structure that provides the following operations: <indexterm>
  <primary>FIFO queue</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>append:</term>
      <listitem>
  
  <para>Add a new item to the end of the queue. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>pop:</term>
      <listitem>
  
  <para>Remove and return the item at the front of the queue. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>There are several good implementations of this data structure. One is the <emphasis role="bold">doubly-linked list</emphasis>, which you can read about at <ulink url="wikipedia.org/wiki/Doubly-linked_list">wikipedia.org/wiki/Doubly-linked_list</ulink>. Another is a circular buffer, which you can read about at <ulink url="wikipedia.org/wiki/Circular_buffer">wikipedia.org/wiki/Circular_buffer</ulink>. <indexterm>
  <primary>doubly-linked list</primary>

</indexterm> <indexterm>
  <primary>circular buffer</primary>

</indexterm> </para>

  
  

  
  <para>Write an implementation of a FIFO using either a doubly-linked list or a circular buffer. </para>

  
  

  
  <para>Yet another possibility is to use a Python dictionary and two indices: <literal>nextin</literal> keeps track of the back of the queue; <literal>nextout</literal> keeps track of the front. The dictionary maps from integer indices to values. <indexterm>
  <primary>dictionary</primary>

</indexterm> </para>

  
  <para>Here is an implementation based on Raymond Hettinger’s recipe at <ulink url="http://code.activestate.com/recipes/68436/">http://code.activestate.com/recipes/68436/</ulink>. <indexterm>
  <primary sortas="DictFifo">DictFifo</primary>

</indexterm> </para>

  
  <programlisting>class DictFifo(object):

    def __init__(self):
        self.nextin = 0
        self.nextout = 0
        self.data = {}

    def append(self, value):
        self.data[self.nextin] = value
        self.nextin += 1

    def pop(self, n=-1):
        value = self.data.pop(self.nextout)
        self.nextout += 1
        return value</programlisting>

  
  <para><literal>append</literal> stores the new item and increments <literal>nextin</literal>; both operations are constant time. </para>

  
  <para><literal>pop</literal> removes the last item and increments <literal>nextout</literal>. Again, both operations are constant time. </para>

  
  <para>As yet another alternative, the Python <literal>collections</literal> module provides an object called a <literal>deque</literal>, which stands for “double-ended queue”. It is supposed to be pronounced “deck,” but many people say “deek.” A Python deque can be adapted to implement a FIFO. <indexterm>
  <primary>deque</primary>

</indexterm> <indexterm>
  <primary>double-ended queue</primary>

</indexterm> </para>

  
  <para>You can read about deques at <ulink url="wikipedia.org/wiki/Deque">wikipedia.org/wiki/Deque</ulink> and get the details of the Python implementation at <ulink url="docs.python.org/lib/deque-objects.html">docs.python.org/lib/deque-objects.html</ulink>. </para>

  
  

  
  <para>The following implementation of a BFS<footnote><para>This was the implementation at <ulink url="wikipedia.org/wiki/Breadth-first_search">wikipedia.org/wiki/Breadth-first_search</ulink> before I fixed it.</para></footnote> contains two performance errors. What are they? What is the actual order of growth for this algorithm? <indexterm>
  <primary>order of growth</primary>

</indexterm> <indexterm>
  <primary>performance error</primary>

</indexterm> </para>

  
  <programlisting>def bfs(top_node, visit):
    """Breadth-first search on a graph, starting at top_node."""
    visited = set()
    queue = [top_node]
    while len(queue):
        curr_node = queue.pop(0)    # Dequeue
        visit(curr_node)            # Visit the node
        visited.add(curr_node)

        # Enqueue non-visited and non-enqueued children
        queue.extend(c for c in curr_node.children
                     if c not in visited and c not in queue)</programlisting>

  
  <para>Test this code with a range of graph sizes and check your analysis. Then use a FIFO implementation to fix the errors and confirm that your algorithm is linear. </para>

  
  

</sect1><sect1 id="a0000000029" remap="section">
  <title>Stanley Milgram</title>
    
  
  <para>Stanley Milgram was an American social psychologist who conducted two of the most famous experiments in social science, the Milgram experiment, which studied people’s obedience to authority (<ulink url="wikipedia.org/wiki/Milgram_experiment">wikipedia.org/wiki/Milgram_experiment</ulink>) and the Small World Experiment <ulink url="wikipedia.org/wiki/Small_world_phenomenon">wikipedia.org/wiki/Small_world_phenomenon</ulink>, which studied the structure of social networks. <indexterm>
  <primary>Milgram, Stanley</primary>

</indexterm> <indexterm>
  <primary>small world experiment</primary>

</indexterm> <indexterm>
  <primary>Kansas</primary>

</indexterm> <indexterm>
  <primary>Wichita, Kansas</primary>

</indexterm> <indexterm>
  <primary>Massachusetts</primary>

</indexterm> <indexterm>
  <primary>Sharon, Massachusetts</primary>

</indexterm> </para>

  
  <para>In the Small World Experiment, Milgram sent a package to several randomly-chosen people in Wichita, Kansas, with instructions asking them to forward an enclosed letter to a target person, identified by name and occupation, in Sharon, Massachusetts (which is the town near Boston where I grew up). The subjects were told that they could mail the letter directly to the target person only if they knew him personally; otherwise they were instructed to send it, and the same instructions, to a relative or friend they thought would be more likely to know the target person. </para>

  
  <para>Many of the letters were never delivered, but of the ones that were it turned out that the average path length—the number of times the letters were forwarded—was about six. This result was taken to confirm previous observations (and speculations) that the typical distance between any two people in a social network is about “six degrees of separation.” <indexterm>
  <primary>six degrees</primary>

</indexterm> </para>

  
  <para>This conclusion is surprising because most people expect social networks to be localized—people tend to live near their friends—and in a graph with local connections, path lengths tend to increase in proportion to geographical distance. For example, most of my friends live nearby, so I would guess that the average distance between nodes in a social network is about 50 miles. Wichita is about 1600 miles from Boston, so if Milgram’s letters traversed typical links in the social network, they should have taken 32 hops, not six. <indexterm>
  <primary>hop</primary>

</indexterm> <indexterm>
  <primary>social network</primary>

</indexterm> <indexterm>
  <primary>local connection</primary>

</indexterm> </para>

</sect1><sect1 id="a0000000030" remap="section">
  <title>Watts and Strogatz</title>
    
  
  <para>In 1998 Duncan Watts and Steven Strogatz published a paper in <emphasis>Nature</emphasis>, “Collective dynamics of ’small-world’ networks,” that proposed an explanation for the small world phenomenon. <indexterm>
  <primary>Watts, Duncan</primary>

</indexterm> <indexterm>
  <primary>Strogatz, Steven</primary>

</indexterm> <indexterm>
  <primary>small world network</primary>

</indexterm> </para>

  
  <para>Watts and Strogatz started with two kinds of graph that were well understood: random graphs and regular graphs. They looked at two properties of these graphs, clustering and path length. <indexterm>
  <primary>random graph</primary>

</indexterm> <indexterm>
  <primary>regular graph</primary>

</indexterm> <indexterm>
  <primary>clustering</primary>

</indexterm> <indexterm>
  <primary>path length</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term></term>
      <listitem>
  
  <para>Clustering is a measure of the “cliquishness” of the graph. In a graph, a <emphasis role="bold">clique</emphasis> is a subset of nodes that are all connected to each other; in a social network, a clique is a set of friends who all know each other. Watts and Strogatz defined a clustering coefficient that quantifies the likelihood that two nodes that are connected to the same node are also connected to each other. <indexterm>
  <primary>clique</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term></term>
      <listitem>
  
  <para>Path length is a measure of the average distance between two nodes, which corresponds to the degrees of separation in a social network. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>Their initial result was what you might expect: regular graphs have high clustering and high path lengths; random graphs with the same size tend to have low clustering and low path lengths. So neither of these is a good model of social networks, which seem to combine high clustering with short path lengths. </para>

  
  <para>Their goal was to create a <emphasis role="bold">generative model</emphasis> of a social network. A generative model tries to explain a phenomenon by modeling the process that builds or leads to the phenomenon. In this case Watts and Strogatz proposed a process for building small-world graphs: <indexterm>
  <primary>generative model</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Start with a regular graph with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> nodes and degree <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Watts and Strogatz start with a ring lattice, which is a kind of regular graph. You could replicate their experiment or try instead a graph that is regular but not a ring lattice. </para>
</listitem>
  
  <listitem>
  
  <para>Choose a subset of the edges in the graph and “rewire” them by replacing them with random edges. Again, you could replicate the procedure described in the paper or experiment with alternatives. <indexterm>
  <primary>rewire</primary>

</indexterm> </para>
</listitem>
  
</orderedlist></para>

  
  <para>The proportion of edges that are rewired is a parameter, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, that controls how random the graph is. With <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0071.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p=0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the graph is regular; with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0072.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p=1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> it is random. <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  <para>Watts and Strogatz found that small values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> yield graphs with high clustering, like a regular graph, and low path lengths, like a random graph. </para>

  
  

  
  <para>Read the Watts and Strogatz paper and answer the following questions: </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What process do Watts and Strogatz use to rewire their graphs? </para>
</listitem>
  
  <listitem>
  
  <para>What is the definition of the clustering coefficient <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0073.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$C(p)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? <indexterm>
  <primary>clustering coefficient</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What is the definition of the average path length <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0074.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$L(p)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>
</listitem>
  
  <listitem>
  
  <para>What real-world graphs did Watts and Strogatz look at? What evidence do they present that these graphs have the same structure as the graphs generated by their model? </para>
</listitem>
  
</orderedlist></para>

  
  

  
  

  
  <para>Create a file named <literal>SmallWorldGraph.py</literal> and define a class named <literal>SmallWorldGraph</literal> that inherits from <literal>RandomGraph</literal>. </para>

  
  <para>If you did <xref linkend="ex.randomgraph" /> you can use your own <literal>RandomGraph.py</literal>; otherwise you can download mine from <ulink url="thinkcomplex.com/RandomGraph.py">thinkcomplex.com/RandomGraph.py</ulink>. </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Write a method called <literal>rewire</literal> that takes a probability <literal>p</literal> as a parameter and, starting with a regular graph, rewires the graph using Watts and Strogatz’s algorithm. </para>
</listitem>
  
  <listitem>
  
  <para>Write a method called <literal remap="verb">clustering_coefficient</literal> that computes and returns the clustering coefficient as defined in the paper. </para>
</listitem>
  
  <listitem>
  
  <para>Make a graph that replicates the line marked <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0075.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$C(p)/C(0)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in Figure 2 of the paper. In other words, confirm that the clustering coefficient drops off slowly for small values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
</orderedlist></para>

  
  <para>Before we can replicate the other line, we have to learn about shortest path algorithms. </para>

  
  

</sect1><sect1 id="a0000000031" remap="section">
  <title>Dijkstra</title>
    
  
  <para>Edsger W. Dijkstra was a Dutch computer scientist who invented an efficient shortest-path algorithm (see <ulink url="wikipedia.org/wiki/Dijkstra’s_algorithm">wikipedia.org/wiki/Dijkstra’s_algorithm</ulink>). He also invented the semaphore, which is a data structure used to coordinate programs that communicate with each other (see <ulink url="wikipedia.org/wiki/Semaphore_(programming)">wikipedia.org/wiki/Semaphore_(programming)</ulink> and Downey, <emphasis>The Little Book of Semaphores</emphasis>). <indexterm>
  <primary>Dijkstra, Edsger</primary>

</indexterm> <indexterm>
  <primary sortas="Little Book of Semaphores">The Little Book of Semaphores</primary>

</indexterm> </para>

  
  <para>Dijkstra is famous (and notorious) as the author of a series of essays on computer science. Some, like “A Case against the GO TO Statement,” have had a profound effect on programming practice. Others, like “On the Cruelty of Really Teaching Computing Science,” are entertaining in their cantankerousness, but less effective. </para>

  
  <para>Dijkstra’s algorithm solves the “single source shortest path problem,” which means that it finds the minimum distance from a given “source” node to every other node in the graph (or at least every connected node). <indexterm>
  <primary>shortest path</primary>

</indexterm> <indexterm>
  <primary>single source shortest path</primary>

</indexterm> <indexterm>
  <primary>Dijkstra’s algorithm</primary>

</indexterm> </para>

  
  <para>We start with a simplified version of the algorithm that considers all edges the same length. The more general version works with any non-negative edge lengths. </para>

  
  <para>The simplified version is similar to the breadth-first search in <xref linkend="bfs" /> except that instead of marking visited nodes, we label them with their distance from the source. Initially all nodes are labeled with an infinite distance. Like a breadth-first search, Dijkstra’s algorithm uses a queue of discovered unvisited nodes. <indexterm>
  <primary>breadth-first search</primary>

</indexterm> <indexterm>
  <primary>BFS</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Give the source node distance 0 and add it to the queue. Give the other nodes infinite distance. <indexterm>
  <primary>source node</primary>

</indexterm> <indexterm>
  <primary>queue</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>Remove a vertex from the queue and call its distance <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0076.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Find the vertices it is connected to. For each connected vertex with infinite distance, replace the distance with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0077.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d+1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and add it to the queue. </para>
</listitem>
  
  <listitem>
  
  <para>If the queue is not empty, go back to Step 2. </para>
</listitem>
  
</orderedlist></para>

  
  <para>The first time you execute Step 2, the only node in the queue has distance 0. The second time, the queue contains all nodes with distance 1. Once those nodes are processed, the queue contains all nodes with distance 2, and so on. </para>

  
  <para>So when a node is discovered for the first time, it is labeled with the distance <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0077.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d+1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the shortest path to that node. It is not possible that you will discover a shorter path later, because if there were a shorter path, you would have discovered it sooner. That is not a proof of the correctness of the algorithm, but it sketches the structure of the proof by contradiction. <indexterm>
  <primary>labelling nodes</primary>

</indexterm> </para>

  
  <para>In the more general case, where the edges have different lengths, it is possible to discover a shorter path after you have discovered a longer path, so a little more work is needed. </para>

  
  

  
  <para>Write an implementation of Dijkstra’s algorithm and use it to compute the average path length of a SmallWorldGraph. </para>

  
  <para>Make a graph that replicates the line marked <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0078.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$L(p)/L(0)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in Figure 2 of the Watts and Strogatz paper. Confirm that the average path length drops off quickly for small values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. What is the range of values for <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> that yield graphs with high clustering and low path lengths? </para>

  
  

  
  

  
  <para>A natural question about the Watts and Strogatz paper is whether the small world phenomenon is specific to their generative model or whether other similar models yield the same qualitative result (high clustering and low path lengths). <indexterm>
  <primary>small world phenomenon</primary>

</indexterm> </para>

  
  <para>To answer this question, choose a variation of the Watts and Strogatz model and replicate their Figure 2. There are two kinds of variation you might consider: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Instead of starting with a regular graph, start with another graph with high clustering. One option is a locally-connected graph where vertices are placed at random locations in the plane and each vertex is connected to its nearest <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> neighbors. </para>
</listitem>
  
    <listitem>
  
  <para>Experiment with different kinds of rewiring. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>If a range of similar models yield similar behavior, we say that the results of the paper are <emphasis role="bold">robust</emphasis>. <indexterm>
  <primary>robust</primary>

</indexterm> </para>

  
  

  
  

  
  <para>To compute the average path length in a SmallWorldGraph, you probably ran Dijkstra’s single-source shortest path algorithm for each node in the graph. In effect, you solved the “all-pairs shortest path” problem, which finds the shortest path between all pairs of nodes. <indexterm>
  <primary>shortest path</primary>

</indexterm> <indexterm>
  <primary>all pairs shortest path</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Find an algorithm for the all-pairs shortest path problem and implement it. Compare the run time with your “all-source Dijkstra” algorithm. </para>
</listitem>
  
  <listitem>
  
  <para>Which algorithm gives better order-of-growth run time as a function of the number of vertices and edges? Why do you think Dijkstra’s algorithm does better than the order-of-growth analysis suggests? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000032" remap="section">
  <title>What kind of explanation is <emphasis>that</emphasis>?</title>
    
  
  <para>If you ask me why planetary orbits are elliptical, I might start by modeling a planet and a star as point masses; I would look up the law of universal gravitation at <ulink url="wikipedia.org/wiki/Newton’s_law_of_universal_gravitation">wikipedia.org/wiki/Newton’s_law_of_universal_gravitation</ulink> and use it to write a differential equation for the motion of the planet. Then I would either derive the orbit equation or, more likely, look it up at <ulink url="wikipedia.org/wiki/Orbit_equation">wikipedia.org/wiki/Orbit_equation</ulink>. With a little algebra, I could derive the conditions that yield an elliptical orbit. Then I would argue that the objects we consider planets satisfy these conditions. <indexterm>
  <primary>planetary motion</primary>

</indexterm> <indexterm>
  <primary>universal gravitation</primary>

</indexterm> </para>

  
  <para>People, or at least scientists, are generally satisfied with this kind of explanation. One of the reasons for its appeal is that the assumptions and approximations in the model seem reasonable. Planets and stars are not really point masses, but the distances between them are so big that their actual sizes are negligible. Planets in the same solar system can affect each others’ orbits, but the effect is usually small. And we ignore relativistic effects, again on the assumption that they are small. <indexterm>
  <primary>explanatory model</primary>

</indexterm> </para>

  
  <para>This explanation is also appealing because it is equation-based. We can express the orbit equation in a closed form, which means that we can compute orbits efficiently. It also means that we can derive general expressions for the orbital velocity, orbital period, and other quantities. <indexterm>
  <primary>equation-based model</primary>

</indexterm> </para>

  
  <para>Finally, I think this kind of explanation is appealing because it has the form of a mathematical proof. It starts from a set of axioms and derives the result by logic and analysis. But it is important to remember that the proof pertains to the model and not the real world. That is, we can prove that an idealized model of a planet yields an elliptic orbit, but we can’t prove that the model pertains to actual planets (in fact, it does not). <indexterm>
  <primary>mathematical proof</primary>

</indexterm> <indexterm>
  <primary>proof</primary>

</indexterm> </para>

  
  <para>By comparison, Watts and Strogatz’s explanation of the small world phenomenon may seem less satisfying. First, the model is more abstract, which is to say less realistic. Second, the results are generated by simulation, not by mathematical analysis. Finally, the results seem less like a proof and more like an example. <indexterm>
  <primary>abstract model</primary>

</indexterm> </para>

  
  <para>Many of the models in this book are like the Watts and Strogatz model: abstract, simulation-based and (at least superficially) less formal than conventional mathematical models. One of the goals of this book it to consider the questions these models raise: <indexterm>
  <primary>simulation-based model</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>What kind of work can these models do: are they predictive, or explanatory, or both? </para>
</listitem>
  
    <listitem>
  
  <para>Are the explanations these models offer less satisfying than explanations based on more traditional models? Why? </para>
</listitem>
  
    <listitem>
  
  <para>How should we characterize the differences between these and more conventional models? Are they different in kind or only in degree? </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Over the course of the book I will offer my answers to these questions, but they are tentative and sometimes speculative. I encourage you to consider them skeptically and reach your own conclusions. </para>

</sect1>
</chapter><chapter id="a0000000033">
  <title>Scale-free networks</title>
  <sect1 id="a0000000034" remap="section">
  <title>Zipf’s Law</title>
    
  
  <para>Zipf’s law describes a relationship between the frequencies and ranks of words in natural languages; see <ulink url="wikipedia.org/wiki/Zipf’s_law">wikipedia.org/wiki/Zipf’s_law</ulink>. The “frequency” of a word is the number of times it appears in a body of work. The “rank” of a word is its position in a list of words sorted by frequency: the most common word has rank 1, the second most common has rank 2, etc. <indexterm>
  <primary>Zipf’s law</primary>

</indexterm> </para>

  
  <para>Specifically, Zipf’s Law predicts that the frequency, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, of the word with rank <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0079.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$r$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is: <indexterm>
  <primary>frequency</primary>

</indexterm> <indexterm>
  <primary>rank</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000035" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0080.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  f = c r^{-s}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para> where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0081.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0037.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> are parameters that depend on the language and the text. <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  <para>If you take the logarithm of both sides of this equation, you get: </para>

  
  <para><indexterm>
  <primary>logarithm</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000036" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0082.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \log f = \log c - s \log r  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para> So if you plot <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0083.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\log f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0084.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\log r$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, you should get a straight line with slope <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0085.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and intercept <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0086.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\log c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>log-log plot</primary>

</indexterm> </para>

  
  

  
  <para>Write a program that reads a text from a file, counts word frequencies, and prints one line for each word, in descending order of frequency. You can test it by downloading an out-of-copyright book in plain text format from <literal>gutenberg.net</literal>. You might want to remove punctuation from the words. </para>

  
  <para>If you need some help getting started, you can download <ulink url="thinkcomplex.com/Pmf.py">thinkcomplex.com/Pmf.py</ulink>, which provides an object named <literal>Hist</literal> that maps from value to frequencies. <indexterm>
  <primary sortas="Hist">Hist</primary>

</indexterm> </para>

  
  <para>Plot the results and check whether they form a straight line. For plotting suggestions, see <xref linkend="pyplot" />. Can you estimate the value of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0081.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>? </para>

  
  <para>You can download my solution from <ulink url="thinkcomplex.com/Zipf.py">thinkcomplex.com/Zipf.py</ulink> </para>

  
  

</sect1><sect1 id="a0000000037" remap="section">
  <title>Cumulative distributions</title>
    
  
  <para>A distribution is a statistical description of a set of values. For example, if you collect the population of every city and town in the U.S., you would have a set of about 14,000 integers. <indexterm>
  <primary>cumulative distribution</primary>

</indexterm> </para>

  
  <para>The simplest description of this set is a list of numbers, which would be complete but not very informative. A more concise description is a statistical summary like the mean and variation, but that is not a complete description because there are many sets of values with the same summary statistics. <indexterm>
  <primary>summary statistic</primary>

</indexterm> </para>

  
  <para>One alternative is a histogram, which divides the range of possible values into “bins” and counts the number of values that fall in each bin. Histograms are common, so they are easy to understand, but it is tricky to get the bin size right. If the bins are too small, the number of values in each bin is also small, so the histogram doesn’t give much insight. If the bins are too large, they lump together a wide range of values, which obscures details that might be important. <indexterm>
  <primary>histogram</primary>

</indexterm> <indexterm>
  <primary>bin size</primary>

</indexterm> </para>

  
  <para>A better alternative is a <emphasis role="bold">cumulative distribution function</emphasis> (CDF), which maps from a value, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0063.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, to the fraction of values less than or equal to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0063.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. If you choose a value at random, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0087.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$CDF(x)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the probability that the value you get is less than or equal to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0063.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>cumulative distribution function</primary>

</indexterm> <indexterm>
  <primary>CDF</primary>

</indexterm> </para>

  
  <para>For a list of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> values, the simplest way to compute CDF is to sort the values. Then the CDF of the <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0088.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$i$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>th value (starting from 1) is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0089.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$i/n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>I have written a class called <literal>Cdf</literal> that provides functions for creating and manipulating CDFs. You can download it from <ulink url="thinkcomplex.com/Cdf.py">thinkcomplex.com/Cdf.py</ulink>. <indexterm>
  <primary sortas="Cdf">Cdf</primary>

</indexterm> </para>

  
  <para>As an example, we’ll compute the CDF for the values <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0090.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\{ 1,2,2,4,5\} $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>: </para>

  
  <programlisting>import Cdf
cdf = Cdf.MakeCdfFromList([1,2,2,4,5])</programlisting>

  
  <para><literal>MakeCdfFromList</literal> can take any sequence or iterator. Once you have the <literal>Cdf</literal>, you can find the probability, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0087.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$CDF(x)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, for a given value: </para>

  
  <programlisting>prob = cdf.Prob(2)</programlisting>

  
  <para>The result is 0.6, because 3/5 of the values are less than or equal to 2. You can also compute the value for a given probability: </para>

  
  <programlisting>value = cdf.Value(0.5)</programlisting>

  
  <para>The value with probability 0.5 is the median, which in this example is 2. </para>

  
  <para>To plot the <literal>Cdf</literal>, you can use <literal>Render</literal>, which returns a list of value-probability pairs. </para>

  
  <programlisting>xs, ps = cdf.Render()
    for x, p in zip(xs, ps):
        print x, p</programlisting>

  
  <para>The result is: </para>

  
  <programlisting>1 0.0
1 0.2
2 0.2
2 0.6
4 0.6
4 0.8
5 0.8
5 1.0</programlisting>

  
  <para>Each value appear twice. That way when we plot the CDF, we get a stair-step pattern. <indexterm>
  <primary sortas="pyplot">pyplot</primary>

</indexterm> <indexterm>
  <primary>plotting CDFs</primary>

</indexterm> </para>

  
  <programlisting>import matplotlib.pyplot as pyplot

    xs, ps = cdf.Render()

    pyplot.plot(xs, ps, linewidth=3)
    pyplot.axis([0.9, 5.1, 0, 1])
    pyplot.title('CDF')
    pyplot.xlabel('value, x')
    pyplot.ylabel('probability, CDF(x)')
    pyplot.show()</programlisting>

  
  <para>The following figure shows the cumulative distribution function (CDF), for the values <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0091.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$(1,2,2,4,5)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <figure id="a0000000038">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/cdf_example.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>I drew vertical lines at each of the values, which is not mathematically correct. To be more rigorous, I should draw a discontinuous function. </para>

  
  <para> Read the code in <literal>Cdf.py</literal>. What is the order of growth for <literal>MakeCdfFromList</literal> and the methods <literal>Prob</literal> and <literal>Value</literal>? <indexterm>
  <primary>order of growth</primary>

</indexterm>  </para>

</sect1><sect1 id="a0000000039" remap="section">
  <title>Continuous distributions</title>
    
  
  <para>The distributions we have seen so far are sometimes called <emphasis role="bold">empirical distributions</emphasis> because they are based on a dataset that comes from some kind of empirical observation. <indexterm>
  <primary>empirical distribution</primary>

</indexterm> </para>

  
  <para>An alternative is a <emphasis role="bold">continuous distribution</emphasis>, which is characterized by a CDF that is a continuous function. Some of these distributions, like the Gaussian or normal distribution, are well known, at least to people who have studied statistics. Many real world phenomena can be approximated by continuous distributions, which is why they are useful. <indexterm>
  <primary>continuous distribution</primary>

</indexterm> <indexterm>
  <primary>normal distribution</primary>

</indexterm> <indexterm>
  <primary>Gaussian distribution</primary>

</indexterm> </para>

  
  <para>For example, if you observe a mass of radioactive material with an instrument that can detect decay events, the distribution of times between events will most likely fit an exponential distribution. The same is true for any series where an event is equally likely at any time. <indexterm>
  <primary>exponential distribution</primary>

</indexterm> </para>

  
  <para>The CDF of the exponential distribution is: </para>

  
  <para><informalequation id="a0000000040" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0092.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  CDF(x) = 1 - e^{-\lambda x}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>The parameter, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0003.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, determines the mean and variance of the distribution. This equation can be used to derive a simple visual test for whether a dataset can be well approximated by an exponential distribution. All you have to do is plot the <emphasis role="bold">complementary distribution</emphasis> on a log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scale. <indexterm>
  <primary>parameter</primary>

</indexterm> <indexterm>
  <primary>complementary distribution</primary>

</indexterm> </para>

  
  <para>The complementary distribution (CCDF) is just <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0093.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1 - CDF(x)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; if you plot the complementary distribution of a dataset that you think is exponential, you expect to see a function like: </para>

  
  <para><informalequation id="a0000000041" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0094.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  y = 1 - CDF(x) \sim e^{-\lambda x}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>If you take the log of both sides of this equation, you get: </para>

  
  <para><informalequation id="a0000000042" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0095.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \log y \sim -\lambda x  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>So on a log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scale the CCDF should look like a straight line with slope <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0096.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-\lambda $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  

  
  <para>Write a function called <literal remap="verb">plot_ccdf</literal> that takes a list of values and the corresponding list of probabilities and plots the CCDF on a log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scale. </para>

  
  <para>To test your function, use <literal>expovariate</literal> from the <literal>random</literal> module to generate 100 values from an exponential distribution. Plot the CCDF on a log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scale and see if it falls on a straight line. <indexterm>
  <primary sortas="random module">random module</primary>

</indexterm> </para>

  
  

</sect1><sect1 id="a0000000043" remap="section">
  <title>Pareto distributions</title>
    
  
  <para>The Pareto distribution is named after the economist Vilfredo Pareto, who used it to describe the distribution of wealth; see <ulink url="wikipedia.org/wiki/Pareto_distribution">wikipedia.org/wiki/Pareto_distribution</ulink>. Since then, people have used it to describe phenomena in the natural and social sciences including sizes of cities and towns, sand particles and meteorites, forest fires and earthquakes. <indexterm>
  <primary>Pareto distribution</primary>

</indexterm> <indexterm>
  <primary>Pareto, Vilfredo</primary>

</indexterm> </para>

  
  <para>The Pareto distribution is characterized by a CDF with the following form: </para>

  
  <para><informalequation id="a0000000044" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0097.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  1- \left( \frac{x}{x_ m} \right) ^{-\alpha }  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>The parameters <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0098.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ m$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0099.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\alpha $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> determine the location and shape of the distribution. <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0098.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ m$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the minimum possible quantity. <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  <para>Values from a Pareto distribution often have these properties: </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Long tail:</term>
      <listitem>
  
  <para>Pareto distributions contain many small values and a few very large ones. <indexterm>
  <primary>long tail</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>80/20 rule:</term>
      <listitem>
  
  <para>The large values in a Pareto distribution are so large that they make up a disproportionate share of the total. In the context of wealth, the 80/20 rule says that 20% of the people own 80% of the wealth. <indexterm>
  <primary>80/20 rule</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Scale free:</term>
      <listitem>
  
  <para>Short-tailed distributions are centered around a typical size, which is called a “scale.” For example, the great majority of adult humans are between 100 and 200 cm in height, so we could say that the scale of human height is a few hundred centimeters. But for long-tailed distributions, there is no similar range (bounded by a factor of two) that contains the bulk of the distribution. So we say that these distributions are “scale-free.” <indexterm>
  <primary>scale</primary>

</indexterm> <indexterm>
  <primary>scale-free</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>To get a sense of the difference between the Pareto and Gaussian distributions, imagine what the world would be like if the distribution of human height were Pareto. </para>

  
  <para>In Pareto World, the shortest person is 100 cm, and the median is 150 cm, so that part of the distribution is not very different from ours. <indexterm>
  <primary>Pareto World</primary>

</indexterm> </para>

  
  <para>But if you generate 6 billion values from this distribution distribution, the tallest person might be 100 km—that’s what it means to be scale-free! </para>

  
  <para>There is a simple visual test that indicates whether an empirical distribution is well-characterized by a Pareto distribution: on a log-log scale, the CCDF looks like a straight line. The derivation is similar to what we saw in the previous section. </para>

  
  <para>The equation for the CCDF is: </para>

  
  <para><informalequation id="a0000000045" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0100.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  y = 1 - CDF(x) \sim \left( \frac{x}{x_ m} \right) ^{-\alpha }  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Taking the log of both sides yields: </para>

  
  <para><informalequation id="a0000000046" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0101.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \log y \sim -\alpha (\log x - \log x_ m )  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>So if you plot <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0102.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\log y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0103.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\log x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, it should look like a straight line with slope <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0104.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-\alpha $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and intercept <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0105.png" depth="7.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-\alpha \log x_ m$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>log-log plot</primary>

</indexterm> </para>

  
  

  
  <para>Write a version of <literal remap="verb">plot_ccdf</literal> that plots the complementary CCDF on a log-log scale. </para>

  
  <para>To test your function, use <literal>paretovariate</literal> from the <literal>random</literal> module to generate 100 values from an exponential distribution. Plot the CCDF on a log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0064.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$y$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scale and see if it falls on a straight line. What happens to the curve as you increase the number of values? <indexterm>
  <primary sortas="random module">random module</primary>

</indexterm> </para>

  
  

  
  

  
  <para>The distribution of populations for cities and towns has been proposed as an example of a real-world phenomenon that can be described with a Pareto distribution. <indexterm>
  <primary>population</primary>

</indexterm> </para>

  
  <para>The U.S. Census Bureau publishes data on the population of every incorporated city and town in the United States. I wrote a small program that downloads this data and converts it into a convenient form. You can download it from <ulink url="thinkcomplex.com/populations.py">thinkcomplex.com/populations.py</ulink>. <indexterm>
  <primary>U.S. Census Bureau</primary>

</indexterm> </para>

  
  <para>Read over the program to make sure you know what it does and then write a program that computes and plots the distribution of populations for the 14593 cities and towns in the dataset. </para>

  
  <para>Plot the CDF on linear and log-<inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0063.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> scales so you can get a sense of the shape of the distribution. Then plot the CCDF on a log-log scale to see if it has the characteristic shape of a Pareto distribution. </para>

  
  <para>What conclusion do you draw about the distribution of sizes for cities and towns? </para>

  
  

  
  

</sect1><sect1 id="a0000000047" remap="section">
  <title>Barabási and Albert</title>
    
  
  <para>In 1999 Barabási and Albert published a paper in <emphasis>Science</emphasis>, “Emergence of Scaling in Random Networks,” that characterizes the structure (also called “topology”) of several real-world networks, including graphs that represent the interconnectivity of movie actors, world-wide web (WWW) pages, and elements in the electrical power grid in the western United States. <indexterm>
  <primary>topology</primary>

</indexterm> <indexterm>
  <primary>movie actor</primary>

</indexterm> <indexterm>
  <primary>world-wide web</primary>

</indexterm> <indexterm>
  <primary>electrical power grid</primary>

</indexterm> </para>

  
  <para>They measure the degree (number of connections) of each node and compute <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the probability that a vertex has degree <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; then they plot <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> on a log-log scale. The tail of the plot fits a straight line, so they conclude that it obeys a <emphasis role="bold">power law</emphasis>; that is, as <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> gets large, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is asymptotic to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0107.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k^{- \gamma }$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0108.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\gamma $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a parameter that determines the rate of decay. <indexterm>
  <primary>degree</primary>

</indexterm> <indexterm>
  <primary>power law</primary>

</indexterm> </para>

  
  <para>They also propose a model that generates random graphs with the same property. The essential features of the model, which distinguish it from the Erdȍs-Rényi  model and the Watts-Strogatz model, are: <indexterm>
  <primary>generative model</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Growth:</term>
      <listitem>
  
  <para>Instead of starting with a fixed number of vertices, Barabási and Albert start with a small graph and add vertices gradually. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Preferential attachment:</term>
      <listitem>
  
  <para>When a new edge is created, it is more likely to connect to a vertex that already has a large number of edges. This “rich get richer” effect is characteristic of the growth patterns of some real-world networks. <indexterm>
  <primary>preferential attachment</primary>

</indexterm> <indexterm>
  <primary>rich get richer</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>Finally, they show that graphs generated by this model have a distribution of degrees that obeys a power law. Graphs that have this property are sometimes called <emphasis role="bold">scale-free networks</emphasis>; see <ulink url="wikipedia.org/wiki/Scale-free_network">wikipedia.org/wiki/Scale-free_network</ulink>. That name can be confusing because it is the distribution of degrees that is scale-free, not the network. <indexterm>
  <primary>scale-free network</primary>

</indexterm> </para>

  
  <para>In order to maximize confusion, distributions that obey the power law are sometimes called <emphasis role="bold">scaling distributions</emphasis> because they are invariant under a change of scale. That means that if you change the units the quantities are expressed in, the slope parameter, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0108.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\gamma $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, doesn’t change. You can read <ulink url="wikipedia.org/wiki/Power_law">wikipedia.org/wiki/Power_law</ulink> for the details, but it is not important for what we are doing here. <indexterm>
  <primary>scaling distribution</primary>

</indexterm> </para>

  
  

  
  <para>This exercise asks you to make connections between the Watts-Strogatz (WS) and Barabási-Albert (BA) models: <indexterm>
  <primary>Watts-Strogatz model</primary>

</indexterm> <indexterm>
  <primary sortas="Barabasi-Albert model">Barabási-Albert model</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Read Barabási and Albert’s paper and implement their algorithm for generating graphs. See if you can replicate their Figure 2(A), which shows <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> for a graph with 150 000 vertices. </para>
</listitem>
  
  <listitem>
  
  <para>Use the WS model to generate the largest graph you can in a reasonable amount of time. Plot <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and see if you can characterize the tail behavior. </para>
</listitem>
  
  <listitem>
  
  <para>Use the BA model to generate a graph with about 1000 vertices and compute the characteristic length and clustering coefficient as defined in the Watts and Strogatz paper. Do scale-free networks have the characteristics of a small-world graph? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000048" remap="section">
  <title>Zipf, Pareto and power laws</title>
    
  
  <para>At this point we have seen three phenomena that yield a straight line on a log-log plot: <indexterm>
  <primary>log-log plot</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Zipf plot:</term>
      <listitem>
  
  <para>Frequency as a function of rank. <indexterm>
  <primary>Zipf plot</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Pareto CCDF:</term>
      <listitem>
  
  <para>The complementary CDF of a Pareto distribution. <indexterm>
  <primary>complementary CDF</primary>

</indexterm> </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Power law plot:</term>
      <listitem>
  
  <para>A histogram of frequencies. <indexterm>
  <primary>power law</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>The similarity in these plots is not a coincidence; these visual tests are closely related. </para>

  
  <para>Starting with a power-law distribution, we have: </para>

  
  <para><informalequation id="a0000000049" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0109.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  P(k) \sim k^{- \gamma }  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>If we choose a random node in a scale free network, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0106.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the probability that its degree equals <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>degree</primary>

</indexterm> </para>

  
  <para>The cumulative distribution function, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0110.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$CDF(k)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, is the probability that the degree is less than or equal to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, so we can get that by summation: </para>

  
  <para><informalequation id="a0000000050" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0111.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  CDF(k) = \sum _{i=0}^ k P(i)  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>For large values of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> we can approximate the summation with an integral: </para>

  
  <para><informalequation id="a0000000051" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0112.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \sum _{i=0}^ k i^{- \gamma } \sim \int _{i=0}^ k i^{- \gamma } = \frac{1}{\gamma -1} (1 - k^{-\gamma + 1})  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>To make this a proper CDF we could normalize it so that it goes to 1 as <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> goes to infinity, but that’s not necessary, because all we need to know is: </para>

  
  <para><informalequation id="a0000000052" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0113.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  CDF(k) \sim 1 - k^{-\gamma + 1}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Which shows that the distribution of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is asymptotic to a Pareto distribution with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0114.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\alpha = \gamma - 1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Similarly, if we start with a straight line on a Zipf plot, we have<footnote><para>This derivation follows Adamic, “Zipf, power law and Pareto—a ranking tutorial,” available at <ulink url="www.hpl.hp.com/research/idl/papers/ranking/ranking.html">www.hpl.hp.com/research/idl/papers/ranking/ranking.html</ulink></para></footnote> </para>

  
  <para><informalequation id="a0000000053" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0080.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  f = c r^{-s}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the frequency of the word with rank <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0079.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$r$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Inverting this relationship yields: <indexterm>
  <primary>rank</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000054" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0115.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  r = (f/c)^{-{1/s}}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Now subtracting 1 and dividing through by the number of different words, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, we get </para>

  
  <para><informalequation id="a0000000055" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0116.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \frac{r-1}{n} = \frac{(f/c)^{-{1/s}}}{n} - \frac{1}{n}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Which is only interesting because if <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0079.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$r$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the rank of a word, then <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0117.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$(r-1)/n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the fraction of words with lower ranks, which is the fraction of words with higher frequency, which is the CCDF of the distribution of frequencies: </para>

  
  <para><informalequation id="a0000000056" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0118.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  CCDF(x) = \frac{(f/c)^{-{1/s}}}{n} - \frac{1}{n}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>To characterize the asymptotic behavior for large <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> we can ignore <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0037.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0119.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which yields: </para>

  
  <para><informalequation id="a0000000057" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0120.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  CCDF(x) \sim f^{-{1/s}}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Which shows that if a set of words obeys Zipf’s law, the distribution of their frequencies is asymptotic to a Pareto distribution with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0121.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\alpha = 1/s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>So the three visual tests are mathematically equivalent; a dataset that passes one test will pass all three. But as a practical matter, the power law plot is noisier than the other two, because it is the derivative of the CCDF. <indexterm>
  <primary>noise</primary>

</indexterm> </para>

  
  <para>The Zipf and CCDF plots are more robust, but Zipf’s law is only applicable to discrete data (like words), not continuous quantities. CCDF plots work with both. <indexterm>
  <primary>robust</primary>

</indexterm> </para>

  
  <para>For these reasons—robustness and generality—I recommend using CCDFs. </para>

  
  

  
  <para>The Stanford Large Network Dataset Collection is a repository of datasets from a variety of networks, including social networks, communication and collaboration, Internet and road networks. See <ulink url="http://snap.stanford.edu/data/index.html">http://snap.stanford.edu/data/index.html</ulink>. <indexterm>
  <primary>Stanford Large Network Dataset Collection</primary>

</indexterm> </para>

  
  <para>Download one of these datasets and explore. Is there evidence of small-world behavior? Is the network scale-free? What else can you discover? </para>

  
  

</sect1><sect1 id="a0000000058" remap="section">
  <title>Explanatory models</title>
    
  
  <para>We started the discussion of networks with Milgram’s Small World Experiment, which shows that path lengths in social networks are surprisingly small; hence, “six degrees of separation”. <indexterm>
  <primary>six degrees</primary>

</indexterm> </para>

  
  <para>When we see something surprising, it is natural to ask “Why?” but sometimes it’s not clear what kind of answer we are looking for. One kind of answer is an <emphasis role="bold">explanatory model</emphasis>; the logical structure of an explanatory model is: <indexterm>
  <primary>explanatory model</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>In a system, S, we see something observable, O, that warrants explanation. <indexterm>
  <primary>system</primary>

</indexterm> <indexterm>
  <primary>observable</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>We construct a model, M, that is analogous to the system; that is, there is a correspondence between the elements of the model and the elements of the system. <indexterm>
  <primary>model</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>By simulation or mathematical derivation, we show that the model exhibits a behavior, B, that is analogous to O. <indexterm>
  <primary>behavior</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>We conclude that S exhibits O <emphasis>because</emphasis> S is similar to M, M exhibits B, and B is similar to O. </para>
</listitem>
  
</orderedlist></para>

  
  <para>At its core, this is an argument by analogy, which says that if two things are similar in some ways, they are likely to be similar in other ways. <indexterm>
  <primary>analogy</primary>

</indexterm> <indexterm>
  <primary>argument by analogy</primary>

</indexterm> </para>

  
  <para>Argument by analogy can be useful, and explanatory models can be satisfying, but they do not constitute a proof in the mathematical sense of the word. <indexterm>
  <primary>proof</primary>

</indexterm> <indexterm>
  <primary>mathematical proof</primary>

</indexterm> </para>

  
  <para>First, remember that all models leave out, or “abstract away” details that we think are unimportant. But for any system there are many possible models that include or ignore different features. And there might be models that exhibit different behaviors, B, B’ and B”, that are similar to O in different ways. <indexterm>
  <primary>abstract model</primary>

</indexterm> </para>

  
  <para>In that case, which model explains O? </para>

  
  <para>The small world phenomenon is a case in point: the Watts-Strogatz (WS) model and the Barabási-Albert (BA) model both exhibit small world behavior, but they offer different explanations: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>The WS model suggests that social networks are “small” because they include both strongly-connected clusters and “weak ties” that connect clusters<footnote><para>See <ulink url="http://en.wikipedia.org/wiki/Mark_Granovetter">http://en.wikipedia.org/wiki/Mark_Granovetter</ulink>.</para></footnote>. <indexterm>
  <primary>weak ties</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>The BA model suggests that social networks are small because they include nodes with high degree that act as hubs, and that hubs grow, over time, due to preferential attachment. <indexterm>
  <primary>preferential attachment</primary>

</indexterm> </para>
</listitem>
  
</itemizedlist></para>

  
  <para>As is often the case in young areas of science, the problem is not that we have no explanations, but too many. </para>

  
  

  
  <para>Are these explanations compatible; that is, can they both be right? </para>

  
  <para>Which do you find more satisfying as an explanation, and why? </para>

  
  <para>Is there data you could collect, or experiments you could perform, that would provide evidence in favor of one model over the other? </para>

  
  <para>Choosing among competing models is the topic of Thomas Kuhn’s essay, “Objectivity, Value Judgment, and Theory Choice.” Kuhn was a historian of science who wrote <emphasis>The Structure of Scientific Revolutions</emphasis> in 1962, and spent the rest of his life explaining what he meant to say. <indexterm>
  <primary>Kuhn, Thomas</primary>

</indexterm> <indexterm>
  <primary sortas="Structure of Scientific Revolutions">The Structure of Scientific Revolutions</primary>

</indexterm> <indexterm>
  <primary>theory choice</primary>

</indexterm> <indexterm>
  <primary>objectivity</primary>

</indexterm> </para>

  
  <para>What criteria does Kuhn propose for choosing among competing models? Do these criteria influence your opinion about the WS and BA models? Are there other criteria you think should be considered? </para>

  
  

</sect1>
</chapter><chapter id="a0000000059">
  <title>Cellular Automata</title>
  
  
  <para>A cellular automaton is a model of a world with very simple physics. “Cellular” means that the space is divided into discrete chunks, called cells. An “automaton” is a machine that performs computations—it could be a real machine, but more often the “machine” is a mathematical abstraction or a computer simulation. <indexterm>
  <primary>cellular automaton</primary>

</indexterm> </para>

  
  <para>Automata are governed by rules that determine how the system evolves in time. Time is divided into discrete steps, and the rules specify how to compute the state of the world during the next time step based on the current state. <indexterm>
  <primary>time step</primary>

</indexterm> </para>

  
  <para>As a trivial example, consider a cellular automaton (CA) with a single cell. The state of the cell is an integer represented with the variable <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0122.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ i$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, where the subscript <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0088.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$i$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> indicates that <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0122.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ i$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the state of the system during timestep <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0088.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$i$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. As an initial condition, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0123.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_0 = 0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>state</primary>

</indexterm> </para>

  
  <para>Now all we need is a rule. Arbitrarily, I’ll pick <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0124.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ i = x_{i-1} + 1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which says that after each time step, the state of the CA gets incremented by 1. So far, we have a simple CA that performs a simple calculation: it counts. <indexterm>
  <primary>rule</primary>

</indexterm> </para>

  
  <para>But this CA is atypical; normally the number of possible states is finite. To bring it into line, I’ll choose the smallest interesting number of states, 2, and another simple rule, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0125.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$x_ i = (x_{i-1} + 1) \%  2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0126.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\% $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the remainder (or modulus) operator. </para>

  
  <para>This CA performs a simple calculation: it blinks. That is, the state of the cell switches between 0 and 1 after every timestep. </para>

  
  <para>Most CAs are <emphasis role="bold">deterministic</emphasis>, which means that rules do not have any random elements; given the same initial state, they always produce the same result. There are also nondeterministic CAs, but I will not address them here. <indexterm>
  <primary>deterministic</primary>

</indexterm> </para>
<sect1 id="a0000000060" remap="section">
  <title>Stephen Wolfram</title>
    
  
  <para>The CA in the previous section was 0-dimensional and it wasn’t very interesting. But 1-dimensional CAs turn out to be surprisingly interesting. <indexterm>
  <primary>Wolfram, Stephen</primary>

</indexterm> <indexterm>
  <primary>1-D cellular automaton</primary>

</indexterm> </para>

  
  <para>In the early 1980s Stephen Wolfram published a series of papers presenting a systematic study of 1-dimensional CAs. He identified four general categories of behavior, each more interesting than the last. </para>

  
  <para>To say that a CA has dimensions is to say that the cells are arranged in a contiguous space so that some of them are considered “neighbors.” In one dimension, there are three natural configurations: <indexterm>
  <primary>neighbor</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Finite sequence:</term>
      <listitem>
  
  <para>A finite number of cells arranged in a row. All cells except the first and last have two neighbors. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Ring:</term>
      <listitem>
  
  <para>A finite number of cells arranged in a ring. All cells have two neighbors. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Infinite sequence:</term>
      <listitem>
  
  <para>An infinite number of cells arranged in a row. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>The rules that determine how the system evolves in time are based on the notion of a “neighborhood,” which is the set of cells that determines the next state of a given cell. Wolfram’s experiments use a 3-cell neighborhood: the cell itself and its left and right neighbors. <indexterm>
  <primary>neighborhoos</primary>

</indexterm> </para>

  
  <para>In these experiments, the cells have two states, denoted 0 and 1, so the rules can be summarized by a table that maps from the state of the neighborhood (a tuple of 3 states) to the next state for the center cell. The following table shows an example: <indexterm>
  <primary>rule table</primary>

</indexterm> <indexterm>
  <primary>state</primary>

</indexterm> </para>

  
  <para> 
   
   
     <informaltable remap="tabular">
     <tr>
     
       
       <td>
  
  <para> prev </para>
</td>
     
       
       <td>
  
  <para> 111 </para>
</td>
     
       
       <td>
  
  <para> 110 </para>
</td>
     
       
       <td>
  
  <para> 101 </para>
</td>
     
       
       <td>
  
  <para> 100 </para>
</td>
     
       
       <td>
  
  <para> 011 </para>
</td>
     
       
       <td>
  
  <para> 010 </para>
</td>
     
       
       <td>
  
  <para> 001 </para>
</td>
     
       
       <td>
  
  <para> 000 </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>next </para>
</td>
     
       
       <td>
  
  <para> 0 </para>
</td>
     
       
       <td>
  
  <para> 0 </para>
</td>
     
       
       <td>
  
  <para> 1 </para>
</td>
     
       
       <td>
  
  <para> 1 </para>
</td>
     
       
       <td>
  
  <para> 0 </para>
</td>
     
       
       <td>
  
  <para> 0 </para>
</td>
     
       
       <td>
  
  <para> 1 </para>
</td>
     
       
       <td>
  
  <para> 0 </para>
</td>
     
     </tr>
     </informaltable>
   
 </para>

  
  <para>The row first shows the eight states a neighborhood can be in. The second row shows the state of the center cell during the next timestep. As a concise encoding of this table, Wolfram suggested reading the bottom row as a binary number. Because 00110010 in binary is 50 in decimal, Wolfram calls this CA “Rule 50.” <indexterm>
  <primary>enumeration</primary>

</indexterm> </para>

  
  <para>The following figure shows the effect of Rule 50 over 10 time steps: </para>

  
  <figure id="a0000000061">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-50-10.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>The first row shows the state of the system during the first timestep; it starts with one cell “on” and the rest “off”. The second row shows the state of the system during the next time step, and so on. </para>

  
  <para>The triangular shape in the figure is typical of these CAs; is it a consequence of the shape of the neighborhood. In one time step, each cell influences the state of one neighbor in either direction. During the next time step, that influence can propagate one more cell in each direction. So each cell in the past has a “triangle of influence” that includes all of the cells that can be affected by it. <indexterm>
  <primary>triangle of influence</primary>

</indexterm> </para>

</sect1><sect1 id="a0000000062" remap="section">
  <title>Implementing CAs</title>
    
  
  <para>To generate the previous figure, I wrote a Python program that implements and draws CAs. You can download my code from <ulink url="thinkcomplex.com/CA.py">thinkcomplex.com/CA.py</ulink>. and <ulink url="thinkcomplex.com/CADrawer.py">thinkcomplex.com/CADrawer.py</ulink>. <indexterm>
  <primary>implementing cellular automata</primary>

</indexterm> </para>

  
  <para>To store the state of the CA, I use a NumPy array. An array is a multi-dimensional data structure whose elements are all the same type. It is similar to a nested list, but usually smaller and faster. The following figure shows why: <indexterm>
  <primary>NumPy</primary>

</indexterm> <indexterm>
  <primary>array</primary>

</indexterm> <indexterm>
  <primary>nested list</primary>

</indexterm> </para>

  
  <figure id="a0000000063">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/array.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>The diagram on the left shows a list of lists of integers; each dot represents a reference, which takes up 4–8 bytes. To access one of the integers, you have to follow two references. <indexterm>
  <primary>reference</primary>

</indexterm> </para>

  
  <para>The diagram on the right shows an array of the same integers. Because the elements are all the same size, they can be stored contiguously in memory. This arrangement saves space because it doesn’t use references, and it saves time because the location of an element can be computed directly from the indices; there is no need to follow a series of references. </para>

  
  <para>Here is a CA object that uses a NumPy array: <indexterm>
  <primary sortas="CA">CA</primary>

</indexterm> </para>

  
  <programlisting>import numpy

class CA(object):

    def __init__(self, rule, n=100, ratio=2):
        self.table = make_table(rule)
        self.n = n
        self.m = ratio*n + 1
        self.array = numpy.zeros((n, self.m), dtype=numpy.int8)
        self.next = 0</programlisting>

  
  <para><literal>rule</literal> is an integer in the range 0-255, which represents the CA rule table using Wolfram’s encoding. <literal remap="verb">make_table</literal> converts the rule to a dictionary that maps from neighborhood states to cell states. For example, in Rule 50 the table contains a map from <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0127.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$(1,1,1)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to 0. </para>

  
  <para><literal>n</literal> is the number of rows in the array, which is the number of timesteps we will compute. <literal>m</literal> is the number of columns, which is the number of cells. At least to get started, we implement a finite array of cells. </para>

  
  <para><literal>zeros</literal> is provided by NumPy; it creates a new array with the given dimensions, <literal>n</literal> by <literal>m</literal>; <literal>dtype</literal> stands for “data type,” and is specifies the type of the array elements. <literal>int8</literal> is an 8-bit integer, so we are limited to 256 states, but that’s no problem: we only need two. <indexterm>
  <primary sortas="zeros">zeros</primary>

</indexterm> </para>

  
  <para><literal>next</literal> is the index of the next timestep. </para>

  
  <para>There are two common starting conditions for CAs: a single cell, or a row of random cells. <literal remap="verb">start_single</literal> initializes the first row with a single cell and increments <literal>next</literal>: </para>

  
  <programlisting>def start_single(self):
        """Starts with one cell in the middle of the top row."""
        self.array[0, self.m/2] = 1
        self.next += 1</programlisting>

  
  <para> Array indexing is similar to list and dictionary indexing. Array indexing is similar to list indexing. <indexterm>
  <primary>array indexing</primary>

</indexterm> </para>

  
  <para><literal>step</literal> computes the next state of the CA: </para>

  
  <programlisting>def step(self):
        i = self.next
        self.next += 1

        a = self.array
        t = self.table
        for j in xrange(1,self.m-1):
            a[i,j] = t[tuple(a[i-1, j-1:j+2])]</programlisting>

  
  <para><literal>i</literal> is the timestep and the index of the row we are about to compute. <literal>j</literal> loops through the cells, skipping the first and last, which are always off. </para>

  
  <para>Arrays support slice operations, so <literal>self.array[i-1, j-1:j+2]</literal> gets three elements from row <literal>i-1</literal>. Then we look up the neighborhood tuple in the table, get the next state, and store it in the array. <indexterm>
  <primary>array slice</primary>

</indexterm> </para>

  
  <para>Array indexing is constant time, so <literal>step</literal> is linear in <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Filling in the whole array is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0128.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$O(nm)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <indexterm>
  <primary>order of growth</primary>

</indexterm> </para>

  
  <para>You can read more about NumPy and arrays at <ulink url="scipy.org/Tentative_NumPy_Tutorial">scipy.org/Tentative_NumPy_Tutorial</ulink>. </para>

</sect1><sect1 id="a0000000064" remap="section">
  <title>CADrawer</title>
    
  
  <para>An <emphasis role="bold">abstract class</emphasis> is a class definition that specifies the interface for a set of methods without providing an implementation. Child classes extend the abstract class and implement the incomplete methods. See <ulink url="http://en.wikipedia.org/wiki/Abstract_type">http://en.wikipedia.org/wiki/Abstract_type</ulink>. <indexterm>
  <primary>abstract class</primary>

</indexterm> </para>

  
  <para>As an example, I present an abstract class, <literal>CADrawer</literal>, that defines an interface for drawing CAs, and child classes that implement this interface. <indexterm>
  <primary>implement</primary>

</indexterm> <indexterm>
  <primary>interface</primary>

</indexterm> </para>

  
  <para>Here’s the definition for <literal>CADrawer</literal>: <indexterm>
  <primary sortas="CADrawer">CADrawer</primary>

</indexterm> </para>

  
  <programlisting>class Drawer(object):
    """Drawer is an abstract class that should not be instantiated.
    It defines the interface for a CA drawer; child classes of Drawer
    should implement draw, show and save.

    If draw_array is not overridden, the child class should provide
    draw_cell.
    """
    def __init__(self):
        msg = 'CADrawer is an abstract type and should not be instantiated.'
        raise UnimplementedMethodException, msg

    def draw(self, ca):
        """Draws a representation of cellular automaton (CA).
        This function generally has no visible effect."""
        raise UnimplementedMethodException

    def draw_array(self, a):
        """Iterate through array (a) and draws any non-zero cells."""
        for i in xrange(self.rows):
            for j in xrange(self.cols):
                if a[i,j]:
                    self.draw_cell(j, self.rows-i-1)

    def draw_cell(self, ca):
        """Draws a single cell.
        Not required for all implementations."""
        raise UnimplementedMethodException

    def show(self):
        """Displays the representation on the screen, if possible."""
        raise UnimplementedMethodException

    def save(self, filename):
        """Saves the representation of the CA in filename."""
        raise UnimplementedMethodException</programlisting>

  
  <para>Abstract classes should not be instantiated; if you try, you get an <literal>UnimplementedMethodException</literal>, which is a simple extension of <literal>Exception</literal>: <indexterm>
  <primary sortas="UnimplementedMethodException">UnimplementedMethodException</primary>

</indexterm> </para>

  
  <programlisting>class UnimplementedMethodException(Exception):
    """Used to indicate that a child class has not implemented an
    abstract method."""</programlisting>

  
  <para>To instantiate a <literal>CADrawer</literal> you have to define a child class that implements the methods, then instantiate the child. <indexterm>
  <primary>instantiate</primary>

</indexterm> </para>

  
  <para><literal>CADrawer.py</literal> provides three implementations, one that uses <literal>pyplot</literal>, one that uses the Python Imaging Library (PIL), and one that generates Encapsulated Postscript (EPS). <indexterm>
  <primary>pyplot</primary>

</indexterm> <indexterm>
  <primary>Python Imaging Library</primary>

</indexterm> <indexterm>
  <primary>PIL</primary>

</indexterm> <indexterm>
  <primary>Postscript</primary>

</indexterm> <indexterm>
  <primary>EPS</primary>

</indexterm> </para>

  
  <para>Here is an example that uses <literal>PyplotDrawer</literal> to display a CA on the screen: </para>

  
  <programlisting>ca = CA(rule, n)
    ca.start_single()
    ca.loop(n-1)

    drawer = CADrawer.PyplotDrawer()
    drawer.draw(ca)
    drawer.show()</programlisting>

  
  

  
  <para>Download <ulink url="thinkcomplex.com/CA.py">thinkcomplex.com/CA.py</ulink> and <ulink url="thinkcomplex.com/CADrawer.py">thinkcomplex.com/CADrawer.py</ulink> and confirm that they run on your system; you might have to install additional Python packages. </para>

  
  <para>Create a new class called <literal>CircularCA</literal> that extends <literal>CA</literal> so that the cells are arranged in a ring. <indexterm>
  <primary>CircularCA</primary>

</indexterm> </para>

  
  <para>Hint: you might find it useful to add a column of “ghost cells” to the array. <indexterm>
  <primary>ghost cells</primary>

</indexterm> </para>

  
  <para>You can download my solution from <ulink url="thinkcomplex.com/CircularCA.py">thinkcomplex.com/CircularCA.py</ulink> </para>

  
  

</sect1><sect1 id="a0000000065" remap="section">
  <title>Classifying CAs</title>
    
  
  <para>Wolfram proposes that the behavior of CAs can be grouped into four classes. Class 1 contains the simplest (and least interesting) CAs, the ones that evolve from almost any starting condition to the same uniform pattern. As a trivial example, Rule 0 always generates an empty pattern after one time step. <indexterm>
  <primary>classifying cellular automata</primary>

</indexterm> </para>

  
  <para>Rule 50 is an example of Class 2. It generates a simple pattern with nested structure; that is, the pattern contains many smaller versions of itself. Rule 18 makes the nested structure even clearer; here is what it looks like after 64 steps: </para>

  
  <figure id="a0000000066">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-18-64.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>This pattern resembles the Sierpiński triangle, which you can read about at <ulink url="wikipedia.org/wiki/Sierpinski_triangle">wikipedia.org/wiki/Sierpinski_triangle</ulink>. <indexterm>
  <primary>Sierpiński triangle</primary>

</indexterm> </para>

  
  <para>Some Class 2 CAs generate patterns that are intricate and aesthetic, but compared to Classes 3 and 4, they are relatively simple. </para>

</sect1><sect1 id="a0000000067" remap="section">
  <title>Randomness</title>
    
  
  <para>Class 3 is a pattern that generate randomness. Rule 30 is an example; here is what it looks like after 100 timesteps: <indexterm>
  <primary>randomness</primary>

</indexterm> <indexterm>
  <primary>Class 3 behavior</primary>

</indexterm> <indexterm>
  <primary>Rule 30</primary>

</indexterm> </para>

  
  <figure id="a0000000068">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-30-100.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>Along the left side there is an apparent pattern, and on the right side there are triangles in various sizes, but the center seems quite random. In fact, if you take the center column and treat it as a sequence of bits, it is hard to distinguish from a truly random sequence. It passes many of the statistical tests people use to test whether a sequence of bits is random. </para>

  
  <para>Programs that produce random-seeming numbers are called <emphasis role="bold">pseudo-random number generators</emphasis> (PRNGs). They are not considered truly random because <indexterm>
  <primary>pseudo-random number generator</primary>

</indexterm> <indexterm>
  <primary>PRNG</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Many of them produce sequences with regularities that can be detected statistically. For example, the original implementation of <literal>rand</literal> in the C library used a linear congruential generator that yielded sequences with easily detectable serial correlations. <indexterm>
  <primary>linear congruential generator</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Any PRNG that uses a finite amount of state (that is, storage) will eventually repeat itself. One of the characteristics of a generator is the <emphasis role="bold">period</emphasis> of this repetition. <indexterm>
  <primary>period</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>The underlying process is fundamentally deterministic, unlike some physical processes, like radioactive decay and thermal noise, that are considered to be fundamentally random. <indexterm>
  <primary>deterministic</primary>

</indexterm> </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Modern PRNGs produce sequences that are statistically indistinguishable from random, and they can be implemented with with periods so long that the universe will collapse before they repeat. The existence of these generators raises the question of whether there is any real difference between a good quality pseudo-random sequence and a sequence generated by a “truly” random process. In <emphasis>A New Kind of Science</emphasis>, Wolfram argues that there is not (pages 315–326). <indexterm>
  <primary sortas="New Kind of Science">A New Kind of Science</primary>

</indexterm> </para>

  
  

  
  <para>This exercise asks you to implement and test several PRNGs. </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Write a program that implements one of the linear congruential generators described at <ulink url="wikipedia.org/wiki/Linear_congruential_generator">wikipedia.org/wiki/Linear_congruential_generator</ulink>). </para>
</listitem>
  
  <listitem>
  
  <para>Download <literal>DieHarder</literal>, a random number test suite, from <ulink url="phy.duke.edu/~rgb/General/rand_rate.php">phy.duke.edu/~rgb/General/rand_rate.php</ulink> and use it to test your PRNG. How does it do? <indexterm>
  <primary>DieHarder</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>Read the documentation of Python’s <literal>random</literal> module. What PRNG does it use? Test it using DieHarder. <indexterm>
  <primary sortas="random module">random module</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>Implement a Rule 30 CA on a ring with a few hundred cells, run it for as many time steps as you can in a reasonable amount of time, and output the center column as a sequence of bits. Test it using DieHarder. <indexterm>
  <primary>Rule 30</primary>

</indexterm> </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000069" remap="section">
  <title>Determinism</title>
    
  
  <para>The existence of Class 3 CAs is surprising. To understand how surprising, it is useful to consider the philosophical stance called <emphasis role="bold">determinism</emphasis> (see <ulink url="wikipedia.org/wiki/Determinism">wikipedia.org/wiki/Determinism</ulink>). Most philosophical stances are hard to define precisely because they come in a variety of flavors. I often find it useful to define them with a list of statements ordered from weak to strong: <indexterm>
  <primary>determinism</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>D1:</term>
      <listitem>
  
  <para>Deterministic models can make accurate predictions for some physical systems. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>D2:</term>
      <listitem>
  
  <para>Many physical systems can be modeled by deterministic processes, but some are intrinsically random. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>D3:</term>
      <listitem>
  
  <para>All events are caused by prior events, but many physical systems are nevertheless fundamentally unpredictable. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>D4:</term>
      <listitem>
  
  <para>All events are caused by prior events, and can (at least in principle) be predicted. <indexterm>
  <primary>causation</primary>

</indexterm> </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>My goal in constructing this range is to make D1 so weak that virtually everyone would accept it, D4 so strong that almost no one would accept it, with intermediate statements that some people accept. </para>

  
  <para>The center of mass of world opinion swings along this range in response to historical developments and scientific discoveries. Prior to the scientific revolution, many people regarded the working of the universe as fundamentally unpredictable or controlled by supernatural forces. After the triumphs of Newtonian mechanics, some optimists came to believe something like D4; for example, in 1814 Pierre-Simon Laplace wrote <indexterm>
  <primary>Newtonian mechanics</primary>

</indexterm> <indexterm>
  <primary>Laplace, Pierre-Simon</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> We may regard the present state of the universe as the effect of its past and the cause of its future. An intellect which at a certain moment would know all forces that set nature in motion, and all positions of all items of which nature is composed, if this intellect were also vast enough to submit these data to analysis, it would embrace in a single formula the movements of the greatest bodies of the universe and those of the tiniest atom; for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes. </para>
</blockquote>

  
  <para>This “intellect” came to be called “Laplace’s Demon”. See <ulink url="wikipedia.org/wiki/Laplace’s_demon">wikipedia.org/wiki/Laplace’s_demon</ulink>. The word “demon” in this context has the sense of “spirit,” with no implication of evil. <indexterm>
  <primary>Laplace’s Demon</primary>

</indexterm> </para>

  
  <para>Discoveries in the 19th and 20th centuries gradually dismantled this hope. The thermodynamic concept of entropy, radioactive decay, and quantum mechanics posed successive challenges to strong forms of determinism. <indexterm>
  <primary>entropy</primary>

</indexterm> <indexterm>
  <primary>radioactive decay</primary>

</indexterm> <indexterm>
  <primary>quantum mechanics</primary>

</indexterm> </para>

  
  <para>In the 1960s chaos theory showed that in some deterministic systems prediction is only possible over short time scales, limited by the precision of measurement of initial conditions. <indexterm>
  <primary>chaos</primary>

</indexterm> </para>

  
  <para>Most of these systems were continuous in space (if not time) and nonlinear, so the complexity of their behavior was not entirely surprising. Wolfram’s demonstration of complex behavior in simple cellular automata is more surprising—and disturbing, at least to a deterministic world view. <indexterm>
  <primary>complex behavior</primary>

</indexterm> <indexterm>
  <primary>simple rules</primary>

</indexterm> </para>

  
  <para>So far I have focused on scientific challenges to determinism, but the longest-standing objection is the conflict between determinism and human free will. Complexity science provides an approach that may resolve this apparent conflict, but I will stop there for now. <indexterm>
  <primary>free will</primary>

</indexterm> </para>

</sect1><sect1 id="a0000000070" remap="section">
  <title>Structures</title>
    
  
  <para>The behavior of Class 4 CAs is even more surprising. Several 1-D CAs, most notably Rule 110, are <emphasis role="bold">Turing complete</emphasis>, which means that they can compute any computable function. This property, also called <emphasis role="bold">universality</emphasis>, was proved by Matthew Cook in 1998. See <ulink url="http://en.wikipedia.org/wiki/Rule_110">http://en.wikipedia.org/wiki/Rule_110</ulink>. <indexterm>
  <primary>Turing complete</primary>

</indexterm> <indexterm>
  <primary>universality</primary>

</indexterm> <indexterm>
  <primary>Cook, Matthew</primary>

</indexterm> </para>

  
  <para>Here is a what Rule 110 looks like with an initial condition of a single cell and 100 timesteps: <indexterm>
  <primary>Rule 110</primary>

</indexterm> </para>

  
  <figure id="a0000000071">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-110-100.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>At this time scale it is not apparent that anything special is going on. There are some regular patterns but also some features that are hard to characterize. </para>

  
  <para><xref linkend="rule110" /> shows a bigger picture, starting with a random initial condition and 600 timesteps: </para>

  
  <figure id="rule110">
  
  <title>Rule 110 with random initial conditions and 600 timesteps.<anchor id="a0000000072" /></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-110-600-random.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>After about 100 steps the background settles into a simple repeating pattern, but there are a number of persistent structures that appear as disturbances in the background. Some of these structures are stable, so they appear as vertical lines. Others translate in space, appearing as diagonals with different slopes, depending on how many time steps they take to shift by one column. These structures are sometimes called <emphasis role="bold">spaceships</emphasis>. <indexterm>
  <primary>spaceships</primary>

</indexterm> </para>

  
  <para>Collisions between spaceships yield different results depending on the types of the spaceships and the phase they are in when they collide. Some collisions annihilate both ships; others leave one ship unchanged; still others yield one or more ships of different types. </para>

  
  <para>These collisions are the basis of computation in a Rule 110 CA. If you think of spaceships as signals that propagate on wires, and collisions as gates that compute logical operations like AND and OR, you can see what it means for a CA to perform a computation. </para>

  
  

  
  <para>This exercise asks you to experiment with Rule 110 and see how many spaceships you can find. </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Modify your program from the previous exercises so it starts with an initial condition that yields the stable background pattern. </para>
</listitem>
  
  <listitem>
  
  <para>Modify the initial condition by adding different patterns in the center of the row and see which ones yield spaceships. You might want to enumerate all possible patterns of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> bits, for some reasonable value of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. For each spaceship, can you find the period and rate of translation? What is the biggest spaceship you can find? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000073" remap="section">
  <title>Universality</title>
    
  
  <para>To understand universality, we have to understand computability theory, which is about models of computation and what they compute. <indexterm>
  <primary>universality</primary>

</indexterm> </para>

  
  <para>One of the most general models of computation is the Turing machine, which is an abstract computer proposed by Alan Turing in 1936. A Turing machine is a 1-D CA, infinite in both directions, augmented with a read-write head. At any time, the head is positioned over a single cell. It can read the state of that cell (usually there are only two states) and it can write a new value into the cell. <indexterm>
  <primary>Turing machine</primary>

</indexterm> <indexterm>
  <primary>Turing, Alan</primary>

</indexterm> </para>

  
  <para>In addition, the machine has a register, which records which of a finite number of states the machine is in, and a table of rules. For each machine state and cell state, the table specifies an action. Actions include modifying the cell the head is over and moving one cell to the left or right. <indexterm>
  <primary>register</primary>

</indexterm> <indexterm>
  <primary>tape</primary>

</indexterm> <indexterm>
  <primary>read/write head</primary>

</indexterm> <indexterm>
  <primary>cell</primary>

</indexterm> </para>

  
  <para>A Turing machine is not a practical design for a computer, but it models common computer architectures. For a given program running on a real computer, it is possible (at least in principle) to construct a Turing machine that performs an equivalent computation. </para>

  
  <para>The Turing machine is useful because it is possible to characterize the set of functions that can be computed by a Turing machine, which is what Turing did. Functions in this set are called Turing computable. <indexterm>
  <primary>computable function</primary>

</indexterm> </para>

  
  <para>To say that a Turing machine can compute any Turing-computable function is a <emphasis role="bold">tautology</emphasis>: it true by definition. But Turing-computability is more interesting than that. <indexterm>
  <primary>tautology</primary>

</indexterm> </para>

  
  <para>It turns out that just about every reasonable model of computation anyone has come up with is Turing complete; that is, it can compute exactly the same set of functions as the Turing machine. Some of these models, like lamdba calculus, are very different from a Turing machine, so their equivalence is surprising. <indexterm>
  <primary>lambda calculus</primary>

</indexterm> <indexterm>
  <primary>Church-Turing thesis</primary>

</indexterm> </para>

  
  <para>This observation led to the Church-Turing Thesis, which is essentially a definition of what it means to be computable. The “thesis” is that Turing-computability is the right, or at least natural, definition of computability, because it describes the power of such a diverse collection of models of computation. </para>

  
  <para>The Rule 110 CA is yet another model of computation, and remarkable for its simplicity. That it, too, turns out to be universal lends support to the Church-Turing Thesis. </para>

  
  <para>In <emphasis>A New Kind of Science</emphasis>, Wolfram states a variation of this thesis, which he calls the “principle of computational equivalence:” <indexterm>
  <primary>principle of computational equivalence</primary>

</indexterm> <indexterm>
  <primary sortas="New Kind of Science">A New Kind of Science</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> Almost all processes that are not obviously simple can be viewed as computations of equivalent sophistication. </para>

  
  <para>More specifically, the principle of computational equivalence says that systems found in the natural world can perform computations up to a maximal (“universal”) level of computational power, and that most systems do in fact attain this maximal level of computational power. Consequently, most systems are computationally equivalent<footnote><para>See <ulink url="mathworld.wolfram.com/PrincipleofComputationalEquivalence.html">mathworld.wolfram.com/PrincipleofComputationalEquivalence.html</ulink>.</para></footnote>. </para>
</blockquote>

  
  <para>Applying these definitions to CAs, Classes 1 and 2 are “obviously simple.” It may be less obvious that Class 3 is simple, but in a way perfect randomness is as simple as perfect order; complexity happens in between. So Wolfram’s claim is that Class 4 behavior is common in the natural world, and that almost all of the systems that manifest it are computationally equivalent. <indexterm>
  <primary>Class 4 behavior</primary>

</indexterm> </para>

  
  

  
  <para>The goal of this exercise is to implement a Turing machine. See <ulink url="http://en.wikipedia.org/wiki/Turing_machine">http://en.wikipedia.org/wiki/Turing_machine</ulink>. </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Start with a copy of <literal>CA.py</literal> named <literal>TM.py</literal>. Add attributes to represent the location of the head, the action table and the state register. </para>
</listitem>
  
  <listitem>
  
  <para>Override <literal>step</literal> to implement a Turing machine update. </para>
</listitem>
  
  <listitem>
  
  <para>For the action table, use the rules for a 3-state busy beaver. <indexterm>
  <primary>busy beaver</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>Write a class named <literal>TMDrawer</literal> that generates an image that represents the state of the tape and the position and state of the head. For one example of what that might look like, see <ulink url="http://mathworld.wolfram.com/TuringMachine.html">http://mathworld.wolfram.com/TuringMachine.html</ulink>. </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000074" remap="section">
  <title>Falsifiability</title>
    
  
  <para>Wolfram holds that his principle is a stronger claim than the Church-Turing Thesis because it is about the natural world rather than abstract models of computation. But saying that natural processes “can be viewed as computations” strikes me as a statement about theory choice more than a hypothesis about the natural world. <indexterm>
  <primary>falsifiability</primary>

</indexterm> </para>

  
  <para>Also, with qualifications like “almost” and undefined terms like “obviously simple,” his hypothesis may be <emphasis role="bold">unfalsifiable</emphasis>. Falsifiability is an idea from the philosophy of science, proposed by Karl Popper as a demarcation between scientific hypotheses and pseudoscience. A hypothesis is falsifiable if there is an experiment, at least in the realm of practicality, that would contradict the hypothesis if it were false. <indexterm>
  <primary>Popper, Karl</primary>

</indexterm> </para>

  
  <para>For example, the claim that all life on earth is descended from a common ancestor is falsifiable because it makes specific predictions about similarities in the genetics of modern species (among other things). If we discovered a new species whose DNA was almost entirely different from ours, that would contradict (or at least bring into question) the theory of universal common descent. <indexterm>
  <primary>universal common descent</primary>

</indexterm> </para>

  
  <para>On the other hand, “special creation,” the claim that all species were created in their current form by a supernatural agent, is unfalsifiable because there is nothing that we could observe about the natural world that would contradict it. Any outcome of any experiment could be attributed to the will of the creator. <indexterm>
  <primary>special creation</primary>

</indexterm> </para>

  
  <para>Unfalsifiable hypotheses can be appealing because they are impossible to refute. If your goal is never to be proved wrong, you should choose hypotheses that are as unfalsifiable as possible. </para>

  
  <para>But if your goal is to make reliable predictions about the world—and this is at least one of the goals of science—then unfalsifiable hypotheses are useless. The problem is that they have no consequences (if they had consequences, they would be falsifiable). <indexterm>
  <primary>prediction</primary>

</indexterm> </para>

  
  <para>For example, if the theory of special creation were true, what good would it do me to know it? It wouldn’t tell me anything about the creator except that he has an “inordinate fondness for beetles. <footnote><para>Attributed to J. B. S. Haldane.</para></footnote>” And unlike the theory of common descent, which informs many areas of science and bioengineering, it would be of no use for understanding the world or acting in it. <indexterm>
  <primary>Haldane, J. B. S.</primary>

</indexterm> <indexterm>
  <primary>beetles</primary>

</indexterm> </para>

  
  

  
  <para>Falsifiability is an appealing and useful idea, but among philosophers of science it is not generally accepted as a solution to the demarcation problem, as Popper claimed. </para>

  
  <para>Read <ulink url="wikipedia.org/wiki/Falsifiability">wikipedia.org/wiki/Falsifiability</ulink> and answer the following questions. </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What is the demarcation problem? <indexterm>
  <primary>demarcation problem</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>How, according to Popper, does falsifiability solve the demarcation problem? </para>
</listitem>
  
  <listitem>
  
  <para>Give an example of two theories, one considered scientific and one considered unscientific, that are successfully distinguished by the criterion of falsifiability. </para>
</listitem>
  
  <listitem>
  
  <para>Can you summarize one or more of the objections that philosophers and historians of science have raised to Popper’s claim? </para>
</listitem>
  
  <listitem>
  
  <para>Do you get the sense that practicing philosophers think highly of Popper’s work? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1><sect1 id="a0000000075" remap="section">
  <title>What is this a model of?</title>
    
  
  <para>Some cellular automata are primarily mathematical artifacts. They are interesting because they are surprising, or useful, or pretty, or because they provide tools for creating new mathematics (like the Church-Turing thesis). <indexterm>
  <primary>mathematics</primary>

</indexterm> </para>

  
  <para>But it is not clear that they are models of physical systems. And if they are, they are highly abstracted, which is to say that they are not very detailed or realistic. For example, some species of cone snail produce a pattern on their shells that resembles the patterns generated by cellular automata. See <ulink url="en.wikipedia.org/wiki/Cone_snail">en.wikipedia.org/wiki/Cone_snail</ulink>. <indexterm>
  <primary>physical model</primary>

</indexterm> <indexterm>
  <primary>cone snail</primary>

</indexterm> <indexterm>
  <primary>abstract model</primary>

</indexterm> </para>

  
  <para>So it is natural to suppose that a CA is a model of the mechanism that produces patterns on shells as they grow. But, at least initially, it is not clear how the elements of the model (so-called cells, communication between neighbors, rules) correspond to the elements of a growing snail (real cells, chemical signals, protein interaction networks). </para>

  
  <para>For conventional physical models, being realistic is a virtue, at least up to a point. If the elements of a model correspond to the elements of a physical system, there is an obvious analogy between the model and the system. In general, we expect a model that is more realistic to make better predictions and to provide more believable explanations. <indexterm>
  <primary>realistic model</primary>

</indexterm> </para>

  
  <para>Of course, this is only true up to a point. Models that are more detailed are harder to work with, and less likely to be amenable to analysis. At some point, a model can be so complex that it is easier to experiment with a real system. </para>

  
  <para>At the other extreme, simple models can be compelling exactly because they are simple. </para>

  
  <para>Simple models offer a different kind of explanation than detailed models. With a detailed model, the argument goes something like this: “We are interested in physical system S, so we construct a detailed model, M, and show by analysis and simulation that M exhibits a behavior, B, that is similar (qualitatively or quantitatively) to an observation of the real system, O. So why does O happen? Because S is similar to M, and B is similar to O, and we can prove that M leads to B.” <indexterm>
  <primary>argument by analogy</primary>

</indexterm> </para>

  
  <para>With simple models we can’t claim that S is similar to M, because it isn’t. Instead, the argument goes like this: “There is a set of models, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0129.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>${M_0, M_1, ...}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> that share a common set of features, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0130.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>${F_0, F_1, ...}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Any model that has these features exhibits behavior B, and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0131.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$M_0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the simplest. If we make an observation, O, that resembles B, one way to explain it is to show that the system, S, has the set of features in common with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0131.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$M_0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> that produce B. </para>

  
  <para>For this kind of argument, adding more features doesn’t help. Making the model more realistic doesn’t make the model more reliable; it only obscures the difference between the essential features that cause O and the incidental features that are particular to S. </para>

</sect1>
</chapter><chapter id="a0000000076">
  <title>Game of Life</title>
  
  
  <para>One of the first cellular automata to be studied, and probably the most popular of all time, is a 2-D CA called “The Game of Life,” or GoL for short. It was developed by John H. Conway and popularized in 1970 in Martin Gardner’s column in <emphasis>Scientific American</emphasis>. See <ulink url="http://en.wikipedia.org/wiki/Conway_Game_of_Life">http://en.wikipedia.org/wiki/Conway_Game_of_Life</ulink>. <indexterm>
  <primary>Game of Life</primary>

</indexterm> <indexterm>
  <primary>Conway, John H.</primary>

</indexterm> <indexterm>
  <primary>Gardner, Martin</primary>

</indexterm> </para>

  
  <para>The cells in GoL are arranged in a 2-D <emphasis role="bold">grid</emphasis>, either infinite in both directions or wrapped around. A grid wrapped in both directions is called a <emphasis role="bold">torus</emphasis> because it is topographically equivalent to the surface of a doughnut. See <ulink url="wikipedia.org/wiki/Torus">wikipedia.org/wiki/Torus</ulink>. <indexterm>
  <primary>torus</primary>

</indexterm> <indexterm>
  <primary>grid</primary>

</indexterm> </para>

  
  <para>Each cell has two states—live and dead—and 8 neighbors—north, south, east, west, and the four diagonals. This set of neighbors is sometimes called a Moore neighborhood. <indexterm>
  <primary>Moore neighborhood</primary>

</indexterm> <indexterm>
  <primary>neighborhood</primary>

</indexterm> </para>

  
  <para>The rules of GoL are <emphasis role="bold">totalistic</emphasis>, which means that the next state of a cell depends on the number of live neighbors only, not on their arrangement. The following table summarizes the rules: <indexterm>
  <primary>totalistic</primary>

</indexterm> </para>

  
  <para>
   
   
     <informaltable remap="tabular">
     <tr>
     
       
       <td>
  
  <para> Number of </para>
</td>
     
       
       <td>
  
  <para> Current </para>
</td>
     
       
       <td>
  
  <para> Next </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>neighbors </para>
</td>
     
       
       <td>
  
  <para> state </para>
</td>
     
       
       <td>
  
  <para> state </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>2–3 </para>
</td>
     
       
       <td>
  
  <para> live </para>
</td>
     
       
       <td>
  
  <para> live </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>0–1,4–8 </para>
</td>
     
       
       <td>
  
  <para> live </para>
</td>
     
       
       <td>
  
  <para> dead </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>3 </para>
</td>
     
       
       <td>
  
  <para> dead </para>
</td>
     
       
       <td>
  
  <para> live </para>
</td>
     
     </tr><tr>
     
       
       <td>
  
  <para>0–2,4–8 </para>
</td>
     
       
       <td>
  
  <para> dead </para>
</td>
     
       
       <td>
  
  <para> dead </para>
</td>
     
     </tr>
     </informaltable>
   
</para>

  
  <para>This behavior is loosely analogous to real cell growth: cells that are isolated or overcrowded die; at moderate densities they flourish. </para>

  
  <para>GoL is popular because: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>There are simple initial conditions that yield surprisingly complex behavior. <indexterm>
  <primary>complex behavior</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>There are many interesting stable patterns: some oscillate (with various periods) and some move like the spaceships in Wolfram’s Rule 110 CA. </para>
</listitem>
  
    <listitem>
  
  <para>Like Rule 110, GoL is Turing complete. <indexterm>
  <primary>Turing complete</primary>

</indexterm> <indexterm>
  <primary>universal</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Conway posed an intriguing conjecture—that there is no initial condition that yields unbounded growth in the number of live cells—and offered $50 to anyone who could prove or disprove it. <indexterm>
  <primary>unbounded</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>The increasing availability of computers made it possible to automate the computation and display the results graphically. That turns out to be more fun than Conway’s original implementation using a checkerboard. </para>
</listitem>
  
</itemizedlist></para>
<sect1 id="a0000000077" remap="section">
  <title>Implementing Life</title>
    
  
  <para>To implement GoL efficiently, we can take advantage of the multi-dimensional convolution function in SciPy. SciPy is a Python package that provides functions related to scientific computing You can read about it at <ulink url="http://www.scipy.org/">http://www.scipy.org/</ulink>; if it is not already on your system, you might have to install it. <indexterm>
  <primary>implementing Game of Life</primary>

</indexterm> <indexterm>
  <primary>SciPy</primary>

</indexterm> </para>

  
  <para><emphasis role="bold">Convolution</emphasis> is an operation common in digital image processing, where an image is an array of pixels, and many operations involve computing a function of a pixel and its neighbors. <indexterm>
  <primary>convolution</primary>

</indexterm> </para>

  
  <para>The neighborhood is described by a smaller array, called a <emphasis role="bold">kernel</emphasis> that specifies the location and <emphasis role="bold">weight</emphasis> of the neighbors. For example, this array: <indexterm>
  <primary>kernel</primary>

</indexterm> <indexterm>
  <primary>weight</primary>

</indexterm> </para>

  
  <programlisting>kernel = numpy.array([[1,1,1],
                          [1,0,1],
                          [1,1,1]])</programlisting>

  
  <para>represents a neighborhood with eight neighbors, all with weight 1. </para>

  
  <para>Convolution computes the weighted sum of the neighbors for each element of the array. So this kernel computes the sum of the neighbors (not including the center element). </para>

  
  <para>For example, if <literal>array</literal> represents a GoL grid with 1s for live cells and 0s for dead cells we can use convolution to compute the number of neighbors for each cell. </para>

  
  <programlisting>import scipy.ndimage
    neighbors = scipy.ndimage.filters.convolve(array, kernel)</programlisting>

  
  <para>Here’s an implementation of GoL using <literal>convolve</literal>: <indexterm>
  <primary sortas="Life">Life</primary>

</indexterm> </para>

  
  <programlisting>import numpy
import scipy.ndimage

class Life(object):

    def __init__(self, n, mode='wrap'):
        self.n = n
        self.mode = mode
        self.array = numpy.random.random_integers(0, 1, (n, n))
        self.weights = numpy.array([[1,1,1],
                                    [1,10,1],
                                    [1,1,1]])

    def step(self):
        con = scipy.ndimage.filters.convolve(self.array,
                                             self.weights,
                                             mode=self.mode)

        boolean = (con==3) | (con==12) | (con==13)
        self.array = numpy.int8(boolean)</programlisting>

  
  <para>The attributes of the <literal>Life</literal> object are <literal>n</literal>, the number of rows and columns in the grid, <literal>mode</literal>, which controls the behaviors of the boundary cells, <literal>array</literal>, which represents the grid, and <literal>weights</literal> which is the kernel used to count the neighbors. </para>

  
  <para>The weight of the center cell is 10, so the number of neighbors is 0-8 for dead cells and 10-18 for live cells. </para>

  
  <para>In <literal>step</literal>, <literal>boolean</literal> is a boolean array with <literal>True</literal> for live cells; <literal>numpy.int8</literal> converts it to integers. </para>

  
  <para>To display an animated sequence of grids, I use <literal>pyplot</literal>. Animation in <literal>pyplot</literal> is a little awkward, but here’s a class that manages it: <indexterm>
  <primary>animation</primary>

</indexterm> <indexterm>
  <primary>pyplot</primary>

</indexterm> <indexterm>
  <primary sortas="LifeViewer">LifeViewer</primary>

</indexterm> </para>

  
  <programlisting>import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as pyplot


class LifeViewer(object):

    def __init__(self, life, cmap=matplotlib.cm.gray_r):
        self.life = life
        self.cmap = cmap

        self.fig = pyplot.figure()
        pyplot.axis([0, life.n, 0, life.n])
        pyplot.xticks([])
        pyplot.yticks([])

        self.pcolor = None
        self.update()</programlisting>

  
  <para><literal>life</literal> is a <literal>Life</literal> object. <literal>cmap</literal> is a color map provided by <literal>matplotlib</literal>; you can see the other color maps at <ulink url="http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps">http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps</ulink>. <indexterm>
  <primary>color map</primary>

</indexterm> </para>

  
  <para><literal>self.fig</literal> is a reference to the <literal>matplotlib</literal> figure, and <literal>self.pcolor</literal> is a reference to the <emphasis role="bold">pseudocolor plot</emphasis> created by <literal>update</literal>: <indexterm>
  <primary>pseudocolor plot</primary>

</indexterm> </para>

  
  <programlisting>def update(self):
        if self.pcolor:
            self.pcolor.remove()

        a = self.life.array
        self.pcolor = pyplot.pcolor(a, cmap=self.cmap)
        self.fig.canvas.draw()</programlisting>

  
  <para>If there is already a plot, we have to remove it; then we create a new one and invoke <literal>draw</literal> to update the display. </para>

  
  <para>To run the animation, we need two methods: </para>

  
  <programlisting>def animate(self, steps=10):
        self.steps = steps
        self.fig.canvas.manager.window.after(1000, self.animate_callback)
        pyplot.show()

    def animate_callback(self):
        for i in range(self.steps):
            self.life.step()
            self.update()</programlisting>

  
  <para><literal>animate</literal> gets the animation started. It invokes <literal>pyplot.show</literal>, which sets up the GUI and waits for user events, but <emphasis>first</emphasis> it has to invoke <literal>window.after</literal> to set up a callback, so that <literal remap="verb">animate_callback</literal> gets invoked after the window is set up. The first argument is the delay in milliseconds. The second argument is a bound method (see Chapter 19 of <emphasis>Think Python</emphasis>). <indexterm>
  <primary sortas="Think Python">Think Python</primary>

</indexterm> </para>

  
  <para><literal remap="verb">animate_callback</literal> invokes <literal>step</literal> to update the <literal>Life</literal> object and <literal>update</literal> to update the display. </para>

  
  

  
  <para>Download my implementation of GoL from <ulink url="thinkcomplex.com/Life.py">thinkcomplex.com/Life.py</ulink>. </para>

  
  <para>Start the CA in a random state and run it until it stabilizes. What stable patterns can you identify? </para>

  
  

</sect1><sect1 id="a0000000078" remap="section">
  <title>Life patterns</title>
    
  
  <para>If you run GoL from a random starting state, a number of stable patterns are likely to appear. Blocks, boats, beehives, blinkers and gliders are among the most common. <indexterm>
  <primary>Game of Life patterns</primary>

</indexterm> <indexterm>
  <primary>glider</primary>

</indexterm> <indexterm>
  <primary>spaceship</primary>

</indexterm> </para>

  
  <para>People have spent embarrassing amounts of time finding and naming these patterns. If you search the web, you will find many collections. </para>

  
  <para>From most initial conditions, GoL quickly reaches a stable state where the number of live cells is nearly constant (usually with a small amount of oscillation). </para>

  
  <para>But there are a some simple starting conditions that take a long time to settle down and yield a surprising number of live cells. These patterns are called “Methuselahs” because they are so long-lived. <indexterm>
  <primary>Methuselah</primary>

</indexterm> </para>

  
  <para>One of the simplest is the r-pentomino, which has only five cells in the shape of a “r,” hence the name. It runs for 1103 steps and yields 6 gliders, 8 blocks, 4 blinkers, 4 beehives, 1 boat, 1 ship, and 1 loaf. One of the longest-lived small patterns is rabbits, which starts with 9 live cells and takes 17 331 steps to stabilize. <indexterm>
  <primary>r-pentomino</primary>

</indexterm> </para>

  
  

  
  <para>Start with an r-pentomino as an initial condition and confirm that the results are consistent with the description above. You might have to adjust the size of the grid and the boundary behavior. </para>

  
  

</sect1><sect1 id="a0000000079" remap="section">
  <title>Conway’s conjecture</title>
    
  
  <para>The existence of long-lived patterns bring us back to Conway’s original question: are there initial patterns that never stabilize? Conway thought not, but he described two kinds of pattern that would prove him wrong, a “gun” and a “puffer train.” A gun is a stable pattern that periodically produces a spaceship—as the stream of spaceships moves out from the source, the number of live cells grows indefinitely. A puffer train is a translating pattern that leaves live cells in its wake. <indexterm>
  <primary>glider gun</primary>

</indexterm> <indexterm>
  <primary>puffer train</primary>

</indexterm> </para>

  
  <para>It turns out that both of these patterns exist. A team led by Bill Gosper discovered the first, a glider gun now called Gosper’s Gun. Gosper also discovered the first puffer train. You can find descriptions and animations of these patterns in several places on the Web. <indexterm>
  <primary>Gosper, Bill</primary>

</indexterm> </para>

  
  <para>There are many patterns of both types, but they are not easy to design or find. That is not a coincidence. Conway chose the rules of GoL so that his conjecture would not be obviously true or false. Of all the possible rules for a 2-D CA, most yield simple behavior; most initial conditions stabilize quickly or grow unboundedly. By avoiding uninteresting CAs, Conway was also avoiding Wolfram’s Class 1 and Class 2 behavior, and probably Class 3 as well. </para>

  
  <para>If we believe Wolfram’s Principle of Computational Equivalence, we expect GoL to be in Class 4. And it is. The Game of Life was proved Turing complete in 1982 (and again, independently, in 1983). Since then several people have constructed GoL patterns that implement a Turing machine or another machine known to be Turing complete. <indexterm>
  <primary>Class 4 behavior</primary>

</indexterm> <indexterm>
  <primary>Turing complete</primary>

</indexterm> <indexterm>
  <primary>universality</primary>

</indexterm> </para>

  
  

  
  <para>Many named patterns are available in portable file formats. Modify <literal>Life.py</literal> to parse one of these formats and initialize the grid. </para>

  
  

</sect1><sect1 id="a0000000080" remap="section">
  <title>Realism</title>
    
  
  <para>Stable patterns in GoL are hard not to notice, especially the ones that move. It is natural to think of them as persistent entities, but remember that a CA is made of cells; there is no such thing as a toad or a loaf. Gliders and other spaceships are even less real because they are not even made up of the same cells over time. So these patterns are like constellations of stars. We perceive them because we are good at seeing patterns, or because we have active imaginations, but they are not real. <indexterm>
  <primary>realism</primary>

</indexterm> </para>

  
  <para>Right? </para>

  
  <para>Well, not so fast. Many entities that we consider “real” are also persistent patterns of entities at a smaller scale. Hurricanes are just patterns of air flow, but we give them personal names. And people, like gliders, are not made up of the same cells over time. But even if you replace every cell in your body, we consider you the same person. <indexterm>
  <primary>hurricane</primary>

</indexterm> </para>

  
  <para>This is not a new observation—about 2500 years ago Heraclitus pointed out that you can’t step in the same river twice—but the entities that appear in the Game of Life are a useful test case for thinking about <emphasis role="bold">philosophical realism</emphasis>. <indexterm>
  <primary>philosophical realism</primary>

</indexterm> </para>

  
  <para>In the context of philosophy, realism is the view that entities in the world exist independent of human perception and conception. By “perception” I mean the information that we get from our senses, and by “conception” I mean the mental model we form of the world. For example, our vision systems perceive something like a 2-D projection of a scene, and our brains use that image to construct a 3-D model of the objects in the scene. <indexterm>
  <primary>perception</primary>

</indexterm> <indexterm>
  <primary>conception</primary>

</indexterm> </para>

  
  <para><emphasis role="bold">Scientific realism</emphasis> pertains to scientific theories and the entities they postulate. A theory postulates an entity if it is expressed in terms of the properties and behavior of the entity. For example, Mendelian genetics postulated a “gene” as a unit that controls a heritable characteristic. Eventually we discovered that genes are encoded in DNA, but for about 50 years, a gene was just a postulated entity. See <ulink url="http://en.wikipedia.org/wiki/Gene">http://en.wikipedia.org/wiki/Gene</ulink>. <indexterm>
  <primary>gene</primary>

</indexterm> <indexterm>
  <primary>postulated entity</primary>

</indexterm> </para>

  
  <para>Again, I find it useful to state philosophical positions in a range of strengths, where SR1 is a weak form of scientific realism and SR4 is a strong form: </para>

  
  <para><variablelist>
  <varlistentry>
    <term>SR1:</term>
      <listitem>
  
  <para>Scientific theories are true or false to the degree that they approximate reality, but no theory is exactly true. Some postulated entities may be real, but there is no principled way to say which ones. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>SR2:</term>
      <listitem>
  
  <para>As science advances, our theories become better approximations of reality. At least some postulated entities are known to be real. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>SR3:</term>
      <listitem>
  
  <para>Some theories are exactly true; others are approximately true. Entities postulated by true theories, and some entities in approximate theories, are real. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>SR4:</term>
      <listitem>
  
  <para>A theory is true if it describes reality correctly, and false otherwise. The entities postulated by true theories are real; others are not. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>SR4 is so strong that it is probably untenable; by such a strict criterion, almost all current theories are known to be false. Most realists would accept something in the space between SR1 and SR3. </para>

</sect1><sect1 id="a0000000081" remap="section">
  <title>Instrumentalism</title>
    
  
  <para>But SR1 is so weak that it verges on <emphasis role="bold">instrumentalism</emphasis>, which is the view that we can’t say whether a theory is true or false because we can’t know whether a theory corresponds to reality. Theories are instruments that we use for our purposes; a theory is useful, or not, to the degree that it is fit for its purpose. <indexterm>
  <primary>instrumentalism</primary>

</indexterm> </para>

  
  <para>To see whether you are comfortable with instrumentalism, consider the following statements: </para>

  
  <blockquote remap="quote">
  <para> “Entities in the Game of Life aren’t real; they are just patterns of cells that people have given cute names.” </para>
</blockquote>

  
  <blockquote remap="quote">
  <para> “A hurricane is just a pattern of air flow, but it is a useful description because it allows us to make predictions and communicate about the weather.” </para>
</blockquote>

  
  <para> <indexterm>
  <primary>hurricane</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> “Freudian entities like the Id and the Superego aren’t real, but they are useful tools for thinking and communicating about psychology (or at least some people think so).” </para>
</blockquote>

  
  <para> <indexterm>
  <primary>Id</primary>

</indexterm> <indexterm>
  <primary>Freud, Sigmund</primary>

</indexterm> <indexterm>
  <primary>Superego</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> “Electrons are postulated entities in our best theories of electro-magnetism, but they aren’t real. We could construct other theories, without postulating electrons, that would be just as useful.” </para>
</blockquote>

  
  <para> <indexterm>
  <primary>electron</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> “Many of the things in the world that we identify as objects are arbitrary collections like constellations. For example, a mushroom is just the fruiting body of a fungus, most of which grows underground as a barely-contiguous network of cells. We focus on mushrooms for practical reasons like visibility and edibility.” </para>
</blockquote>

  
  <para> <indexterm>
  <primary>mushroom</primary>

</indexterm> </para>

  
  <blockquote remap="quote">
  <para> “Some objects have sharp boundaries, but many are fuzzy. For example, which molecules are part of your body: Air in your lungs? Food in your stomach? Nutrients in your blood? Nutrients in a cell? Water in a cell? Structural parts of a cell? Hair? Dead skin? Dirt? Bacteria on your skin? Bacteria in your gut? Mitochondria? How many of those molecules do you include when you weigh yourself. Conceiving the world in terms of discrete objects is useful, but the entities we identify are not real.” </para>
</blockquote>

  
  <para>Give yourself one point for each statement you agree with. If you score 4 or more, you might be an instrumentalist! </para>

  
  <para>If you are more comfortable with some of these statements than with others, ask yourself why. What are the differences in these scenarios that influence your reaction? Can you make a principled distinction between them? </para>

  
  

  
  <para>Read <ulink url="http://en.wikipedia.org/wiki/Instrumentalism">http://en.wikipedia.org/wiki/Instrumentalism</ulink> and construct a sequence of statements that characterize instrumentalism in a range of strengths. </para>

  
  

</sect1><sect1 id="a0000000082" remap="section">
  <title>Turmites</title>
    
  
  <para>If you generalize the Turing machine to two dimensions, or add a read-write head to a 2-D CA, the result is a cellular automaton called a Turmite. It is named after a termite because of the way the read-write head moves, but spelled wrong as an homage to Turing. <indexterm>
  <primary>turmite</primary>

</indexterm> <indexterm>
  <primary>Turing, Alan</primary>

</indexterm> </para>

  
  <para>The most famous Turmite is Langton’s Ant, discovered by Chris Langton in 1986. See <ulink url="http://en.wikipedia.org/wiki/Langton_ant">http://en.wikipedia.org/wiki/Langton_ant</ulink>. <indexterm>
  <primary>Langton’s Ant</primary>

</indexterm> <indexterm>
  <primary>Langton, Chris</primary>

</indexterm> </para>

  
  <para>The ant is a read-write head with four states, which you can think of as facing north, south, east or west. The cells have two states, black and white. <indexterm>
  <primary>read-write head</primary>

</indexterm> </para>

  
  <para>The rules are simple. During each time step, the ant checks the color of the cell is it on. If it is black, the ant turns to the right, changes the cell to white, and moves forward one space. If the cell is white, the ant turns left, changes the cell to black, and moves forward. <indexterm>
  <primary>simple rules</primary>

</indexterm> </para>

  
  <para>Given a simple world, a simple set of rules, and only one moving part, you might expect to see simple behavior—but you should know better by now. Starting with all white cells, Langton’s ant moves in a seemingly random pattern for more than 10 000 steps before it enters a cycle with a period of 104 steps. After each cycle, the ant is translated diagonally, so it leaves a trail called the “highway.” <indexterm>
  <primary>complex behavior</primary>

</indexterm> <indexterm>
  <primary>period</primary>

</indexterm> </para>

  
  <para>If you start with multiple Turmites, they interact with each other in seemingly complex ways. If one Turmite is on the highway, another can follow it, overtake it, and cause it to reverse its pattern, moving back up the highway and leaving only white cells behind. </para>

  
  

  
  <para>Write an implementation of Langton’s Ant. </para>

  
  <para>You can find a solution in <literal>TurmiteWorld.py</literal>, which is part of Swampy. See <ulink url="http://thinkpython.com/swampy/">http://thinkpython.com/swampy/</ulink>. <indexterm>
  <primary>Swampy</primary>

</indexterm> </para>

  
  

</sect1>
</chapter><chapter id="a0000000083">
  <title>Fractals</title>
  
  
  <para>To understand fractals, we have to start with dimensions. The dimension of a space is the number of coordinates we need to specify a point in a space. A number line takes one coordinate, a Euclidean plane takes 2, a solid takes 3, etc. See <ulink url="http://en.wikipedia.org/wiki/Dimension">http://en.wikipedia.org/wiki/Dimension</ulink>. <indexterm>
  <primary>fractals</primary>

</indexterm> <indexterm>
  <primary>dimension</primary>

</indexterm> <indexterm>
  <primary>geometric objects</primary>

</indexterm> </para>

  
  <para>For simple geometric objects, dimension is defined in terms of scaling behavior; that is, how “size” depends on length, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0132.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$l$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. For example, the area of a square is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0133.png" depth="8.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$l^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; the exponent, 2, indicates that a square is 2-dimensional. Similarly, the volume of a cube is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0134.png" depth="9px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$l^3$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and a cube is 3-dimensional. A line has dimension 1 and, if we think of a point as infinitesimally small, it has dimension 0. <indexterm>
  <primary>line</primary>

</indexterm> <indexterm>
  <primary>square</primary>

</indexterm> <indexterm>
  <primary>cube</primary>

</indexterm> </para>

  
  <para><emphasis role="bold">Fractal dimension</emphasis> is a more precise and more general extension of this definition. There are several versions; the one I find easiest to understand and apply is the <emphasis role="bold">box-counting dimension</emphasis>, which is defined for a set, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0135.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$S$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, of points in a <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0076.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>-dimensional space. See <ulink url="http://en.wikipedia.org/wiki/Box-counting_dimension">http://en.wikipedia.org/wiki/Box-counting_dimension</ulink>. <indexterm>
  <primary>fractal dimension</primary>

</indexterm> <indexterm>
  <primary>box-counting dimension</primary>

</indexterm> </para>

  
  

  
  <para>To compute the box-counting dimension, we divide the space into a grid where the size of each cell is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0136.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Then we count <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0137.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N(\varepsilon )$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the number of cells that contain at least one element of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0135.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$S$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. As <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0136.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> gets smaller, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0137.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N(\varepsilon )$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> gets bigger. For many objects the relationship has the form: </para>

  
  <para><informalequation id="a0000000084" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0138.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  N(\varepsilon ) \sim \left( 1 / \varepsilon \right)^ D  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>The box counting dimension, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, is defined to be the exponent, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0140.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Taking the log of both sides and rearranging yields: </para>

  
  <para><informalequation id="a0000000085" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0141.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  D_{box} = \frac{log N(\varepsilon )}{log \left( 1 / \varepsilon \right)}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>More formally, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the limit of this ratio as <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0136.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> goes to zero. <indexterm>
  <primary>log-log plot</primary>

</indexterm> </para>
<sect1 id="a0000000086" remap="section">
  <title>Fractal CAs</title>
    
  
  <para>To investigate the behavior of fractal dimension, we’ll apply it to cellular automata. Box-counting for CAs is simple; we just count the number of “on” cells. <indexterm>
  <primary>fractal cellular automaton</primary>

</indexterm> </para>

  
  <para>As an example, consider Rule 254. Here’s what it looks like after <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0142.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t=4$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> time steps. <indexterm>
  <primary>Rule 254</primary>

</indexterm> </para>

  
  <figure id="a0000000087">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/fractal-254-4.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>And here’s what it looks like after <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0143.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t=8$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> time steps: </para>

  
  <figure id="a0000000088">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/fractal-254-8.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>As <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> increases, we can imagine the triangle getting bigger, but for purposes of box-counting, it makes more sense to imagine the cells getting smaller. In that case the size of the cells, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0136.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, is just <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0144.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>After 1 time step, there is 1 black cell. After 2 time steps, there are a total of 4, then 9, then 16, then 25. As expected, the area of the triangle goes up quadratically. More formally, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0145.png" depth="10px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N(\varepsilon ) = \left( 1 / \varepsilon \right)^2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, so <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0146.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box} = 2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. And we conclude that a triangle is 2-dimensional. </para>

  
  <para>Rule 18 is more interesting. Here’s what it looks like after 64 steps: <indexterm>
  <primary>Rule 18</primary>

</indexterm> </para>

  
  <figure id="a0000000089">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/rule-18-64.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>And here’s <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0137.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N(\varepsilon )$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0147.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> on a log-log scale: </para>

  
  <figure id="a0000000090">
  
  <title>Caption.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/fractal_dim-18-64.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>To estimate <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> I fit a line to this curve; its slope is 1.56. <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a non-integer, which means that this set of points is a <emphasis role="bold">fractal</emphasis>. As <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> increases, the slope approaches <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0148.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$log 3 / log 2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the fractal dimension of Sierpiński’s triangle. See <ulink url="wikipedia.org/wiki/Sierpinski_triangle">wikipedia.org/wiki/Sierpinski_triangle</ulink>. <indexterm>
  <primary>fractal</primary>

</indexterm> <indexterm>
  <primary>Sierpiński’s triangle</primary>

</indexterm> </para>

  
  

  
  <para>Write a function that takes a CA object, plots <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0137.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N(\varepsilon )$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> versus <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0147.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/\varepsilon $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0149.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\varepsilon = 1/t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and estimates <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Can you find other CAs with non-integer fractal dimensions? Be careful, you might have to run the CA for a while before <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0139.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D_{box}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> converges. </para>

  
  <para>Here are some functions from <literal>numpy</literal> you might find useful: <literal>cumsum</literal>, <literal>log</literal>, and <literal>polyfit</literal>. <indexterm>
  <primary>NumPy</primary>

</indexterm> </para>

  
  <para>You can download my solution from <ulink url="fractal.py">fractal.py</ulink>. </para>

  
  

  
  

  
  <para>In 1990 Bak, Chen and Tang proposed a cellular automaton that is an abstract model of a forest fire. Each cell is in one of three states: empty, occupied by a tree, or on fire. <indexterm>
  <primary>Bak, Per</primary>

</indexterm> <indexterm>
  <primary>forest fire model</primary>

</indexterm> </para>

  
  <para>The rules of the CA are: </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>An empty cell becomes occupied with probability <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
  <listitem>
  
  <para>A cell with a tree burns if any of its neighbors is on fire. </para>
</listitem>
  
  <listitem>
  
  <para>A cell with a tree spontaneously burns, with probability <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, even if none of its neighbors is on fire. </para>
</listitem>
  
  <listitem>
  
  <para>A cell with a burning tree becomes an empty cell in the next time step. </para>
</listitem>
  
</orderedlist></para>

  
  <para>Read about this model at <ulink url="http://en.wikipedia.org/wiki/Forest-fire_model">http://en.wikipedia.org/wiki/Forest-fire_model</ulink> and write a program that implements it. You might want to start with a copy of <ulink url="thinkcomplex.com/Life.py">thinkcomplex.com/Life.py</ulink>. </para>

  
  <para>Starting from a random initial condition, run the CA until it reaches a steady state where the number of trees no longer increases or decreases consistently. You might have to tune <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>In steady state, is the geometry of the forest fractal? What is its fractal dimension? </para>

  
  

</sect1><sect1 id="a0000000091" remap="section">
  <title>Percolation</title>
    
  
  <para>The CAs we have seen so far are not physical models; that is, they are not intended to describe systems in the real world. <indexterm>
  <primary>physical model</primary>

</indexterm> </para>

  
  <para>But some CAs are designed explicitly as physical models. In this section we consider a simple grid-based model of percolation; in the next chapter we see examples that model forest fires, avalanches, and earthquakes. <indexterm>
  <primary>forest fire</primary>

</indexterm> <indexterm>
  <primary>avalanche</primary>

</indexterm> <indexterm>
  <primary>earthquake</primary>

</indexterm> </para>

  
  <para>Percolation is a process in which a fluid flows through a semi-porous material. Examples include oil in rock formations, water in paper, and hydrogen gas in micropores. Percolation models are also used to study systems that are not literally percolation, including epidemics and networks of electrical resistors. See <ulink url="http://en.wikipedia.org/wiki/Percolation_theory">http://en.wikipedia.org/wiki/Percolation_theory</ulink>. <indexterm>
  <primary>percolation</primary>

</indexterm> </para>

  
  <para>Percolation processes often exhibit a phase change; that is, an abrupt transition from one behavior (low flow) to another (high flow) with a small change in a continuous parameter (like the porosity of the material). This transition is sometimes called a “tipping point.” <indexterm>
  <primary>tipping point</primary>

</indexterm> </para>

  
  <para>There are two common models of these systems: bond percolation and site percolation. Bond percolation is based on a grid of sites, where each site is connected to four neighbors by a bond. Each bond is either porous or non-porous. A set of sites that are connected (directly or indirectly) by porous bonds is called a cluster. In the vocabulary of graphs, a site is a vertex, a bond is an edge, and a cluster is a connected subgraph. <indexterm>
  <primary>bond percolation</primary>

</indexterm> <indexterm>
  <primary>site percolation</primary>

</indexterm> </para>

  
  <para>Site percolation is based on a grid of cells, where each cell represents a porous segment of the material or a non-porous segment. If two porous cells are adjacent, they are considered connected; a set of connected cells is considered a cluster. </para>

  
  <para>The rate of flow in a percolation system is primarily determined by whether or not the porous cells form a path all the way through the material, so it is useful to know whether a set of cells (or bonds) contains a “spanning cluster.” There are several definitions of a spanning cluster; the choice depends on the system you are trying to model. The simplest choice is a cluster that reaches the top and bottom row of the grid. <indexterm>
  <primary>spanning cluster</primary>

</indexterm> <indexterm>
  <primary>grid</primary>

</indexterm> </para>

  
  <para>To model the porosity of the material, it is common to define a parameter, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which the probability that any cell (or bond) is porous. For a given value of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0013.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, you can estimate <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0150.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$R(p)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the probability that there is a spanning cluster, by generating a large number of random grids and computing the fraction that contain a spanning cluster. This way of estimating probabilities is called a “Monte Carlo simulation” because it a similar to a game of chance. <indexterm>
  <primary>porosity</primary>

</indexterm> <indexterm>
  <primary>Monte Carlo simulation</primary>

</indexterm> </para>

  
  <para>Percolation models are often used to compute a critical value, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0151.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$p_ c$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the fraction of porous segments where the phase change occurs; that is, where the probability of a spanning cluster increases quickly from near 0 to near 1. <indexterm>
  <primary>critical value</primary>

</indexterm> </para>

  
  

  
  <para>The paper “Efficient Monte Carlo Algorithm and High-Precision Results for Percolation,” by Newman and Ziff, presents an efficient algorithm for checking whether there is a path through a grid. Read this paper, implement their algorithm, and see if you can reproduce their Figure 2(a). </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>What is the difference between what Newman and Ziff call the “microcanonical ensemble” and the “canonical ensemble”<footnote><para>You might find it useful to read about the use of these terms in statistical mechanics: <ulink url="wikipedia.org/wiki/Statistical_mechanics">wikipedia.org/wiki/Statistical_mechanics</ulink>.</para></footnote>? Which one is easier to estimate by Monte Carlo simulation? <indexterm>
  <primary>microcanonical ensemble</primary>

</indexterm> <indexterm>
  <primary>canonical ensemble</primary>

</indexterm> </para>
</listitem>
  
  <listitem>
  
  <para>What algorithm do they use to merge two clusters efficiently? </para>
</listitem>
  
  <listitem>
  
  <para>What is the primary reason their algorithm is faster than the simpler alternative? </para>
</listitem>
  
</orderedlist></para>

  
  

</sect1>
</chapter><chapter id="a0000000092">
  <title>Self-organized criticality</title>
  <sect1 id="a0000000093" remap="section">
  <title>Sand piles</title>
    
  
  <para>In 1987 Bak, Tang and Wiesenfeld published a paper in Physical Review Letters, “Self-organized criticality: an explanation of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise.” The title takes some explaining. A system is “critical” if it is in transition between two phases; for example, water at its freezing point is a critical system. <indexterm>
  <primary>Bak, Per</primary>

</indexterm> <indexterm>
  <primary>self-organized criticality</primary>

</indexterm> <indexterm>
  <primary>criticality</primary>

</indexterm> </para>

  
  <para>A variety of critical systems demonstrate common behaviors: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Long-tailed distributions of some physical quantities: for example, in freezing water the distribution of crystal sizes is characterized by a power law. <indexterm>
  <primary>long tail</primary>

</indexterm> <indexterm>
  <primary>power law</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Fractal geometries: freezing water tends to form fractal patterns—the canonical example is a snowflake. Fractals are characterized by self-similarity; that is, parts of the pattern resemble scaled copies of the whole. <indexterm>
  <primary>fractal geometry</primary>

</indexterm> <indexterm>
  <primary>self-similarity</primary>

</indexterm> </para>
</listitem>
  
    <listitem>
  
  <para>Variations in time that exhibit pink noise: what we call “noise” is a time series with many frequency components. In “white” noise, all of the components have equal power. In “pink” noise, low-frequency components have more power than high-frequency components. Specifically, the power at frequency <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is proportional to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Visible light with this power spectrum looks pink, hence the name. <indexterm>
  <primary>pink noise</primary>

</indexterm> <indexterm>
  <primary sortas="1/f noise">1/f noise</primary>

</indexterm> </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Critical systems are usually unstable. For example, to keep water in a partially frozen state requires active control of the temperature. If the system is near the critical temperature, a small deviation tends to move the system into one phase or the other. <indexterm>
  <primary>unstable</primary>

</indexterm> </para>

  
  <para>Many natural systems exhibit characteristic behaviors of criticality, but if critical points are unstable, they should not be common in nature. This is the puzzle Bak, Tang and Wiesenfeld address. Their solution is called self-organized criticality (SOC), where “self-organized” means that from any initial condition, the system tends to move toward a critical state, and stay there, without external control. <indexterm>
  <primary>SOC</primary>

</indexterm> </para>

  
  <para>As an example, they propose a model of a sand pile. The model is not realistic, but it has become the standard example of self-organized criticality. <indexterm>
  <primary>sand pile model</primary>

</indexterm> <indexterm>
  <primary>abstract model</primary>

</indexterm> </para>

  
  <para>The model is a 2-D cellular automaton where the state of each cell, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0153.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$z(i,j)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, represents the slope of a part of a sand pile. During each time step, each cell is checked to see whether it exceeds some critical value, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0154.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$K$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. If so, an “avalanche” occurs that transfers sand to neighboring cells; specifically, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0153.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$z(i,j)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is decreased by 4, and each of the 4 neighbors is increased by 1. <indexterm>
  <primary>2-D cellular automaton</primary>

</indexterm> <indexterm>
  <primary>state</primary>

</indexterm> </para>

  
  <para>At the perimeter of the grid, all cells are kept at <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0155.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$z=0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, so the excess spills over the edge. To initialize the system, Bak et al. start with all <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0156.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$z &gt; K$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and evolve the system until it stabilizes. Then they observe the effect of small perturbations; they choose a cell at random, increment its value by 1, and evolve the system, again, until it stabilizes. <indexterm>
  <primary>grid</primary>

</indexterm> </para>

  
  <para>For each perturbation, they measure <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0140.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the total number of cells that are affected by the resulting avalanche. Most of the time, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0140.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is small, usually 1. But occasionally a large avalanche affects a substantial fraction of the grid. The distribution of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0140.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$D$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> turns out to be long-tailed, which supports the claim that the system is in a critical state. <indexterm>
  <primary>avalanche</primary>

</indexterm> </para>

  
  

  
  <para>Read the paper and write a program that implements their CA. You might want to start with a copy of <ulink url="thinkcomplex.com/Life.py">thinkcomplex.com/Life.py</ulink>. </para>

  
  <para>See if you can reproduce their Figure 2(a), which shows the distribution of cluster sizes. </para>

  
  <para>After the system has been running for a while, compute its fractal dimension. <indexterm>
  <primary>fractal dimension</primary>

</indexterm> </para>

  
  

</sect1><sect1 id="a0000000094" remap="section">
  <title>Spectral density</title>
    
  
  <para>To understand <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise, we have to take a detour to understand spectral density. If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0157.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h(t)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a signal that varies in time, it can be described by its power spectral density, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0158.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P(f)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is a function that maps from a frequency, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, to the amount of power the signal contains at that frequency. <indexterm>
  <primary>spectral density</primary>

</indexterm> <indexterm>
  <primary>power</primary>

</indexterm> <indexterm>
  <primary>frequency</primary>

</indexterm> </para>

  
  <para>This analysis applies to any varying signal, but I use sound as an example. The note we call “middle A” corresponds to a frequency of 440 cycles per second, or Hertz (Hz). If you strike a middle A tuning fork, it produces a sound that is close to a pure sine wave at 440 Hz. But if you play the same note on a piano, what you hear is a complex sound that contains components at many different frequencies. The frequency with the most power is 440, which is why we perceive the sound as a middle A, but there are also components at 660, 880, and many higher frequencies. These components are called “harmonics.” <indexterm>
  <primary>pitch</primary>

</indexterm> <indexterm>
  <primary>Hertz</primary>

</indexterm> <indexterm>
  <primary>harmonics</primary>

</indexterm> </para>

  
  <para>What we identify as the pitch of a sound is usually the dominant frequency component. But if a sound contains many different components with roughly the same power, it has no particular pitch. To our ears, it sounds like noise. <indexterm>
  <primary>noise</primary>

</indexterm> </para>

  
  <para>Spectral analysis is the process of taking a signal and computing its spectral density<footnote><para>The presentation here follows Press et al, <emphasis>Numerical Recipes in C</emphasis>.</para></footnote>. The first step is to compute the Fourier transform of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0157.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h(t)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>: <indexterm>
  <primary>Fourier transform</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000095" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0159.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  H(\omega ) = \int _{-\infty }^{\infty } h(t) e^{i \omega t} dt  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0160.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$\omega = 2 \pi f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the angular frequency in radians per second (rather than cycles per second). The advantage of working with angular frequency is that it reduces the number of times the term <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0161.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$2 \pi $</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> appears. <indexterm>
  <primary>angular frequency</primary>

</indexterm> </para>

  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0162.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H(\omega )$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is written with a capital letter because it is a complex number, which you can think of as a vector with a magnitude, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0163.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$|H(\omega )|$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and an angle. The power spectral density is related to the Fourier transform by the following relation: <indexterm>
  <primary>power spectral density</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000096" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0164.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  P(f) = |H(2 \pi f)|^2  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Depending on the application, we may not care about the difference between <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0042.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0165.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. In that case, we would use the one-sided power spectral density: </para>

  
  <para><informalequation id="a0000000097" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0166.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  P(f) = |H(2 \pi f)|^2 + |H(-2 \pi f)|^2  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>So far we have assumed that <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0157.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h(t)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is a continuous function, but often it is a series of values at discrete times. In that case we can replace the continuous Fourier transform with the discrete Fourier transform (DFT). Suppose that we have <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0167.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> values <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0168.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h_ k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0053.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in the range from 0 to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0169.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N-1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. The DFT is written <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is an index related to frequency: <indexterm>
  <primary>discrete Fourier transform</primary>

</indexterm> <indexterm>
  <primary>DFT</primary>

</indexterm> </para>

  
  <para><informalequation id="dft" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0171.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\begin{equation}  \label{dft} H_ n = \sum _{k=0}^{N-1} h_ k e^{2 \pi i k n / N} \end{equation}</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Each element of this sequence corresponds to a particular frequency. If the elements of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0168.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h_ k$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> are equally spaced in time, with time step <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0076.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the frequency that corresponds to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is </para>

  
  <para><informalequation id="a0000000098" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0172.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  f_ n = \frac{n}{N d}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>To get the one-sided power spectral density, you can compute <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in the range <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0173.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$-N/2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0174.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N/2$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and </para>

  
  <para><informalequation id="a0000000099" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0175.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  P_ n = |H_ n|^2 + |H_{-n}|^2  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>To avoid negative indices, it is conventional to compute <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in the range <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0176.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0169.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N-1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and use the relation <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0177.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_{-n} = H_{N-n}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to convert. </para>

  
  

  
  <para>Write a function named <literal>dft</literal> that takes <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, a sequence of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0167.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> values, and returns the sequence <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0012.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> in the range <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0176.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$0$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0169.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N-1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>Python provides support for complex numbers as a built-in type. The function <literal>complex</literal> takes two arguments, a real part and an imaginary part, and returns a complex number: <indexterm>
  <primary sortas="complex">complex</primary>

</indexterm> </para>

  
  <programlisting>&gt;&gt;&gt; complex(1, 1)
(1+1j)</programlisting>

  
  <para>The <literal>cmath</literal> module provides math functions that support complex numbers: </para>

  
  <programlisting>&gt;&gt;&gt; import cmath
&gt;&gt;&gt; i = complex(0, 1)
&gt;&gt;&gt; N = 128
&gt;&gt;&gt; cmath.exp(2 * math.pi * i / N)
(0.99879545620517241+0.049067674327418015j)</programlisting>

  
  <para>What is the order of growth run time of <literal>dft</literal>? </para>

  
  <para><emphasis role="bold">Hoisting</emphasis> is a way to speed up code by moving an expression that does not change out of a loop. See <ulink url="http://en.wikipedia.org/wiki/Loop-invariant_code_motion">http://en.wikipedia.org/wiki/Loop-invariant_code_motion</ulink>. You can make your code easier to read and more efficient by hoisting: <indexterm>
  <primary>hoisting</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000100" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0179.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\begin{equation}  W = e^{2 \pi i / N} \end{equation}</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para> What effect does hoisting have on the order of growth? <indexterm>
  <primary>order of growth</primary>

</indexterm> </para>

  
  

</sect1><sect1 id="a0000000101" remap="section">
  <title>Fast Fourier Transform</title>
    
  
  <para>The Fast Fourier Transform (FFT) is an efficient algorithm for computing the DFT. It is often attributed to Cooley and Tukey, but it was independently discovered several times earlier. See <ulink url="http://en.wikipedia.org/wiki/Fast_Fourier_transform">http://en.wikipedia.org/wiki/Fast_Fourier_transform</ulink>. <indexterm>
  <primary>Fast Fourier Transform</primary>

</indexterm> <indexterm>
  <primary>FFT</primary>

</indexterm> </para>

  
  <para>The first step toward the FFT is to rewrite Equation <xref linkend="dft" /> with the substitution <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0180.png" depth="9.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$W = e^{2 \pi i/N}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>: </para>

  
  <para><informalequation id="a0000000102" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0181.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\begin{equation}  H_ n = \sum _{k=0}^{N-1} h_ k W^{n k} \end{equation}</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>The second step is the Danielson-Lanczos Lemma which states <indexterm>
  <primary>Danielson-Lanczos Lemma</primary>

</indexterm> </para>

  
  <para><informalequation id="a0000000103" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0182.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  H_ n = H^ e_ n + W^ k H^ o_ n  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>where <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0183.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ e$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the DFT of the even-indexed elements of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0184.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ o$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is the DFT of the odd-indexed elements. This lemma follows naturally from the definition of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0170.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H_ n$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>; you can see a proof at <ulink url="mathworld.wolfram.com/Danielson-LanczosLemma.html">mathworld.wolfram.com/Danielson-LanczosLemma.html</ulink>. </para>

  
  <para>This lemma suggests a recursive algorithm for evaluating the DFT of a sequence <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> has only a single element, then <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0185.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H=h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Otherwise: <indexterm>
  <primary>recursive algorithm</primary>

</indexterm> </para>

  
  <para><orderedlist>
  
  <listitem>
  
  <para>Split <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> into <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0186.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h^ e$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0187.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h^ o$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
  <listitem>
  
  <para>Compute <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0183.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ e$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0184.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ o$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> by making two recursive calls. </para>
</listitem>
  
  <listitem>
  
  <para>Use the lemma to combine <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0183.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ e$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0184.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ o$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> to form <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0188.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
</orderedlist></para>

  
  <para>If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0188.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> has <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0189.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$2N$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> elements, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0183.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ e$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0184.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ o$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> have only <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0167.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. In order to merge them, you have to wrap around, but you can do that because <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0190.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$H^ e_{n+N} = H^ e_{n}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>This recursive algorithm is the Fast Fourier Transform. </para>

  
  

  
  <para>Write a function called <literal>fft</literal> that implements the Fast Fourier Transform. To check your function, you can compare it to the function <literal>fft</literal> provided by the module <literal>numpy.fft</literal>. </para>

  
  <para>What is the order of growth run time of your implementation? What is the order of growth for the space required? </para>

  
  <para>Most FFT implementations use a clever indexing scheme to avoid copying the sequence; instead, they transform the elements in place. You can read <ulink url="wikipedia.org/wiki/Butterfly_diagram">wikipedia.org/wiki/Butterfly_diagram</ulink> to get the details. <indexterm>
  <primary>indexing</primary>

</indexterm> </para>

  
  <para>Once your <literal>fft</literal> is working, write a function named <literal>psd</literal> that takes a sequence, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0178.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$h$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and returns its one-sided power spectral density, <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0191.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$P$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>

  
  <para>You can download my solution from <ulink url="thinkcomplex.com/Fourier.py">thinkcomplex.com/Fourier.py</ulink>. </para>

  
  

</sect1><sect1 id="a0000000104" remap="section">
  <title>Pink noise</title>
    
  
  <para>In a followup paper in 1988, Bak, Tang and Wiesenfeld looked at a time series <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0192.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$F(t)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, which is the number of cells that exceed the threshold during each time step. If I understand their model, they seed avalanches by incrementing the state of a random cell at random intervals; for example, there might be a fixed probability during each time step that a cell is incremented. In this model (unlike the previous one) there may be more than one avalanche at a time. <indexterm>
  <primary>pink noise</primary>

</indexterm> <indexterm>
  <primary sortas="1/f noise">1/f noise</primary>

</indexterm> </para>

  
  <para>A plot of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0192.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$F(t)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> shows that it is noisy, but not completely random, which is consistent with pink, or <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise. As a stronger test, they plot the power spectral density of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0193.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$F$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> on a log-log scale. If <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0193.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$F$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise, then </para>

  
  <para><informalequation id="a0000000105" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0194.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  P_ n \sim 1 / f_ n = \frac{N d}{n}  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>Since the units of time in this model are arbitrary, we can choose <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0195.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$d=1$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Taking the log of both sides yields: </para>

  
  <para><informalequation id="a0000000106" remap="equation">
  
  <mediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0196.png" depth="0px" role="math" scale="25" valign="middle"></imagedata>
    </imageobject>
    <textobject role="tex">
      <phrase>\[  \log P_ n \sim \log N - \log n  \]</phrase>
    </textobject>
  </mediaobject>
</informalequation></para>

  
  <para>So on a log-log scale, the PSD of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise is a straight line with slope -1. <indexterm>
  <primary>log-log plot</primary>

</indexterm> </para>

  
  

  
  <para>Modify your implementation of the sand pile model to increment a random cell at random intervals and record the number of cells that exceed the threshold during each time step. </para>

  
  <para>To estimate the average PSD, you can divide the time series into chunks of 128 to 256 values, compute the PSD of each chunk, and average together the PSDs. Plot the result on a log-log scale and estimate the slope. </para>

  
  

  
  

  
  <para>In a 1989 paper, “Self-organized criticality in the ’Game of Life’,” Bak, Chen and Creutz present evidence that the Game of Life is a self-organized critical system. <indexterm>
  <primary>Game of Life</primary>

</indexterm> <indexterm>
  <primary>self-organized criticality</primary>

</indexterm> </para>

  
  <para>To replicate their tests, run the GoL CA until it stabilizes, then choose a random cell and toggle it. Run the CA until it stabilizes again, keeping track of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the number of timesteps it takes, and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0081.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the number of cells affected. Repeat for a large number of trials and plot the distributions of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0059.png" depth="6.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$t$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0081.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$s$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Also, see if you can think of an effective experiment to test for <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise. </para>

  
  <para>Some later work has called the conclusions of this paper into question. You might want to read Blok, “Life without bounds,” at <ulink url="zoology.ubc.ca/~rikblok/lib/blok95b.html">zoology.ubc.ca/~rikblok/lib/blok95b.html</ulink>. </para>

  
  

</sect1><sect1 id="a0000000107" remap="section">
  <title>Reductionism and Holism</title>
    
  
  <para>The original paper by Bak, Tang and Wiesenfeld is one of the most frequently-cited papers in the last few decades. Many new systems have been shown to be self-organized critical, and the sand-pile model, in particular, has been studied in detail. <indexterm>
  <primary>sand pile model</primary>

</indexterm> </para>

  
  <para>As it turns out, the sand-pile model is not a very good model of a sand pile. Sand is dense and not very sticky, so momentum has a non-negligible effect on the behavior of avalanches. As a result, there are fewer very large and very small avalanches than the model predicts, and the distribution is not long tailed. </para>

  
  <para>Bak has suggested that this observation misses the point. The sand pile model is not meant to be a realistic model of a sand pile; it is meant to be a simple example of a broad category of models. </para>

  
  <para>To understand this point, it is useful to think about two kinds of models, <emphasis role="bold">reductionist</emphasis> and <emphasis role="bold">holistic</emphasis>. A reductionist model describes a system by describing its parts and their interactions. When a reductionist model is used as an explanation, it depends on an analogy between the components of the model and the components of the system. <indexterm>
  <primary>reductionist</primary>

</indexterm> <indexterm>
  <primary>holist</primary>

</indexterm> </para>

  
  <para>For example, to explain why the ideal gas law holds, we can model the molecules that make up a gas with point masses, and model their interactions as elastic collisions. If you simulate or analyze this model you find that it obeys the ideal gas law. This model is satisfactory to the degree that molecules in a gas behave like molecules in the model. The analogy is between the parts of the system and the parts of the model. <indexterm>
  <primary>analogy</primary>

</indexterm> </para>

  
  <para>Holistic models are more focused on similarities between systems and less interested in analogous parts. A holistic approach to modeling often consists of two steps, not necessarily in this order: <indexterm>
  <primary>holistic model</primary>

</indexterm> </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Identify a kind of behavior that appears in a variety of systems. </para>
</listitem>
  
    <listitem>
  
  <para>Find the simplest model that demonstrates that behavior. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>For example, in <emphasis>The Selfish Gene</emphasis>, Richard Dawkins suggests that genetic evolution is just one example of an evolutionary system. He identifies the essential elements of the category—discrete replicators, variability and differential reproduction—and proposes that any system that has these elements displays similar behavior, including complexity without design. <indexterm>
  <primary sortas="Selfish Gene">The Selfish Gene</primary>

</indexterm> <indexterm>
  <primary>Dawkins, Richard</primary>

</indexterm> <indexterm>
  <primary>evolution</primary>

</indexterm> </para>

  
  <para>As another example of an evolutionary system, he proposes memes, which are thoughts or behaviors that are “replicated” by transmission from person to person. As memes compete for the resource of human attention, they evolve in ways that are similar to genetic evolution. <indexterm>
  <primary>meme</primary>

</indexterm> <indexterm>
  <primary>replicator</primary>

</indexterm> </para>

  
  <para>Critics of memetics have pointed out that memes are a poor analogy for genes. Memes differ from genes in many obvious ways. But Dawkins has argued that these differences are beside the point because memes are not <emphasis>supposed</emphasis> to be analogous to genes. Rather, memetics and genetics are examples of the same category—evolutionary systems. The differences between them emphasize the real point, which is that evolution is a general model that applies to many seemingly disparate systems. <indexterm>
  <primary>gene</primary>

</indexterm> <indexterm>
  <primary>genetics</primary>

</indexterm> </para>

  
  <para>Bak has made a similar argument that self-organized criticality is a general model for a broad category of systems. According to Wikipedia, “SOC is typically observed in slowly-driven non-equilibrium systems with extended degrees of freedom and a high level of nonlinearity.” <indexterm>
  <primary>Bak, Per</primary>

</indexterm> </para>

  
  <para>Many natural systems demonstrate behaviors characteristic of critical systems. Bak’s explanation for this prevalence is that these systems are examples of the broad category of self-organized criticality. There are two ways to support this argument. One is to build a realistic model of a particular system and show that the model exhibits SOC. The second is to show that SOC is a feature of many diverse models, and to identify the essential characteristics those models have in common. </para>

  
  <para>The first approach, which I characterize as reductionist, can explain the behavior of a particular system. The second, holistic, approach, explains the prevalence of criticality in natural systems. They are different models with different purposes. <indexterm>
  <primary>prevalence</primary>

</indexterm> </para>

  
  <para>For reductionist models, realism is the primary virtue, and simplicity is secondary. For holistic models, it is the other way around. </para>

  
  

  
  <para>Read <ulink url="wikipedia.org/wiki/Reductionism">wikipedia.org/wiki/Reductionism</ulink> and <ulink url="wikipedia.org/wiki/Holism">wikipedia.org/wiki/Holism</ulink>. </para>

  
  

  
  

  
  <para>In a 1996 paper in Nature, Frette et al report the results of experiments with rice piles. They find that some kinds of rice yield evidence of critical behavior, but others do not. <indexterm>
  <primary>rice pile model</primary>

</indexterm> </para>

  
  <para>Similarly, Pruessner and Jensen studied large-scale versions of the forest fire model (using an algorithm similar to Newman and Ziff’s). In their 2004 paper, “Efficient algorithm for the forest fire model,” they present evidence that the system is not critical after all. <indexterm>
  <primary>forest fire model</primary>

</indexterm> </para>

  
  <para>How do these results bear on Bak’s claim that SOC explains the prevalence of critical phenomena in nature? </para>

  
  

  
  

  
  <para>In <emphasis>The Fractal Geometry of Nature</emphasis>, Benoit Mandelbrot proposes an alternative explanation for the prevalence of long-tailed distributions in natural systems. It may not be, as Bak suggests, that many systems can generate this behavior in isolation. Instead there may be only a few, but there may be interactions between systems that cause the behavior to propagate. <indexterm>
  <primary sortas="Fractal Geometry of Nature">The Fractal Geometry of Nature</primary>

</indexterm> <indexterm>
  <primary>Mandelbrot, Benoit</primary>

</indexterm> <indexterm>
  <primary>long-tailed distribution</primary>

</indexterm> </para>

  
  <para>To support this argument, Mandelbrot points out: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Interactions between systems may be characterized by operations that are (at least approximately) like convolution. For example, if you choose value <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0061.png" depth="4.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$a$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> from distribution <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0001.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$A$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, and independently choose value <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0033.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$b$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> from distribution <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0002.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$B$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>, the distribution of the sum is the convolution of <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0001.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$A$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0002.png" depth="7px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$B$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. </para>
</listitem>
  
    <listitem>
  
  <para>Long-tailed distributions are stable under convolution; that is, if you convolve a long-tailed distribution with another distribution, the result is long-tailed. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Would you characterize Mandelbrot’s argument as reductionist or holist? </para>

  
  

</sect1><sect1 id="a0000000108" remap="section">
  <title>SOC, causation and prediction</title>
    
  
  <para>If a stock market index drops by a fraction of a percent in a day, there is no need for an explanation. But if it drops 10%, people want to know why. Pundits on television are willing to offer explanations, but the real answer may be that there is no explanation. <indexterm>
  <primary>stock market</primary>

</indexterm> </para>

  
  <para>Day-to-day variability in the stock market shows evidence of criticality: the distribution of value changes is long-tailed and the time series exhibits <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0152.png" depth="7.750px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$1/f$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> noise. If the stock market is a self-organized critical system, we should expect occasional large changes as part of the ordinary behavior of the market. <indexterm>
  <primary sortas="1/f noise">1/f noise</primary>

</indexterm> </para>

  
  <para>The distribution of earthquake sizes is also long-tailed, and there are simple models of the dynamics of geological faults that might explain this behavior. If these models are right, they imply that large earthquakes are unexceptional; that is, they do not require explanation any more than small earthquakes do. <indexterm>
  <primary>earthquake</primary>

</indexterm> <indexterm>
  <primary>prediction</primary>

</indexterm> <indexterm>
  <primary>causation</primary>

</indexterm> </para>

  
  <para>Similarly, Charles Perrow has suggested that failures in large engineered systems, like nuclear power plants, are like avalanches in the sand pile model. Most failures are small, isolated and harmless, but occasionally a coincidence of bad fortune yields a catastrophe. When big accidents occur, investigators go looking for the cause, but if Perrow’s “normal accident theory” is correct, there may be no cause. <indexterm>
  <primary>normal accident theory</primary>

</indexterm> <indexterm>
  <primary>Perrow, Charles</primary>

</indexterm> </para>

  
  <para>These conclusions are not comforting. Among other things, they imply that large earthquakes and some kinds of accidents are fundamentally unpredictable. It is impossible to look at the state of a critical system and say whether a large avalanche is “due.” If the system is in a critical state, then a large avalanche is always possible. It just depends on the next grain of sand. </para>

  
  <para>In a sand-pile model, what is the cause of a large avalanche? Philosophers sometimes distinguish the <emphasis role="bold">proximate</emphasis> cause, which is most immediately responsible, from the <emphasis role="bold">ultimate</emphasis> cause, which is, for whatever reason, considered the true cause. <indexterm>
  <primary>proximate cause</primary>

</indexterm> <indexterm>
  <primary>ultimate cause</primary>

</indexterm> </para>

  
  <para>In the sand-pile model, the proximate cause of an avalanche is a grain of sand, but the grain that causes a large avalanche is identical to any other grain, so it offers no special explanation. The ultimate cause of a large avalanche is the structure and dynamics of the systems as a whole: large avalanches occur because they are a property of the system. </para>

  
  <para>Many social phenomena, including wars, revolutions, epidemics, inventions and terrorist attacks, are characterized by long-tailed distributions. If the reason for these distributions is that social systems are critical, that suggests that major historical events may be fundamentally unpredictable and unexplainable. <indexterm>
  <primary>long-tailed distributions</primary>

</indexterm> </para>

  
  

  
  <para>Read about the “Great Man” theory of history at <ulink url="wikipedia.org/wiki/Great_man_theory">wikipedia.org/wiki/Great_man_theory</ulink>. What implication does self-organized criticality have for this theory? <indexterm>
  <primary>Great Man theory</primary>

</indexterm> </para>

  
  

</sect1>
</chapter><chapter id="a0000000109">
  <title>Agent-based models</title>
  <sect1 id="a0000000110" remap="section">
  <title>Thomas Schelling</title>
    
  
  <para>In 1971 Thomas Schelling published “Dynamic Models of Segregation,” which proposes a simple model of racial segregation. The Schelling model of the world is a grid; each cell represents a house. The houses are occupied by two kinds of “agents,” which I label red and blue, in roughly equal numbers. About 10% of the houses are empty. <indexterm>
  <primary>Schelling, Thomas</primary>

</indexterm> </para>

  
  <para>At any point in time, an agent might be happy or unhappy, depending on the other agents in the neighborhood. The neighborhood of each house is the set of eight adjacent cells. In one version of the model, agents are happy if they have at least two neighbors like themselves, and unhappy if they have one or zero. <indexterm>
  <primary>agent-based model</primary>

</indexterm> </para>

  
  <para>The simulation proceeds by choosing an agent at random and checking to see whether it is happy. If so, then nothing happens; if not, the agent chooses one of the unoccupied cells at random and moves. </para>

  
  <para>You might not be surprised to hear that this model leads to some segregation, but you might be surprised by the degree. Fairly quickly, clusters of similar agents appear. The clusters grow and coalesce over time until there are a small number of large clusters and most agents live in homogeneous neighborhoods. <indexterm>
  <primary>segregation</primary>

</indexterm> </para>

  
  <para>If you did not know the process and only saw the result, you might assume that the agents were racist, but in fact all of them would be perfectly happy in a mixed neighborhood. Since they prefer not to be greatly outnumbered, they might be considered xenophobic at worst. Of course, these agents are a wild simplification of real people, so it may not be appropriate to apply these descriptions at all. <indexterm>
  <primary>racism</primary>

</indexterm> <indexterm>
  <primary>xenophobia</primary>

</indexterm> </para>

  
  <para>Racism is a complex human problem; it is hard to imagine that such a simple model could shed light on it. But in fact it provides a strong argument about the relationship between a system and its parts: if you observe segregation in a real city, you cannot conclude that individual racism is the immediate cause, or even that the people in the city are racists. <indexterm>
  <primary>causation</primary>

</indexterm> </para>

  
  <para>But we have to keep in mind the limitations of this argument: Schelling’s model demonstrates a possible cause of segregation, but says nothing about actual causes. </para>

  
  

  
  <para>Implement Schelling’s model in a grid. From random initial conditions, how does the system evolve? </para>

  
  <para>Define a statistic that measures the degree of segregation, and plot this statistic over time. </para>

  
  <para>Experiment with the parameters of the model. What happens as the agents become more tolerant? What happens if the agents are only happy in mixed neighborhoods; that is, if they are unhappy if too many of their neighbors are like themselves? <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  

  
  

  
  <para>In a recent book, <emphasis>The Big Sort</emphasis>, Bill Bishop argues that American society is increasingly segregated by political opinion, as people choose to live among like-minded neighbors. <indexterm>
  <primary sortas="Big Sort">The Big Sort</primary>

</indexterm> <indexterm>
  <primary>Bishop, Bill</primary>

</indexterm> </para>

  
  <para>The mechanism Bishop hypothesizes is not that people, like the agents in Schelling’s model, are more likely to move if they are isolated, but that when they move for any reason, they are likely to choose a neighborhood with people like themselves. </para>

  
  <para>Modify your implementation of Schelling’s model to simulate this kind of behavior and see if it yields similar degrees of segregation. </para>

  
  

</sect1><sect1 id="a0000000111" remap="section">
  <title>Agent-based models</title>
    
  
  <para>Schelling’s model is one of the first, and one of the most famous, agent-based models. Since the 1970s, agent-based modeling has become an important tool in economics and other social sciences, and in some natural sciences. <indexterm>
  <primary>agent-based model</primary>

</indexterm> </para>

  
  <para>The characteristics of agent-based models include: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Agents that model intelligent behavior, usually with a simple set of rules. </para>
</listitem>
  
    <listitem>
  
  <para>The agents are usually situated in space (or in a network), and interact with each other locally. </para>
</listitem>
  
    <listitem>
  
  <para>They usually have imperfect, local information. </para>
</listitem>
  
    <listitem>
  
  <para>Often there is variability between agents. </para>
</listitem>
  
    <listitem>
  
  <para>Often there are random elements, either among the agents or in the world. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Agent-based models are useful for modeling the dynamics of systems that are not in equilibrium (although they are also used to study equilibrium). And they are particularly useful for understanding relationships between individual decisions and system behavior, or as in the title of Schelling’s book, <emphasis>Micromotives and Macrobehavior</emphasis>. <indexterm>
  <primary sortas="Micromotives and Macrobehavior">Micromotives and Macrobehavior</primary>

</indexterm> </para>

  
  <para>For more about agent-based modeling, see <ulink url="wikipedia.org/wiki/Agent-based_model">wikipedia.org/wiki/Agent-based_model</ulink>. </para>

</sect1><sect1 id="a0000000112" remap="section">
  <title>Traffic jams</title>
    
  
  <para>What causes traffic jams? In some cases there is an obvious cause, like an accident, a speed trap, or something else that disturbs the flow of traffic. But other times traffic jams appear for no apparent reason. <indexterm>
  <primary>traffic jam</primary>

</indexterm> </para>

  
  <para>Agent-based models can help explain spontaneous traffic jams. As an example, I implemented a simple highway simulation, based on a model in Resnick, <emphasis>Turtles, Termites and Traffic Jams</emphasis>. <indexterm>
  <primary sortas="Turtles, Termites and Traffic Jams">Turtles, Termites and Traffic Jams</primary>

</indexterm> <indexterm>
  <primary>Resnick, Mitchell</primary>

</indexterm> </para>

  
  <para>You can download my program from <ulink url="thinkcomplex.com/Highway.py">thinkcomplex.com/Highway.py</ulink>. It uses <literal>TurtleWorld</literal>, which is part of Swampy. See <ulink url="thinkpython.com/swampy">thinkpython.com/swampy</ulink>. <indexterm>
  <primary>Swampy</primary>

</indexterm> </para>

  
  <para>This module defines two classes: <literal>Highway</literal>, which inherits from TurtleWorld, and <literal>Driver</literal>, which inherits from Turtle. </para>

  
  <para>The Highway is a one-lane road that forms a circle, but it is displayed as a series of rows that spiral down the canvas. </para>

  
  <para>Each driver starts with a random position and speed. At each time step, each Driver accelerates or brakes based on the distance between it and the Driver in front. Here is an example: </para>

  
  <programlisting>def choose_acceleration(self, dist):
        if dist &lt; self.safe_distance:
            return -1
        else:
            return 0.3</programlisting>

  
  <para>If the following distance is too short, the <literal>Driver</literal> brakes; otherwise it accelerates. In addition, if the current speed would cause a collision, the <literal>Driver</literal> comes to a complete stop. And there is a speed limit for each driver. </para>

  
  <para>If you run <literal>Highway.py</literal> you will probably see a traffic jam, and the natural question is, “Why?” There is nothing about the <literal>Highway</literal> or <literal>Driver</literal> behavior that obviously causes traffic jams. </para>

  
  

  
  <para>Experiment with the parameters of the system to identify the factors that are necessary and sufficient to cause traffic jams. Some of the factors to explore are: <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Density:</term>
      <listitem>
  
  <para>What happens as the number of drivers increases (or the length of the highway)? </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Acceleration and braking:</term>
      <listitem>
  
  <para>What happens if drivers accelerate faster or brake more gently? </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Safe distance:</term>
      <listitem>
  
  <para>What happens as the safe distance between drivers changes? </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Heterogeneity:</term>
      <listitem>
  
  <para>What if all drivers are not the same; for example, if they have different speed limits or following distances? </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  

</sect1><sect1 id="a0000000113" remap="section">
  <title>Boids</title>
    
  
  <para>In 1987 Craig Reynolds published an article, “Flocks, herds and schools: A distributed behavioral model,” that describes an agent-based model of herd behavior. Agents in this models are called “boids,” which is both a contraction of “bird-oid” and an accented pronunciation of “bird,” (although boids are also used to model fish and herding land animals). <indexterm>
  <primary>boid</primary>

</indexterm> <indexterm>
  <primary>Reynolds, Craig</primary>

</indexterm> </para>

  
  <para>You can read an overview of the boid algorithm at <ulink url="http://red3d.com/cwr/boids/">http://red3d.com/cwr/boids/</ulink>. Each agent simulates three behaviors: </para>

  
  <para><variablelist>
  <varlistentry>
    <term>Collision avoidance:</term>
      <listitem>
  
  <para>avoid obstacles, including other birds. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Flock centering:</term>
      <listitem>
  
  <para>move toward the center of the flock. </para>
</listitem>
  </varlistentry><varlistentry>
    <term>Velocity matching:</term>
      <listitem>
  
  <para>align velocity with neighboring birds. </para>
</listitem>
  </varlistentry>
</variablelist></para>

  
  <para>Boids make decisions based on local information only; each boid only sees (or pays attention to) other boids in its field of vision and range. <indexterm>
  <primary>local information</primary>

</indexterm> </para>

  
  <para>The <literal>Visual</literal> package, also known as VPython, is well-suited for implementing boids. It provides simple 3-D graphics as well as vector objects and operations that are useful for the computations. <indexterm>
  <primary>Visual package</primary>

</indexterm> <indexterm>
  <primary>VPython</primary>

</indexterm> </para>

  
  <para>You can download my implementation from <ulink url="thinkcomplex.com/Boids.py">thinkcomplex.com/Boids.py</ulink>. It is based in part on the description of boids in Flake, <emphasis>The Computational Beauty of Nature</emphasis>. </para>

  
  <para>The program defines two classes: <literal>Boid</literal>, which implements the boid algorithm, and <literal>World</literal>, which contains a list of Boids and a “carrot” the Boids are attracted to. <indexterm>
  <primary>carrot</primary>

</indexterm> </para>

  
  <para>The boid algorithm uses <literal remap="verb">get_neighbors</literal> to find other boids in the field of view: </para>

  
  <programlisting>def get_neighbors(self, others, radius, angle):
        boids = []
        for other in others:
            if other is self:
               continue

            offset = other.pos - self.pos

            # if not in range, skip it
            if offset.mag &gt; radius:
                continue

            # if not within viewing angle, skip it
            if self.vel.diff_angle(offset) &gt; angle:
                continue

            # otherwise add it to the list
            boids.append(other)

        return boids</programlisting>

  
  <para><literal remap="verb">get_neighbors</literal> uses vector subtraction to compute the vector from <literal>self</literal> to <literal>other</literal>. The magnitude of this vector is the distance to the other boid. <literal remap="verb">diff_angle</literal> computes the angle between the velocity of <literal>self</literal>, which is also the line of sight, and the other boid. </para>

  
  <para><literal>center</literal> finds the center of mass of the boids in the field of view and returns a vector pointing toward it: </para>

  
  <programlisting>def center(self, others):
        close = self.get_neighbors(others, r_center, a_center)
        t = [other.pos for other in close]
        if t:
            center = sum(t)/len(t)
            toward = vector(center - self.pos)
            return limit_vector(toward)
        else:
            return null_vector</programlisting>

  
  <para>Similarly, <literal>avoid</literal> finds the center of mass of any obstacles in range and returns a vector pointing away from it, <literal>copy</literal> returns the difference between the current heading and the average heading of the neighbors, and <literal>love</literal> computes the heading toward the carrot. </para>

  
  <para><literal remap="verb">set_goal</literal> computes the weighed sum of these goals and sets the overall goal: </para>

  
  <programlisting>def set_goal(self, boids, carrot):
        self.goal = (w_avoid * self.avoid(boids, carrot) +
                     w_center * self.center(boids) +
                     w_copy * self.copy(boids) +
                     w_love * self.love(carrot))</programlisting>

  
  <para>Finally, <literal>move</literal> updates the velocity, position and attitude of the boid: </para>

  
  <programlisting>def move(self, mu=0.1):
        self.vel = (1-mu) * self.vel + mu * self.goal
        self.vel.mag = 1

        self.pos += dt * self.vel
        self.axis = b_length * self.vel.norm()</programlisting>

  
  <para>The new velocity is the weighted sum of the old velocity and the goal. The parameter <literal>mu</literal> determines how quickly the birds can change speed and direction. The time step, <literal>dt</literal> determines how far the boids move. <indexterm>
  <primary>weighted sum</primary>

</indexterm> </para>

  
  <para>Many parameters influence flock behavior, including the range, angle and weight for each behavior, and the maneuverability, <literal>mu</literal>. <indexterm>
  <primary>flock behavior</primary>

</indexterm> </para>

  
  <para>These parameters determine the ability of the boids to form and maintain a flock and the patterns of motion and organization in the flock. For some settings, the boids resemble a flock of birds; other settings resemble a school of fish or a cloud flying insects. </para>

  
  

  
  <para>Run my implementation of the boid algorithm and experiment with different parameters. What happens if you “turn off” one of the behaviors by setting the weight to 0? <indexterm>
  <primary>parameter</primary>

</indexterm> </para>

  
  <para>To generate more bird-like behavior, Flake suggests adding a fourth behavior to maintain a clear line of sight; in other words, if there is another bird nearly directly ahead, the boid should move away laterally. What effect do you expect this rule to have on the behavior of the flock? Implement it and see. </para>

  
  

</sect1><sect1 id="a0000000114" remap="section">
  <title>Prisoner’s Dilemma</title>
    
  
  <para>The Prisoner’s Dilemma is a topic of study in game theory, so it’s not the fun kind of game. Instead, it is the kind of game that sheds light on human motivation and behavior. <indexterm>
  <primary>Prisoner’s Dilemma</primary>

</indexterm> </para>

  
  <para>Here is the presentation of the dilemma from <ulink url="http://en.wikipedia.org/wiki/Prisoner’s_dilemma">http://en.wikipedia.org/wiki/Prisoner’s_dilemma</ulink>. </para>

  
  <blockquote remap="quote">
  <para> Two suspects [Alice and Bob] are arrested by the police. The police have insufficient evidence for a conviction, and, having separated the prisoners, visit each of them to offer the same deal. If one testifies for the prosecution against the other (defects) and the other remains silent (cooperates), the defector goes free and the silent accomplice receives the full one-year sentence. If both remain silent, both prisoners are sentenced to only one month in jail for a minor charge. If each betrays the other, each receives a three-month sentence. Each prisoner must choose to betray the other or to remain silent. Each one is assured that the other would not know about the betrayal before the end of the investigation. How should the prisoners act? </para>
</blockquote>

  
  <para>Notice that in this context, “cooperate” means to keep silent, not to cooperate with police. </para>

  
  <para>It is tempting to say that the players should cooperate with each other, since they would both be better off. But neither player knows what the other will do. Looking at it from Bob’s point of view: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>If Alice remains silent, Bob is better off defecting. </para>
</listitem>
  
    <listitem>
  
  <para>If Alice defects, Bob is better off defecting. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>Either way, Bob is better off defecting. And from her point of view, Alice reaches the same conclusion. So if both players do the math, and no other factors come into play, we expect them to defect and be worse off for it. <indexterm>
  <primary>game theory</primary>

</indexterm> </para>

  
  <para>This result is saddening because it is an example of how good intentions can lead to bad outcomes, and, unfortunately, it applies to other scenarios in real life, not just hypothetical prisoners. </para>

  
  <para>But in real life, the game is often iterated; that is, the same players face each other over and over, so they have the opportunity to learn, react and communicate, at least implicitly. <indexterm>
  <primary>iterated Prisoner’s dilemma</primary>

</indexterm> </para>

  
  <para>The iterated version of the game is not as easy to analyze; it is not obvious what the optimal strategy is or even whether one exists. </para>

  
  <para>So in the late 1970s Robert Axelrod organized a tournament to compare strategies. He invited participants to submit strategies in the form of computer programs, then played the programs against each other and kept score. <indexterm>
  <primary>Axelrod, Robert</primary>

</indexterm> </para>

  
  <para>I won’t tell you the outcome, and if you don’t know you should resist the temptation to look it up. Instead, I encourage you to run your own tournament. I’ll provide the referee; you provide the players. </para>

  
  

  
  <para>Download <ulink url="thinkcomplex.com/Referee.py">thinkcomplex.com/Referee.py</ulink>, which runs the tournament, and <ulink url="thinkcomplex.com/PlayerFlipper.py">thinkcomplex.com/PlayerFlipper.py</ulink>, which implements a simple player strategy. </para>

  
  <para>Here is the code from <literal>PlayerFlipper.py</literal>: </para>

  
  <programlisting>def move(history):
    mine, theirs = history
    if len(mine) % 2 == 0:
        return 'C'
    else:
        return 'D'</programlisting>

  
  <para>Any file that matches the pattern <literal>Player*.py</literal> is recognized as a player. The file should contain a definition for <literal>move</literal>, which takes the history of the match so far and returns a string: <literal>’D’</literal> for defect and <literal>’C’</literal> for cooperate. </para>

  
  <para><literal>history</literal> is a pair of lists: the first list contains the player’s previous responses in order; the second contains the opponent’s responses. </para>

  
  <para><literal>PlayerFlipper</literal> checks whether the number of previous rounds is even or odd and returns <literal>’C’</literal> or <literal>’D’</literal> respectively. </para>

  
  <para>Write a <literal>move</literal> function in a file like <literal>PlayerFlipper.py</literal>, but replace <literal>Flipper</literal> with a name that summarizes your strategy. </para>

  
  <para>Run <literal>Referee.py</literal> and see how your strategy does. </para>

  
  

</sect1><sect1 id="a0000000115" remap="section">
  <title>Emergence</title>
    
  
  <para>The examples in this chapter have something in common: emergence. An <emphasis role="bold">emergent property</emphasis> is a characteristic of a system that results from the interaction of its components, not from their properties. <indexterm>
  <primary>emergence</primary>

</indexterm> <indexterm>
  <primary>emergent property</primary>

</indexterm> </para>

  
  <para>For example, the agents in Schelling’s model are not racist, but the outcome of their interactions is as if they were. Traffic jams move backward even though the cars in them are moving forward or standing still. The behavior of flocks and herds emerges from local interactions between their members. And as Axelrod says about the iterated prisoner’s dilemma: “The emergence of cooperation can be explained as a consequence of individual[s] pursuing their own interests.” </para>

  
  <para>To clarify what emergence is, we can also consider what it isn’t. For example, a brick wall is hard because bricks and mortar are hard, so that’s not an emergent property. As another example, some rigid structures are built from flexible components, so that seems like a kind of emergence. But it is at best a weak kind, because structural properties follow from well-understood laws of mechanics. <indexterm>
  <primary>brick wall</primary>

</indexterm> </para>

  
  <para>Emergent properties are surprising: it is hard to predict the behavior of the system, even if we know all the rules. That difficulty is not an accident; it may be the defining characteristic of emergence. </para>

  
  <para>As Wolfram discusses in <emphasis>A New Kind of Science</emphasis>, conventional science is based on the axiom that if you know the rules that govern a system, you can predict its behavior. What we call “laws” are often computational shortcuts that allow us to predict the outcome of a system without building or observing it. <indexterm>
  <primary sortas="New Kind of Science">A New Kind of Science</primary>

</indexterm> <indexterm>
  <primary>Wolfram, Stephen</primary>

</indexterm> <indexterm>
  <primary>natural law</primary>

</indexterm> </para>

  
  <para>But many cellular automata are <emphasis role="bold">computationally irreducible</emphasis>, which means that there are no shortcuts. The only way to get the outcome is to implement the system. <indexterm>
  <primary>computationally irreducible</primary>

</indexterm> <indexterm>
  <primary>shortcut</primary>

</indexterm> </para>

  
  <para>This result suggests that emergent properties are fundamentally unpredictable, and that studying complex systems requires different methods, what Wolfram calls a new kind of science. </para>

  
  <para>You can read more about emergence at <ulink url="http://en.wikipedia.org/wiki/Emergence">http://en.wikipedia.org/wiki/Emergence</ulink>. </para>

  
  

</sect1>
</chapter><chapter id="a0000000116">
  <title>Sugarscape</title>
  
  
  <para><emphasis>Dan Kearney, Natalie Mattison and Theo Thompson</emphasis> </para>
<sect1 id="a0000000117" remap="section">
  <title>The Sugarscape in its Original Implementation</title>
    
  
  <para>A famous agent-based model is Epstein and Axtell’s “Sugarscape,” explained in detail in their book Growing Artificial Societies. Sugarscape is a virtual 2D grid where each cell has a certain amount of “sugar” or “spice” that increases at a certain rate. Agents roam the grid, consuming sugar as they visit cells. </para>

  
  <para>In the simplest Sugarscape, each agent has a sugar reserve, a metabolism at which rate it consumes its sugar, and a range of nearby cells that it can observe. At each time step, the agent observes its nearby cells and moves to the cell with the most sugar. These rules can be expanded to include topics as varied as reproduction, death, disease, loans, and warfare. For example, a disease can be introduced to the system where any sick agent can infect nearby healthy agents without immunity. </para>

  
  <para>Despite its simplicity, the model shows emergent behavior that resembles the real world. When modeling wealth with Sugarscape, a long tailed distribution appears where some agents are exponentially richer than others. This complex behavior is seen in the United States, where wealth is a Pareto distribution with the top 20% owning about 85% of the total wealth. In general, a long tailed distribution is viewed as a negative because it means there are many people barely surviving while others are fabulously rich. </para>

</sect1><sect1 id="a0000000118" remap="section">
  <title>#Occupy</title>
    
  
  <para>Wealth inequality has partly fueled a modern social movement known as “Occupy”. The first significant Occupy protest was on Wall Street, where thousands of protesters gathered to express their dismay against the wealth distribution, among other things. The movement’s motto is “We are the 99%”, reminding politicians to serve the majority, not the 1% who control more than a third of the nation’s wealth. A major goal of the movement is to achieve a more equal distribution of income, which protesters hope to accomplish by implementing a more progressive tax policy. </para>

  
  <para>There is little debate about the fact that taxes redistribute wealth from the rich to the poor. What opponents of the Occupy movement (and fiscal conservatives in general) claim is that high tax rates for the rich actually hurt the population as a whole. The logic is that wealthy people employ the poor, redistributing the wealth without the need for tax levies. </para>

</sect1><sect1 id="a0000000119" remap="section">
  <title>A New Take on Sugarscape</title>
    
  
  <para>Our implementation of Sugarscape aims to study the effect of taxation on the wealth of a society. We want to show how extreme under or over taxation can affect the society and its individual agents, and what happens in between these two extremes. The model tests a “flat tax” system where every agent gets taxed a constant rate (say 10% of its total wealth) and the tax pool is redistributed evenly among all the agents. We recreate the original Sugarscape and expand on it with the end goal of determining if it is possible to shrink the wealth gap without crippling the society. </para>
<sect2 id="a0000000120" remap="subsection">
  <title>Pygame</title>
    
  
  <para>In the process of implementing Sugarscape, we made a GUI to better understand what was happening on the grid. The visualization of the Sugarscape is done with Pygame, a set of Python modules that allows easy graphic drawing. Pygame can ‘blit’ images onto the screen and it has built-in methods for handling user input like mouse clicks and button presses, making it ideal for designing game or other programs that receive a lot of input. </para>

  
  <para>Below is an abbreviated version of our event loop that draws the cells in the GUI at each timestep. Sugarscape.nextstep() moves every agent forward by one timestep and the rest of the code redraws the update. Redrawing the entire grid is slightly less efficient than changing existing rectangle objects but is a common convention for pygame. A square is drawn for each location, and the color of the square changes based on the amount of sugar contained there. Agents are represented by circles drawn on top of their current location. </para>

  
  <programlisting>def event_loop(self,sugarscape):
   while True:
    sugarscape.nextstep()
    for i in range(sugarscape.length):
     for j in range(sugarscape.width):
      loc=sugarscape.get_location(i,j)
      health_color=(0, 0,loc.get_sugar_amt()/loc.get_max_sugar())
      pygame.draw.rect(self.window,healthColor,(12*i,12*j,10,10))
    pygame.display.update()</programlisting>

  
  <para>Users can control certain attributes of the Sugarscape by moving sliders underneath the grid. A histogram, implemented using the matplotlib library, shows the current distribution of wealth, and text fields show certain characteristics of the distribution. </para>

</sect2>
</sect1><sect1 id="a0000000121" remap="section">
  <title>Taxation and the Leave Behind</title>
    
  
  <para>Taxation in our implementation of Sugarscape is handled with a “Government” object. Every ten timesteps, the Government object collects a constant percentage of each agent’s sugar reserve. The Government then immediately redistributes the collected sugar to each agent equally. </para>

  
  <para>Taxation is a novel concept in Sugarscape, but the implementation described above does not fully capture a society’s response to taxation. In a real society, the wealthiest contribute to society more than the poor because they can open factories, do research and development, and generally make investments into the economy. In order to simulate the benefits that a few wealthy people bring into an economy, we need to implement some mechanism for the rich to contribute more to a society than the poor. As such, we implement a simple “leave behind” feature, where agents leave some sugar behind as they leave a location. The amount that they leave behind is calculated: </para>

  
  <para><inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0197.png" depth="11.500px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$sugar = \frac{wealth\times N}{total\_ wealth}^{1.1} \times \frac{1}{5}$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> </para>

  
  <para>where N is the total number of agents, wealth is the amount of sugar the agent currently has, and total wealth is the total amount of sugar owned by all the agents. Agents who own a large proportion of the total wealth leave behind larger amounts of sugar, making an “investment” into the Sugarscape, and creating wealth around it. </para>
<sect2 id="a0000000122" remap="subsection">
  <title>What is a Gini coefficient?</title>
    
  
  <para>In order to compare tax rates objectively based on their wealth distribution, we need a metric that can measure how distributed or flat a certain wealth distribution is. We use the Gini coefficient, which is often used in economics to measure the wealth gap (named after Corrado Gini who developed it in 1912). This coefficient allows us measure how well the wealth is distributed. The value is always between 0 and 1, with 0 the measurement of a perfectly uniform distribution, and 1 the measurement of a distribution with complete inequality. </para>

  
  <para>A good way to visualize Gini coefficients is a Lorenz curve. A society’s wealth inequality is visualized by the curvature of the graph, where a perfectly distributed society is a straight line. </para>

  
  <figure id="a0000000123">
  
  <title>Lorenz curves for different tax rates.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/lorenz.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

</sect2><sect2 id="a0000000124" remap="subsection">
  <title>Results Without Taxation</title>
    
  
  <figure id="a0000000125">
  
  <title>PMF with no tax.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/pmf_notax.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

  
  <para>Figure 3 shows a histogram describing the wealth distribution when there is no tax system in place. For most initial conditions without taxation, the Sugarscape quickly develops a long-tailed distribution of wealth, skewed to the right. In these cases, some agents die quickly, particularly in an environment with many agents or one with low sugar regrowth rate. The separation between the rich and the poor is significant, and there aren’t many agents occupying the middle ground. This is seen in real life in societies where there is no tax structure and there isn’t much of a middle class. </para>

</sect2><sect2 id="a0000000126" remap="subsection">
  <title>Results With Taxation</title>
    
  
  <figure id="a0000000127">
  
  <title>PMF with tax.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/pmf_20percent.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

  
  <para>Figure 2 shows our results with a relatively high tax rate. The agents have a similar amount of sugar, and the economy has a very low Gini coefficient (.02). Figure 3 confirms this, showing that higher taxes in general result in lower Gini coefficients. This makes sense, since the point of our tax system is to redistribute the wealth. </para>

  
  <para>One drawback to such a small deviation of wealth is the effect it has on the mean wealth. The mean in figure 2 (with 20% tax) is 157, compared to the 0% tax rate case where the mean is 358. Figure 5 shows the plot of the tax rate versus the mean wealth, which shows that the mean wealth gets smaller as taxes get higher. </para>

  
  <figure id="a0000000128">
  
  <title>The Gini coefficient versus the tax rate.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/gini_coeff.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

  
  <figure id="a0000000129">
  
  <title>The tax rate plotted against the mean wealth of the Sugarscape agents. The mean wealth decreases as the tax rate increases, showing the tax rate’s effect on the wealth of the agents.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/mean_wealth.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

</sect2>
</sect1><sect1 id="a0000000130" remap="section">
  <title>Conclusion</title>
    
  
  <para>It’s up to a society to determine its ideal wealth distribution. If a society values total wealth above all else, the best way to achieve that is with zero taxation. Figure 4 shows that taxation causes the total wealth in a society to decline. All the way to the left, at zero taxation, is analogous to a purely capitalist system. The other end of the spectrum is a Marxist system with total taxation and even wealth redistribution. The capitalist system produces more total wealth, while a Marxist system does not allow for much variability. </para>

  
  <para>These two systems are at odds with each other, and neither fully represent how a real-world society values wealth. A real society would want as much wealth as possible while still preventing poverty. An effective way to track how the lower class is doing is showing how the bottom quartile’s wealth changes with taxation. In figure 5, we see the average wealth of the bottom quartile reaches a peak around a tax rate of 4%. </para>

  
  <para>As the tax rate gets higher, the bottom quartile’s wealth initially climbs, which is expected as taxation is designed to aid the poorest in a society. But at a critical point around 3%, the bottom quartile’s wealth drops too–this is the point where the society’s decline overcomes the taxation’s aid. </para>

  
  <figure id="a0000000131">
  
  <title>Bottom quartile value versus tax rate. There is a critical point around a tax rate of 4% where the average wealth of the bottom quartile is maximized.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/bottom_quartile.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

  
  <figure id="a0000000132">
  
  <title>The wealth distribution for a smaller tax rate (2%). There is still some deviation, but the mean wealth is high.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/pmf_2percent.pdf" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</figure>

  
  <para>This means, given our Sugarscape, we will minimize our poorest’s plight by implementing a 4% tax. This means that some taxation should be in place to avoid severe poverty, but over-taxation does more harm than good. </para>

  
  <para>Imagining a society’s total wealth as a pie helps explain this behavior. In a purely capitalist system, the pie is very large, but some members of society have very small slices. In a purely Marxist system, the pie is small, but everyone shares it equally. The goal of a balanced society is to make the smallest piece of the pie large enough to sustain an acceptable quality of life. </para>

  
  <para>Our Sugarscape’s taxing implementation showed this trade off in the decreasing trends of the Gini coefficient and mean wealth as the tax rate increases. With higher taxes, there is more wealth, but also more inequality. We have justified a tax rate of 4% because it results in the highest wealth for the bottom quartile, in effect minimizing poverty in a society. </para>

</sect1>
</chapter><chapter id="a0000000133">
  <title>Ant Trails and Agent-Based Models</title>
  
  
  <para><emphasis>Chloe Vilain and Andrew Pikler</emphasis> </para>
<sect1 id="a0000000134" remap="section">
  <title>Introduction</title>
    
  
  <para>In nature, ants scavenge for food as a swarm. They choose their paths from the nest based on pheromone density, favoring paths with higher concentrations of pheromone. Individuals lay pheromone trails upon finding food, allowing other members of their colony to passively follow them to the food source. Because paths leading to food have higher pheromone density, increasing numbers of ants choose these successful paths. As a result, ant trails transition over time from random paths to streamlined routes. This organization and appearance of patterns over time is an example of <emphasis role="bold">emergence</emphasis>, the process by which complex systems and patterns arise from a multiplicity of simple systems. </para>

  
  <para>Ant feeding patterns lend themselves to simulation with <emphasis role="bold">agent-based models</emphasis>, which simulate the actions and interactions of autonomous agents to assess their effects on the system as a whole. When we model ant feeding patterns, each ant is an agent in the model, a self-governing individual that makes decisions based on its surroundings. When simulating large numbers of ants, behavior emerges that is reflective of ant behavior in the natural world. Beyond being intrinsically fascinating, such models have applications in the “real world” in areas ranging from city planning to film production. We will discuss the application of agent-based models to the entertainment industry later in the paper. </para>

</sect1><sect1 id="a0000000135" remap="section">
  <title>Model Overview</title>
    
  
  <para>We can see one example of an agent-based model in Deneuborg et al.’s 1989 paper <emphasis>The Blind Leading the Blind: Modeling Chemically Mediated Army Ant Raid Patterns</emphasis>, freely available at <ulink url="http://www.ulb.ac.be/sciences/use/publications/JLD/80.pdf">http://www.ulb.ac.be/sciences/use/publications/JLD/80.pdf</ulink>. </para>

  
  <para>The premise of the model is that as ants move around they lay pheromone, which increases the likelihood that other ants will follow the same path. Ants that have found food lay more pheromone than ants that haven’t, making it likely that other ants will follow their paths to find more food. </para>

  
  <para>The ants live in a two-dimensional world of discrete points arranged in a grid. At each step of the model, each ant has a certain probability of moving to one of two neighboring coordinates in the direction the ant is facing, away from the nest—forward left or forward right. All of the ants start out in a corner of the world, which we call the <emphasis>nest</emphasis>, and at each time step of the simulation, we add more ants to the nest. This leads to a constant stream of outgoing ants. </para>

  
  <figure id="fig.antchoice">
  
  <title>In the model, ants live in a grid and face away from the nest. At each time step, they can move forward left or forward right.<anchor id="a0000000136" /></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/antchoice.jpg" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para>Once an ant has found food, it turns back towards the nest. It obeys the same rules for motion—that is, in each time step, its choice to move either forward left or forward right is influenced by the amounts of pheromone it sees, except now, these choices take it back towards the nest. Also, after moving, the ant lays more pheromone than it did while foraging for food. This significantly increases the probability that other foraging ants will follow its path to find, potentially, more food. </para>

  
  <para>In its starting configuration, each point in the world has a chance of containing food. Once this starting condition has been set, we let the simulation run for about 1000 time steps, and plot the result. You can see the plot of one such simulation in <xref linkend="fig.plot" />, which is similar to what Deneuborg et al. claim actual army ant foraging patterns look like in their paper because observable ant trails have emerged. </para>

  
  <figure id="fig.plot">
  
   <title>Plot of our simulation after 1000 time steps.<anchor id="a0000000137" /></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/plot.png" scale="40"></imagedata>
  </imageobject>
</mediaobject>

  
  
</figure>

  
  <para> Download the code for ants.py, our simulation, available at <ulink url="thinkcomplex.com/ants.py">thinkcomplex.com/ants.py</ulink>. Run it for 1000 time steps and see if your results look similar to <xref linkend="fig.plot" />. The simulation can be computationally intensive, and 1000 time steps took about 1.5 minutes to run on our machine—be patient!  </para>

</sect1><sect1 id="a0000000138" remap="section">
  <title>API design</title>
    
  
  <para>A major challenge of writing a simulation such as this is coming up with classes that are easy for human readers of the code to understand, as well as implementing data structures that allow the code to execute efficiently. </para>

  
  <para>One way to break up a model into classes is to list the main nouns you use when describing the model, and then represent the most prominent of those nouns as classes. In the case of our model, we have the World, which contains Ants along with Locations that may or may not contain food. </para>

  
  <para>The next step is to decide what information about the current state of the model an instance of each class will be responsible for knowing. In our case, the behavior of the World is defined by what the Ants and Locations can do, so it makes sense to design our classes bottom-up and consider the World only once we have at least a tentative idea for the methods and attributes of Ants and Locations. </para>

  
  <para>The most important piece of information that Ants know is where they are located in the World; as such, each ant has the attributes x and y to keep track of its current coordinates. Also, each Ant keeps track of whether or not it is currently carrying food, so we define has_food for this purpose. </para>

  
  <para>Note that Ants know only local information about the World; keeping track of all the Ants will be the job of the World object itself. </para>

  
  <para>Knowing that the World will have to interact with individual Ants, we define two methods inside the Ant class that will get called by the World: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>move: Figures out whether the Ant will move this turn, and if so, moves the Ant accordingly. </para>
</listitem>
  
    <listitem>
  
  <para>getPos: Returns the current coordinates of this Ant. </para>
</listitem>
  
</itemizedlist></para>

  
  <para>The Ant class contains numerous other methods, but these are intended for internal use by each Ant object only, and not by the World. For example, the methods will_move and will_go_right determine whether or not the Ant will move this turn and if so, whether it will move forward right or forward left, but these methods are only ever called by the Ant’s move method. Similarly, move is the only method that calls lay_pheromone, which increases the pheromone count at the Ant’s current Location in the World. </para>

  
  <para>Locations know even less than Ants; each Location only keeps track of the food and pheromone it contains, using attributes called food and pheromone, respectively. As far as methods go, a Location only has short accessor methods that Ants and the World use to modify the Location’s food and pheromone amounts. </para>

  
  <para>Note that unlike Ants, Locations do not keep track of their coordinates on the map. While having them do so might make sense at first, we decided against it because a Location’s coordinates never change; since the World must already keep track of each Location’s coordinates so it can access the correct Location given its x and y positions, having the Location also keep track of its position would be redundant. </para>

  
  <para>The World is the “meat” of our simulation—it is where most of the work gets done. The World is only ever instantiated once, and this instance keeps track of all existing Ants and Locations. </para>

  
  <para>The World has methods for controlling the overall state of the simulation. The World’s move_ants method advances the simulation by one time step by calling every existing Ant’s move method, changing the ants attribute to reflect the Ants’ new positions, and evaporating a certain proportion of pheromone from each Location. Other methods include add_ants, which adds a specified number of ants to the nest, place_food, which fills each Location on the map with food at a certain probability, and get_location, which returns a reference to the Location at the given coordinates. </para>

</sect1><sect1 id="a0000000139" remap="section">
  <title>Sparse matrices</title>
    
  
  <para>The group of Locations that make up our World is implemented as a <emphasis role="bold">sparse matrix</emphasis>. What this means is that Locations don’t exist in our representation until they are needed; the World’s get_location method is responsible for fetching either the existing Location at the given coordinates, or creating a new Point if one doesn’t already exist there. An alternate implementation would be a <emphasis role="bold">dense matrix</emphasis>, which would be a two-dimensional array—a list of lists—of all Locations in the world. In our case, a sparse matrix has two main advantages over a dense matrix: </para>

  
  <para><itemizedlist>
  
    <listitem>
  
  <para>Since most of the World is empty most of the time, it’s more memory-efficient to only keep track of those Locations that aren’t empty. </para>
</listitem>
  
    <listitem>
  
  <para>A sparse matrix, unlike a dense matrix, doesn’t have set dimensions. This means that in our implementation, an Ant is free to wander off in any direction with no additional development cost to us as programmers, whereas in a dense matrix if an Ant were to walk outside the dimensions of the matrix, the dimensions would have to be expanded in a developmentally costly operation. </para>
</listitem>
  
</itemizedlist></para>

</sect1><sect1 id="a0000000140" remap="section">
  <title>wx</title>
    
  
  <para>We use the wx Python package to plot a picture of the ants after the simulation finishes running. </para>

  
  <para>Our code defines a class called AntPlot which is responsible for taking the World and popping up a wx window that plots the ants as seen in <xref linkend="fig.plot" />: </para>

  
  <programlisting>class AntPlot:
    def __init__(self, world):
        self.world = world
        self.app = wx.PySimpleApp()
        self.w = 500
        self.h = 500
        self.frame = wx.Frame(None, -1, 'Ant Plot', size=(self.w, self.h))
        self.canvas = FloatCanvas(self.frame, -1)
        
    
    def draw(self):
        positions = self.world.get_ant_dict()
        for pos in positions:
            x, y = pos
            x -= self.w / 2
            y -= self.h / 2
            self.canvas.AddPoint((x, y))
        self.frame.Show()
        self.app.MainLoop()</programlisting>

  
  <para>The specific widget we use to accomplish the plotting is a FloatCanvas. Most canvases in GUI libraries define the point (0, 0) as the upper left corner of the canvas and have x increase to the left and y increase down, but the coordinates in the FloatCanvas work like in math—(0, 0) is defined as the middle, and y increases up. This allows us to write simpler code because we don’t have to transform our coordinates to the canvas’s system like we would have to for a traditional canvas. </para>

  
  <para>Our AntPlot class serves as somewhat of a “hello world” application for wx—all it does is pop up a single window and some plotting. If you are interested in exploring wx further, this class might be a good starting point. </para>

  
  <para> Try altering the pheromone amounts in the model. What happens when Ants only lay pheromone when leaving the nest? When returning? What happens when Ants lay significantly more or less pheromone than currently? Are there any boundary conditions?  </para>

  
  <para> Different species of ants have different patterns of food locations. In ant.py, each Location has a 50% probability of containing one particle of food. What happens when each Location has a 1% probability of containing 50 pieces of food?  </para>

  
  <para> So far, we have only considered scenarios involving one nest of ants. What happens when we consider multiple nests? Pick a value d and modify the code such that Ants spawn at (0, d) and (d, 0) in addition to (0,0). Do the trails of ants converge, or do they all remain distinct? Try keeping track of the amount of food that has been collected in each nest. Does any one of the nests do better than the others?  </para>

  
  <para> Previously, we have assumed that all ants lay the same quantity of pheromone as other ants. Revisiting our three-nest scenario, what happens when ants from one nest lay slightly higher amounts of pheromone than those from the other nests?  </para>

</sect1><sect1 id="a0000000141" remap="section">
  <title>Applications</title>
    
  
  <para>Agent-based models have numerous applications in the “real world”, from modeling traffic patterns to creating realistic battle simulations. The entertainment industry has begun using agent-based models to simulate crowds in films, games, and advertisements that would have previously been infeasible to create. Modeling is far more scalable than filming; that is, it is much easier to model a crowd of a hundred thousand people than it is to recruit a hundred thousand extras. The application of agent-based models to the entertainment industry has changed the nature of film as we know it by allowing for the creation of large-scale, visually stunning sequences. </para>

  
  <para>The <emphasis>Lord of the Rings</emphasis> trilogy is the canonical example of films only possible with the use of agent-based models. The current industry-standard software, called Massive, was originally developed to simulate life-like battle sequences in the trilogy. Massive has since been used in a wide variety of films, for battle sequences in movies like <emphasis>Chronicles of Narnia</emphasis> and <emphasis>300</emphasis>, as well as for more benign crowd simulations in films such as <emphasis>Happy Feet</emphasis> and <emphasis>Avatar</emphasis>. </para>

  
  <para>In <emphasis>Lord of the Rings</emphasis>, developers were tasked with creating battles with hundreds of thousands of soldiers from a variety of races with many different fighting techniques. In order to create these battles, they implemented a simulation wherein each fighter was an agent. Each agent had about 200 possible motions it could perform which were animated using motion-capture. Within its “brain”, the agent chose from the possible responses based on logic and probabilities. Different races within the battles, such as elves, orcs and men, were based on the same “master agent” but had different weapons, abilities and programmed attack responses. </para>

  
  <para>Simulating thousands of agents in tandem allowed for exceptionally complex and sometimes unpredictable battle sequences. The results sometimes surprised even Massive’s developers—in one shot of the prologue battle scene, a number of agents fled the battle. The agents were not programmed to flee; that is, fleeing was not one of their “options” when evaluating the situation to decide which action to perform. Rather, this decision came about based on their evaluation of location and determination to run from enemies and not fight—an emergent behavior. This unexpected action, which would be realistic in an actual battle scenario, speaks to the power of agent-based models. </para>

  
  <para>The use of agent-based models allowed battle sequences to be re-simulated and tinkered with until results were satisfactory. This freedom allowed directors to experiment far more than would have been possible with casted battles. </para>

  
  <para>You may be wondering how <emphasis>Lord of the Rings</emphasis> relates to ant trails. Clearly, the models used in the films are far more complicated than those we used to simulate ant trails; however, their results are further proof of the same concept. Like the agents in <emphasis>Lord of the Rings</emphasis>, our ants were given relatively simple commands from which complex behavior evolved. Moreover, this behavior was believable and true to the natural world. </para>

</sect1>
</chapter><chapter id="a0000000142">
  <title>Directed Graphs and Knots</title>
  
  
  <para><emphasis>Rachel Bobbins and Noam Rubin</emphasis> </para>
<sect1 id="a0000000143" remap="section">
  <title>Directed Graphs</title>
    
  
  <para> Imagine that it’s 2 AM during finals week, and you’re scrambling to finish your research paper on <emphasis>topica obscura</emphasis>. Your adrenaline jumps when you finally find a relevant Wikipedia article, with links to more Wikipedia articles! You start clicking away, jumping from page to page in search of facts. An hour later, you realize you’re still clicking, but these are pages you’ve already visited. No matter which link you click, you can’t seem to discover any new pages! </para>

  
  <para>If this situation has ever happened to you, then you’ve unknowingly (and unfortunately) stumbled upon a knot in Wikipedia. Knots are a unique property of directed graphs. To understand them, it’s necessary to have a basic understanding of directed graphs. </para>

</sect1><sect1 id="a0000000144" remap="section">
  <title>Directed Graphs in Code</title>
    
  
  <para>The graphs we’ve encountered in previous chapters are all undirected graphs. In an undirected graph, a single edge between two vertices represents a symmetric relationship between the vertices. This abstraction works well to describe some real-world systems (such as acquaintance networks and transportation networks), but it is not detailed enough to describe the Internet, including Wikipedia. Relationships between websites do not have to be symmetric – think of all the pages that Google links to. The majority of these pages do not link back to Google. </para>

  
  <para>This non-symmetry holds true for Wikipedia as well. Page A might link to page B, but page B doesn’t have to include any links to page A. To fully describe the relationship between pages A and B, we need two bits of information: whether A links to B, and whether B links to A . This is the essence of a directed graph. In a directed graph, an arc <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0198.png" depth="8px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$e = (A,B)$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> is an <emphasis>edge</emphasis> from A <emphasis>to</emphasis> B. Arcs are usually referred to as directed edges. </para>

  
  <informalfigure>
  
  <title></title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/DirectedGraphExample.png" scale="40"></imagedata>
  </imageobject>
</mediaobject>
</informalfigure>

  
  <para>As previously mentioned, knots are a unique (and sometimes cruel) property of directed graphs. A knot in a directed graph is a collection of vertices and edges with the property that every vertex in the knot has outgoing edges, and all outgoing edges from vertices in the knot terminate at other vertices in the knot. Thus it is impossible to leave the knot while following any path along its directed edges. </para>

  
  <para>We mentioned the idea of knots in Wikipedia. We wondered whether such a thing was even possible. Given that there are 3,811,000+ articles on Wikipedia and they all link to different pages, it seemed unlikely that there would be a knot, but we decided to investigate. </para>

  
  <para>Before writing an algorithm to determine the existence of knots in a directed graph, we extended <literal remap="verb">Graph.py</literal> to support directed graphs. The result is <literal remap="verb">DirectedGraph.py</literal>, which you can download at <ulink url="https://raw.github.com/nrubin/RachelAndNoamsDirectedGraphs/master/DirectedGraph.py">https://raw.github.com/nrubin/RachelAndNoamsDirectedGraphs/master/DirectedGraph.py</ulink>. We recommend reading through this file and making yourself familiar with the terminology. Note that Edges in DirectedGraph are represented by Arcs. </para>

  
  <para>When we were designing <literal remap="verb">DirectedGraph</literal>, we wanted to preserve the order of growth of <literal remap="verb">ertex  and \verb Arc  lookups as they were in \verb Graph.  However, we needed to keep track of edges into a vertex and edges from a vertex. It made sense to keep track of these in separate dictionaries. Thus, out-arcs were stored in the\verb DirectedGraph  internal dictionary, and in-arcs were stored in an additional dictionary called \verb reverse_graph.  Having two dictionaries takes twice as much memory, but this seemed like a reasonable price to pay for maintaining the speed of lookups.

\section{Knotting Algorithm}

Now, back to knots. Our research found only distributed algorithms for detecting knots.\footnote{See \url{http://www.cs.utexas.edu/users/misra/scannedPdf.dir/KnotDetection.pdf}}. Distributed algorithms are designed to run concurrently on multiple processors. Identical but distinct chunks of the algorithm run on each processor, and report to each other the results of their computation. These kinds of algorithms are ideal for large research projects, but we needed an algorithm that would run on a single computer. To this end, we devised our own algorithm.

The algorithm relies heavily on a modified version of breadth-first-search, \verb"_bfsknots". It searches for all the vertices that can be reached from a given starting vertex, and returns these vertices as a set.  The function runs once for every vertex in the graph, building up a dictionary which maps a single vertex to the set of all vertices that are reachable from it.

\begin{verbatim}
  def _bfsknots(self, s):
        # initialize the queue with the start vertex
        queue = [s]
        visited = set()
        on_first_vertex = True
        while queue:

            # get the next vertex
            v = queue.pop(0)

            # skip it if it's already marked
            if v in visited: continue

            # if we're on the first vertex, we're not actually visting
            if v != s or not on_first_vertex: visited.add(v)
            on_first_vertex = False
            
            for x in self.out_vertices(v):
                #if its out vertices have been cached, update visited
                if x in self._knot_cache.keys():
                    visited.update(self._knot_cache[x])
                    visited.add(x)
                    
                #otherwise add it to the queue
                elif x not in self._knot_cache.keys():
                    queue.append(x)

        return visited
\end{verbatim}

Let's say that $S_v$ is the set of vertices that are reachable from some vertex $v$, including itself. if $S_v$ is the same for all the vertices reachable from $v$, the graph has a knot.

The function \verb"has_knot" iterates through each vertex in a graph, and returns True if the previous condition holds for some vertex. If it checks the whole graph and does not find a knot, it returns False.
\begin{verbatim}
    def has_knot(self):
        """
        Returns true if directed graph has a knot.
        """
        self._knot_cache = {}
        #build the cache of which vertices are accessible from which
        for v in self:
            self._knot_cache[v] = self._bfsknots(v)

        #searches for knot
        for v in self:
            if self._knot_at_v(v):
                return True
        return False

\end{verbatim}

\begin{ex}
 Determine the order of growth of \verb has\_knots  experimentally. You might want to review Chapter 3, Section 1. Below are several hints to help you out.
\begin{enumerate}
 \item Use \verb"DirectedGraph.add_random_edges" to generate a few thousand graphs of different sizes.

\item For each graph, time how long it takes to check if it has a knot.

\item Plot the time it took to check if the graph has a knot versus the number of vertices the graph has. Also plot against the number of edges the graph has.

\item What has more of an effect on the runtime \verb has_knots, vertices or edges?

\item From your figures, determine the order of growth of \verb has_knots .
\end{enumerate}

\end{ex}

\begin{ex}
 Find all the knots in a directed graph.
\begin{enumerate}
 \item Write a function, named \verb all_knots , that returns a list of all knots in a graph.
\item Building on your answer from the previous question, write a function named \verb entry_points that returns a list of all the vertices that serve as entry points into knots.
\end{enumerate}

\end{ex}

\section{Parsing Wikipedia}

To find knots in Wikipedia, we selected 558 disjoint subsets of Wikipedia articles, organized by index. For example, the index of articles about neurobiology was used to define one subset, and the index of articles about Zimbabwe was used to define another subset. Combined, these subsets contained about 321,000 articles, or 10\% of Wikipedia. We only looked at subsets because we lacked the processing power to parse and analyze all of Wikipedia.\footnote{If you’re interested in the whole graph of Wikipedia, we recommend checking out research done by Stephen Dolan at Trinity College Dublin. His research is online here: \url{http://mu.netsoc.ie/wiki/}}. 

\section{The Structure of Wikipedia}
Of the 558 subgraphs we examined, 38\% contained at least one knot. This indicates that if you are reading articles listed on the same index page, there is a chance you will get stuck in a knot and start to see the same articles again. In actuality, the odds of this happening are much lower than 38\%, because articles can link to articles which don't share the same parent index. Our analysis ignored these links. For example, our analysis would have ignored a link from a neurobiology article to a Zimbabwe article, unless the Zimbabwe article was also listed in the neurobiology index. Furthermore, the 38\% does not imply that the graph of all of Wikipedia has a knot.

\begin{figure}
 \centering
\includegraphics[width=3.0in]{figs/BAResults.png}
\caption{The graphs from Barabasi and Albert's 1999 paper show the scale-free structure of a few undirected graphs. $k$ is the average connectivity, or degree, of the vertices in the graph, and $P(k)$ is the proportion of vertices in the graph that have this degree. Plotted on a log-log scale, scale-free networks tend to show long-tailed distributions. This is because a few vertices have the highest degree in the graph.}
\label{fig:BAGraph}
\end{figure}


Back to the original question of \emph{topica obscura}. When you started this hypothetical homework assignment, you could have chosen to use journal articles instead of Wikipedia articles. If you'd done this, you probably would have used citations to find other papers to read. You'd never have ended up in this knot. Why? Think of journal articles as vertices in a directed graph, where a directed edge represents one article citing another. Because science articles are published sequentially, and a paper cannot cite a paper that will be created in the future, this directed graph cannot have a knot. Thus, because journal articles cannot have symmetrical citations, while Wikipedia articles can, they are fundamentally different systems of organizing information.


In Barabasi and Albert's paper about scale-free networks\footnote{Barabasi, Albert-Laszlo and Albert, Reka, Emergence of Scaling in Random Networks; Science Magazine, </literal>ol. 286, 15 October 1999., they analyze the underlying undirected graph of citations in scientific articles. Given that this graph must have a different structure than the graph of Wikipedia, we wondered whether the Barabasi-Albert model is applicable to Wikipedia. </para>

  
  <figure id="fig:PunchlineGraph">
  
  <title>The distribution function of connectivities for various large subgraphs of Wikipedia. <emphasis role="bold">(A)</emphasis> Index of India-related articles with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0199.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N = 5,342$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> vertices and average connectivity <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0200.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$ k = 53.56$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <emphasis role="bold">(B)</emphasis> Index of Mathematics articles starting with C, with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0201.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N = 3813$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and average connectivity <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0202.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k = 4.95$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. <emphasis role="bold">(C)</emphasis> Index of Mathematics articles starting with S, with <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0203.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$N = 3950$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation> and average connectivity <inlineequation>
  
  <inlinemediaobject remap="math">
    <imageobject>
      <imagedata fileref="images/img-0204.png" depth="7.250px" scale="25" role="math" />
    </imageobject>
    <textobject role="tex">
      <phrase>$k = 4.85$</phrase>
    </textobject>
  </inlinemediaobject>
</inlineequation>. Compared to <xref linkend="fig:BAGraph" />, these three graphs also display scale-free distributions. The structure of these distinct subgraphs hints at the nature of Wikipedia as a whole, indicating that Wikipedia is possibly scale-free.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/WikipediaPowerLawGraph.png" scale="40"></imagedata>
  </imageobject>
</mediaobject>  <anchor id="a0000000145" /> </para>
</figure>

  
  <para>To determine the structure of the subgraphs of Wikipedia, we looked at the largest graphs and tried to recreate the results from Barabasi and Albert’s 1999 paper (seen in <xref linkend="fig:BAGraph" />. </para>

  
  <para>Comparing <xref linkend="fig:BAGraph" /> to <xref linkend="fig:PunchlineGraph" />, we can see that the general structure of both is very similar. This means that the distinct subgraphs we examined are characteristically scale-free. In addition, it means that Wikipedia graphs are well-modeled by the Barabasi-Albert small world graph model. </para>

  
  <para>But what does this really mean? The Barabasi-Albert model of small-world graphs is especially good at modeling preferential attachment, the phenomenon where a few of the vertices have the highest degree. The fact that both undirected graphs and the directed graphs can have a scale-free distribution of degrees means that preferential attachment is independent of the directedness of the graph. </para>

  
  <figure id="fig:AllThree">
  
  <title>The distribution function of connectivities for the in-degrees <emphasis role="bold">(A)</emphasis>, out-degrees <emphasis role="bold">(B)</emphasis>, and total degrees <emphasis role="bold">(C)</emphasis> of the vertices in the Index of India-related articles subgraph. Both the in- and out-degree distributions are scale-free, further indicating that preferential attachment is independent of directedness.</title>
<mediaobject>
  <imageobject remap="includegraphics">
    <imagedata fileref="figs/AllThreeScaleFree.png" scale="40"></imagedata>
  </imageobject>
</mediaobject>  <anchor id="a0000000146" /> </para>
</figure>

  
  <para>This independence is further demonstrated by <xref linkend="fig:AllThree" />, which shows the degree distribution of the in, out, and total degrees of the “Index of India-related articles” subgraph. All three distributions are scale-free, which means that few vertices have a high in-degree and few vertices have a high out-degree. This corresponds with our findings that preferential attachment is independent of the directedness of a graph. </para>

</sect1><sect1 id="a0000000147" remap="section">
  <title>Conclusion</title>
    
  
  <para>Since Wikipedia subgraphs display a tendency towards preferential attachment, we propose another explanation for why you keep landing on the same articles. Perhaps there is not a knot in the articles you are reading, and in fact, that set of articles is very well connected to the rest of the graph. Since subgraphs of Wikipedia are small-world, a small set of vertices will have the highest degrees in the graph. That means that if you take a random walk through the graph, the odds you’ll encounter these vertices are very high. </para>

  
  <para>Barabasi and Albert’s example of undirected graph of citations in science articles indicates that, even if you are traversing an undirected graph, you may encounter the same vertices over and over, without there being a knot. This small set of articles may be cited the most, so in your research for a certain topic, you’re very likely to see these articles multiple times. </para>

  
  <para>What does this mean for your research project? Whether you’re browsing Wikipedia or JSTOR, you’ll end up seeing the same highly-referenced nodes multiple times. In many ways, this can be frustrating when looking for a specific or isolated article, but it is a result of the small world nature of the graphs that represent the information you’re seeking. </para>

</sect1>
</chapter>
<index></index>
</book>